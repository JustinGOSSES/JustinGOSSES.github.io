<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>Justin</title>
	<atom:link href="/author/darwin1/feed/" rel="self" type="application/rss+xml" />
	<link>/</link>
	<description>Geology, Maps, and Code</description>
	<lastBuildDate>Mon, 25 Apr 2022 01:36:20 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=5.8.4</generator>

<image>
	<url>/wp-content/uploads/2017/02/cropped-JustinGosses_logo-32x32.jpg</url>
	<title>Justin</title>
	<link>/</link>
	<width>32</width>
	<height>32</height>
</image> 
	<item>
		<title>New Version of this Website</title>
		<link>/new-version-of-this-website/</link>
					<comments>/new-version-of-this-website/#respond</comments>
		
		<dc:creator><![CDATA[Justin]]></dc:creator>
		<pubDate>Mon, 25 Apr 2022 01:36:20 +0000</pubDate>
				<category><![CDATA[Uncategorized]]></category>
		<guid isPermaLink="false">/?p=1570</guid>

					<description><![CDATA[After seven years as a WordPress site, I am finally getting around to rebuilding the page with a different toolset. You can see the new page at https://www.justingosses.com/ While this page is WordPress that lives on AWS. The new site is Next.js &#38; Tailwind CSS deployed on Azure static web<a class="moretag" href="/new-version-of-this-website/"> Read more&#8230;</a>]]></description>
										<content:encoded><![CDATA[
<p>After seven years as a WordPress site, I am finally getting around to rebuilding the page with a different toolset. <br><br>You can see the new page at <a href="https://www.justingosses.com/">https://www.justingosses.com/</a> <br><br>While this page is WordPress that lives on AWS. The new site is <a href="https://nextjs.org/">Next.js</a> &amp; <a href="https://tailwindcss.com/">Tailwind CSS</a> deployed on <a href="https://azure.microsoft.com/en-us/">Azure</a> static web apps.<br><br>The content on the new sites is 90% the same as the old site. What changes is theme and styling. Cost and complexity is what drove this change. WordPress is easy and cheap to start, but gets costlier to host over time. There&#8217;s no reason this site can&#8217;t be a simple front-end only site, so finally getting around to that change.</p>
]]></content:encoded>
					
					<wfw:commentRss>/new-version-of-this-website/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>Finding a NASA Contractor Job</title>
		<link>/finding-a-nasa-contractor-job/</link>
					<comments>/finding-a-nasa-contractor-job/#respond</comments>
		
		<dc:creator><![CDATA[Justin]]></dc:creator>
		<pubDate>Thu, 16 Dec 2021 19:35:20 +0000</pubDate>
				<category><![CDATA[Uncategorized]]></category>
		<category><![CDATA[info]]></category>
		<category><![CDATA[job]]></category>
		<category><![CDATA[NASA]]></category>
		<guid isPermaLink="false">/?p=1538</guid>

					<description><![CDATA[Table of Contents What Led to this Blog Post Why Work for a NASA Contractor? Problem this document attempts to impact Who Are NASA Contractor Companies Other Related Information Internships Remote NASA Contractor Jobs Can Foreign Nationals be NASA Contractors What Led to this Blog Post This blog post copies<a class="moretag" href="/finding-a-nasa-contractor-job/"> Read more&#8230;</a>]]></description>
										<content:encoded><![CDATA[
<h2>Table of Contents</h2>



<ul><li><a href="#What Led to this Blog Post" data-type="internal" data-id="#What Led to this Blog Post">What Led to this Blog Post</a></li><li><a href="#why-target-nasa-contractor-job">Why Work for a NASA Contractor?</a></li><li><a href="#problems-this-document-attempts-to-impact">Problem this document attempts to impact</a></li><li><a href="#who-are-nasa-contractor-companies">Who Are NASA Contractor Companies</a></li><li><a href="#other--related-information">Other Related Information</a><ul><li><a href="#internships">Internships</a></li><li><a href="#remote-nasa-contractor-jobs">Remote NASA Contractor Jobs</a></li><li><a href="#can-foreign-nationals-be-nasa-contractors">Can Foreign Nationals be NASA Contractors</a></li></ul></li></ul>



<h3><br><meta charset="utf-8">What Led to this Blog Post</h3>



<p>This blog post copies <a href="https://github.com/JustinGOSSES/nasa-contractor-jobs-information/blob/main/README.md#problem-this-document-attempts-to-impact">information I&#8217;ve previously put in this GitHub repository </a>as a quick and easy document I could share with others interested in NASA contractor jobs without having to retype the same things multiple times in yet another email. If you have any improvements or edits, please read the <a href="https://github.com/JustinGOSSES/nasa-contractor-jobs-information/blob/main/contributing.md">contributing guidelines</a>.</p>



<p>The main contribution of this document is the aggregation of all the various places to find NASA center specific lists of NASA contractor companies.</p>



<p><em>DISCLAIMER: This is just my opinion at one point in time and likely will be incorrect and out of date in some form almost immediately.</em></p>



<h3>Why Work for a NASA Contractor?</h3>



<p>Although most people think about working for NASA in terms of working directly for NASA as a government civil servant, <em>most of NASA&#8217;s work is actually done by contractors</em>. Contractors make up the large majority of NASA&#8217;s workforce.</p>



<p>Working as a NASA contractor can be a great experience. I certainly found my time there to a great opportunity. I found nearly everyone works with a base assumption that things can be done better. You get to directly or indirectly work on things that matter and inspire.</p>



<p>NASA needs and deserves top contractor staff, but sometimes it can be hard for people to find the door. The path in for civil servants is centralized and fairly well known with lots written about it. The contractor path is more fuzzy with lots of different doors.</p>



<h5>What &#8220;Type&#8221; of Contractor Role is It?</h5>



<p>Some contractors work onsite at NASA centers and are very integrated into the main NASA in terms of day to day meetings, culture, etc. Companies like Jacobs and S.A.I.C. employ many contractors that work onsite and are fairly embedded into the daily NASA work culture.</p>



<p>Others are mostly or entirely offsite, produce product X that meets requirements a, b, and c. These contractors work more for their contractor company in terms of culture, reporting, meetings, location, etc. Examples of companies that employe contractors that are more likely be slightly removed from the daily NASA work life include Boeing, SpaceX, and Lockheed Martin Corp.</p>



<h5>My Experience</h5>



<p>For context from 2016 to 2021 I worked as as <a href="/resume/">S.A.I.C. contractor for NASA</a> supporting the Office of Chief Information Officer Transformation and Data Division on open data, open code, code platform, data analytics, and machine learning tasks.</p>



<h2>Problem this document attempts to impact</h2>



<p><strong><em>There is no single site to go to for NASA contractor specific job searches.</em></strong></p>



<p>If you are looking for NASA civil servant jobs, there is https://www.usajobs.gov/ .</p>



<p>There are things that sorta approach being a contractor version of https://www.usajobs.gov/, like https://www.spacetalent.org/ , a job search site &#8220;for the space economy&#8221; but <a href="https://www.spacetalent.org/">space talent</a> has only a small percent of all NASA contractor companies advertising jobs on their site. Additionally, some of the companies advertising there are very adjacent to the aerospace industry to put it mildly.</p>



<p>Job search companies like https://www.indeed.com/ &amp; https://www.linkedin.com/ have gotten better at returning useful results when you type in &#8220;NASA&#8221; but they tend to rely on companies explicitly mentioning &#8220;NASA&#8221; in their job description and advertising on one of those sites. Many companies nearly never mention &#8220;NASA&#8221; in the job title and often don&#8217;t mention &#8220;NASA&#8221; in the body either, even if the job is 100% NASA contractor. </p>



<p><em>Hence, the search results for &#8220;NASA&#8221; or &#8220;NASA contractor&#8221; in most of the major job search websites don&#8217;t lead high quality results. The alternative is to find out who the NASA contract companies are and then search specifically for jobs with those companies.</em></p>



<h2>Who Are NASA Contractor Companies</h2>



<p><em>NOTE: If something in this list is outdated, please consider submitting a pull request or issue to <a href="https://github.com/JustinGOSSES/nasa-contractor-jobs-information">this </a>repository.</em></p>



<h3>Official Listings</h3>



<p>Every NASA center has a listing of the prime contractors somewhere on their public website. Where that list is located online and the format of it is highly variable.</p>



<p>Additionally, these lists often just list prime contractors. Most of the prime contractor have sub-contractors. The sub-contractors may not be listed on the lists of contractors that NASA puts out.</p>



<h3>NASA Center List of Prime Contractors</h3>



<h4>Johnson Space Center (Houston, Texas)</h4>



<p>EXCEL: <a href="https://www.nasa.gov/centers/johnson/about/people/contractorlist.html">https://www.nasa.gov/centers/johnson/about/people/contractorlist.html</a></p>



<h4>Marshal Space Center (Huntsville, Alabama)</h4>



<p>PDF: <a href="https://www.nasa.gov/centers/marshall/pdf/174803main_msfc_prime_contractors.pdf">https://www.nasa.gov/centers/marshall/pdf/174803main_msfc_prime_contractors.pdf</a></p>



<h4>Stennis Space Center (Hancock County, Mississippi)</h4>



<p>HTML: <a href="https://www.nasa.gov/centers/stennis/about/jobs/index.html">https://www.nasa.gov/centers/stennis/about/jobs/index.html</a></p>



<h4>Glenn Research Center (Cleveland, Ohio)</h4>



<p><a href="PDF: https://www.nasa.gov/sites/default/files/atoms/files/grc-local-contractor-listing-060321.pdf">PDF: https://www.nasa.gov/sites/default/files/atoms/files/grc-local-contractor-listing-060321.pdf</a></p>



<h4>Goddard Space Flight Center (Greenbelt, Maryland)</h4>



<p>HTML: <a href="https://www.nasa.gov/centers/goddard/business/foia/contracts.html">https://www.nasa.gov/centers/goddard/business/foia/contracts.html</a> (contracts not contract companies listed)</p>



<p><br>HTML: <a href="https://goddard-contractors-association.org/">https://goddard-contractors-association.org/</a></p>



<h4>Whallops Flight Facility (Wallops Island, Virginia)</h4>



<p>PDF: <a href="https://sites.wff.nasa.gov/code802/wff_prime_contractors.pdf">https://sites.wff.nasa.gov/code802/wff_prime_contractors.pdf</a></p>



<h4>Ames Research Center (Mountain View, California)</h4>



<p>HTML: <a href="https://www.nasa.gov/ames/aeronautics/jobs/contractors">https://www.nasa.gov/ames/aeronautics/jobs/contractors</a></p>



<h4>Armstrong Flight Research Center (Edwards Air Force Base, California)</h4>



<p>HTML: <a href="https://www.nasa.gov/centers/armstrong/employment/contractor-opportunities/index.html">https://www.nasa.gov/centers/armstrong/employment/contractor-opportunities/index.html</a></p>



<h4>Kennedy Space Flight Center (Merritt Island)</h4>



<p>PDF: <a href="https://procurement.ksc.nasa.gov/-/media/LSPKiosk/CIAO/KSC_Marketing_Guide.ashx?la=en&amp;hash=43CE38D5B618C88E54268D13E9CE597D">https://procurement.ksc.nasa.gov/-/media/LSPKiosk/CIAO/KSC_Marketing_Guide.ashx?la=en&amp;hash=43CE38D5B618C88E54268D13E9CE597D</a></p>



<h4>Mary W. Jackson NASA Headquarters (Washington, D.C.)</h4>



<p>COULD NOT FIND THIS ONE!!!!</p>



<h4>Jet Propulsion Laboratory (Los Angeles,California)</h4>



<p>Note that JPL is run by Caltech and everyone who works for JPL s a NASA contractor.</p>



<p>WEBSITE: <a href="https://www.jpl.jobs/">https://www.jpl.jobs/</a></p>



<h3>NASA-wide Contractor Lists</h3>



<h4>Unofficial</h4>



<ul><li>WIKIPEDIA: <a href="https://en.wikipedia.org/wiki/List_of_NASA_contractors">https://en.wikipedia.org/wiki/List_of_NASA_contractors</a></li><li>aeroweb: &#8220;NASA&#8217;s Top 100 Contractors&#8221;: <a href="WIKIPEDIA: https://en.wikipedia.org/wiki/List_of_NASA_contractorsaeroweb: &quot;NASA's Top 100 Contractors&quot;: http://fi-aeroweb.com/Top-100-NASA-Contractors.html">http://fi-aeroweb.com/Top-100-NASA-Contractors.html</a></li></ul>



<h4>Official</h4>



<ul><li>NASA contractors from usaspending.gov which requires a lot of button clicks to get to just NASA but possible: <a href="https://www.usaspending.gov/explorer/agency">https://www.usaspending.gov/explorer/agency</a></li><li>SAM.GOV : technically should have finer details than usaspending.gov but the site has horrible user interface so it in no way obvious what anything on the site does unless you sit through long videos classes on each button/report type. <a href="https://sam.gov/">https://sam.gov/</a></li></ul>



<h2>So….how do I use this information?</h2>



<p>I&#8217;ll start right out and say there isn&#8217;t a great answer to this. A few strategies are listed below.</p>



<h3>Option 1: Rely on Job Search Sites</h3>



<p>None of the job search sites that I know allow you to upload a list of company titles and say just give me the current jobs being advertised by those companies. This is unfortunate, as it would pretty much solve the problem, or at least 85% of the way to a solution.</p>



<p>The alternative is to use the advanced search functionality to at least focus on job descriptions with &#8220;NASA&#8221; or &#8220;johnson space center&#8221; mentioned somewhere in them. This does an alright job, but it certainly misses a lot as well.</p>



<p>Here is a link to indeed results for any job description with &#8220;nasa&#8221;: <a href="https://www.indeed.com/advanced_search?q=nasa&amp;l=">https://www.indeed.com/advanced_search?q=nasa&amp;l=</a></p>



<p>Here is a link to ineed results for any job description with &#8220;johnson space center&#8221;: <a href="https://www.indeed.com/advanced_search?q=johnson%20space%20center&amp;l=">https://www.indeed.com/advanced_search?q=johnson%20space%20center&amp;l=</a></p>



<p>The signal to noise ratio is better in the second option, but you might get more results in total with the first.</p>



<p><strong><em>IF YOU WANT A QUICK SOLUTION THAT DOESN&#8217;T REQUIRE A LOT OF MANUAL WORK OR TECH SKILS, THIS IS IT.</em></strong></p>



<p>However, it will miss a sizable percentage of the open and publicly advertised jobs.</p>



<h3>Option 2: Focus Your Search To A Few Companies &amp; Check Their Websites Directly</h3>



<p>You could limit your search to contractor companies that are listed as the prime contractor at the center nearest to you. You could also limit it to companies listed on the NASA center&#8217;s prime contractor list as doing work related to the type of job you&#8217;re interested in. Some but not all of the center lists also detail what types of work each contractor company is responsible for hiring. A little sleuthing might even get you what NASA orgs each some of the contractors support.</p>



<p>At the end, you might narrow things down to 5-15 companies whose job sites you can check manually every week or so.</p>



<p>This takes a lot of time but it would give you good, if potentially too focused, coverage across open NASA contractor jobs.</p>



<h3>Option 3: Can you Extend Job Sites Via API?</h3>



<p>You might wonder why someone doesn&#8217;t just automate this process into their own NASA contractor specific job site?</p>



<p>The short answer is job sites like Indeed and others seem to have been moving away from making their APIs easily accessible and reusable for this purpose. They want job seekers to go to their site directly it seems.</p>



<p>For example, LinkedIN has information on their APIs here: https://developer.linkedin.com/ but it doesn&#8217;t look like any of these are really geared to job searchers or webpages that are built for job searchers. Google results will return tutorials and examples of developers using Indeed&#8217;s API, but they are mostly all from 2014-2018 and use an API now depreciated.</p>



<p>If you&#8217;re really want to build on top of results coming from job search sites, it looks like, at least currently, you&#8217;re limited to building web scrapers to extract the content from these sites. There&#8217;s a bunch of people who have done that, of course, but it can be dubious from a copyright and legal standpoint, especially if expressly forbidden by the site&#8217;s terms and conditions.</p>



<h3>Option 4: Programmatic Extracting of Job Information from Contractor Websites Directly</h3>



<p>Another option that I haven&#8217;t seen done but theoretically could be done is you build your own clone of indeed/LinkedIN that uses web scraping to get data from each contractor&#8217;s career page.</p>



<p>The obvious disadvantages of this approach is it takes a lot of work. You&#8217;d have to build a scraper and adapt it to each contractor company&#8217;s career page. You&#8217;d then have to normalize the content and display it on your own front-end. You&#8217;d probably want to build in some sort of automated re-generation that would run the scraper every day or so and re-populate your webpage. Additionally, any time a contractor company changed their career page, you&#8217;d have to re-write that portion of your code. There would also be some company&#8217;s career pages that have techniques in place to block bots, which is what your scraper would be.</p>



<p>The main benefit of this approach is it is the only method that would get you all the jobs from NASA contractors that you&#8217;re interested in on a regular basis.</p>



<p>Theoretically, you could even put ads on the site to attempt to recoup some of your costs from building and maintaining the site. This is one of <a href="https://github.com/JustinGOSSES/sideproject_planning">my side project ideas</a> that I&#8217;ve never done. A big question for me is how much time it would continuously take to maintain even if you did build it.</p>



<p>If it still seems tempting, here&#8217;s a link to the XKCD cartoon <a href="https://xkcd.com/1205/">&#8220;Is It Worth The Time&#8221;</a>.</p>



<h2>Other Related Information</h2>



<h3>Internships</h3>



<p>For interns wanted to intern at NASA, please note that there are basically 3 types of interns:</p>



<ul><li>interns for the various contractor companies</li><li>interns for USRA, which is a comapny that manages most of the NASA interns on behalf of NASA. This is the way most students intern.</li><li>Pathways internships. These are basically interning for NASA, aka the federal government directly. Students that get hired out of school for NASA do several pathways internships before becoming normal civil servants. It seems common to do a USRA internship first and then get a Pathways intern later.</li></ul>



<p>WARNING: None of the information above may be accurate at some point in future time and it certainly isn&#8217;t comprehense.</p>



<h4>Accrediation Trap for Pathways Interns</h4>



<p>Also, please note that there are many pathways internship positions where your school must have an accrediated engineering program and there is only one accrediation agency allowed. This rule has in the past been applied for positions like a Pathways computer science internship where the required major (computer science) wouldn&#8217;t normally be considered an engineering major. I known of several students who didn&#8217;t realize their school made them ineligible for pathways interns until it was too late to change schools. I know one who changed schools because of it.</p>



<h3>Remote NASA Contractor Jobs</h3>



<p><em>A caveat up front is that the job market around remote work is still evolving quickly. What is said below is based on limited exprience in 2020-2021.</em></p>



<p>Some NASA contractor jobs will now explicitly say in the job advertisement that they are remote friendly. This is getting more common to see even if it is still rare overall. I&#8217;ve started to see language like &#8220;this job is onsite at <em>_</em> &#8221; to convey that a job is not remote friendly, but it seems the standard language is still developing.</p>



<p>There are many more positions that are possible to work remotely that won&#8217;t say anything about it in the job description. This can be because they&#8217;d prefer a local candidate if possible or because no one thought ot write it into the job description. The HR contact listed probably won&#8217;t know if a position is remote. When asking them via email, a good tactic can be to not just ask them but ask them to ask the hiring manager. Otherwise, they&#8217;ll likely just repeat what&#8217;s already written in the advertisement.</p>



<p>Organizations that cross multiple NASA centers and don&#8217;t deal with anything physical are more likely to be supportive of remote work.</p>



<p>Be aware that, even if a position is remote friendly, there will likely be a need for you to come to a NASA center at the beginning of the role for finger printing and other activities. Many positions require you to be onsite several times a year or within driving distance. Sometimes companies won&#8217;t like to hire someone brand new hundreds miles away, but they&#8217;re okay with existing employees being that far away. Remote can mean different things. It is very much a &#8220;it depends&#8221; situation.</p>



<h3>Can Foreign Nationals be NASA Contractors</h3>



<p>This has been a common question when I&#8217;ve posted positions in certain Slack channels.</p>



<p>I&#8217;ll have to give a hand wavy answer here based on my both my limited knowledge, the limted public documentation on this question, and the extent to which the answer really just depends on position specific things you might have no way of knowing from the outside.</p>



<p>In general, most of the time, no. In special circumstances, yes.</p>



<p>Usually, the position description will include this information, but it is not included one hundred percent of the time.</p>



<p>JPL (Jet Propulsion Laboratory) has foreign nationals working for it. However, not all jobs there can be worked by foreign nationals. That being said, if you want to have a good chance of finding a NASA job that can accept foriegn nationals, JPL is probably your best bet in terms of both scale and percentages.</p>



<p>Similarly, other science facilities run by another organization on behalf of NASA are generally more likely on average to accept foreign national applicants. JPL is by far the biggest of those.</p>



<p>Where it gets very unlikely (but not 100% impossible) that a position will accept foreign national applicants is positions that are either onsite at a physical locality where there are rockets, testing, engineering, or space communications or where you might have easier &#8220;IT&#8221; access to those things.</p>



<p>Again, this is very hand wavy and just observations. These aren&#8217;t rules or guidelines. Don&#8217;t depend on any of these vague generalizations being correct.</p>



<p></p>



<p>Good luck!</p>
]]></content:encoded>
					
					<wfw:commentRss>/finding-a-nasa-contractor-job/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>What if Awesome Lists weren&#8217;t just lists, but enabled views of the open source community?</title>
		<link>/what-if-awesome-lists-werent-just-lists-but-enabled-views-of-the-open-source-community/</link>
					<comments>/what-if-awesome-lists-werent-just-lists-but-enabled-views-of-the-open-source-community/#respond</comments>
		
		<dc:creator><![CDATA[Justin]]></dc:creator>
		<pubDate>Tue, 01 Jun 2021 03:34:52 +0000</pubDate>
				<category><![CDATA[code]]></category>
		<category><![CDATA[awesome]]></category>
		<category><![CDATA[d3.js]]></category>
		<category><![CDATA[data-visualization]]></category>
		<category><![CDATA[GitHub]]></category>
		<category><![CDATA[Open-Source]]></category>
		<category><![CDATA[Reuse]]></category>
		<guid isPermaLink="false">https://54.87.153.110/?p=1392</guid>

					<description><![CDATA[Awesome lists are…. awesome. But could they be even more useful? What if instead of just a curated list you also got a view into a wider community? NOTE 1: this is was also written up on Medium and is described from a slightly different perspective in these slides on<a class="moretag" href="/what-if-awesome-lists-werent-just-lists-but-enabled-views-of-the-open-source-community/"> Read more&#8230;</a>]]></description>
										<content:encoded><![CDATA[
<p><em>Awesome lists are…. awesome. But could they be even more useful? What if instead of just a curated list you also got a view into a wider community?</em></p>



<blockquote class="wp-block-quote"><p>NOTE 1:  this is was also written up on <a href="https://justingosses.medium.com/beyond-awesome-lists-3ccb074f7859">Medium</a> and is described from a slightly different perspective in <a href="https://observablehq.com/@justingosses/more-visible-connections-between-projects-can-nudge-devel">these slides</a> on Observable.</p><p>NOTE 2: Since writing this blog post, I&#8217;ve continued working on this idea and  <a href="https://github.com/JustinGOSSES/awsome-list-visual-explorer-template">made a reusable template</a> that you can use to start a new code repository, change a few lines in a configuration file, run two scripts, and get a whole new website with interactive visualizations to help you understand the code community documented in an Awesome List.</p></blockquote>



<h2 id="8747">What is an Awesome list?</h2>



<p id="dd3d">An Awesome List is a community curated list of code projects within a specific domain, application, or use case. You can read more in the “<a href="https://github.com/sindresorhus/awesome/blob/main/awesome.md">Awesome Manifesto</a>” on&nbsp;<a href="https://github.com/sindresorhus">sindresorhus</a>/<a href="https://github.com/sindresorhus/awesome">awesome</a>.</p>



<p><a href="https://54.87.153.110/what-if-awesome-lists-werent-just-lists-but-enabled-views-of-the-open-source-community/">View Post</a></p>



<p id="ceaf">They are great places to first look for open&nbsp;source code projects that others have found highly use in your problem space, be it markdown editors, JavaScript data visualization, Jupyter notebook widgets, GraphQL, spatial analysis, robotics, or&nbsp;<a href="https://project-awesome.org/phillipadsmith/awesome-github">hundreds</a>&nbsp;of other things. Other places people might discover code are word of mouth, google searches, trolling GitHub, seeing the packages used in other code, or having it recommended by a mentor or peer.</p>



<blockquote class="wp-block-quote"><p><em>Searching for useful code projects is an investment of time. Anything that shortens that time, and enables a developer to reuse code instead of starting from scratch, offers big rewards in terms of time savings.</em></p></blockquote>



<h2 id="ac5f">What Makes Awesome Lists so Successful?</h2>



<p id="4e6a">This is mostly guesswork on my part, but I’d say the success of the “Awesome List” form is some combination of the following characteristics:</p>



<ol><li><strong>Easy to start</strong>&nbsp;(<em>Start a repository with a single README.md file</em>)</li><li><strong>Easy to contribute</strong>&nbsp;to (<em>Edit a single line in a markdown file</em>)</li><li><strong>Fills a need</strong>&nbsp;(E<em>very developer searches for new code tools)</em></li><li><strong>Builds a community</strong>&nbsp;(<em>They have a very large number of contributors. People come back to check the list from time to time. People send links to it to others.</em>)</li></ol>



<h2 id="5b41">What do Awesome Lists Not do Well?</h2>



<p id="6908">As a curated list, they provide a signal of potential value. To be included on an Awesome List, someone has to say a project is “Awesome”.</p>



<p id="a9d8">However, there are a variety of other types of information that would useful to know when evaluating what code project to use or what project to contribute to that Awesome Lists don’t provide. They include:</p>



<ol><li>How popular each code project is?</li><li>Is the rate this new code project is growing in popularity unusual relative to similar code projects in the past?</li><li>What code projects are used by other code projects within the domain space as a dependency and therefore you might want to learn about?</li><li>What code projects share dependencies and probably do related things?</li><li>What code projects share contributors?</li><li>What organizations own the most code projects in that domain/problem/solution space?</li></ol>



<blockquote class="wp-block-quote"><p><em>The interesting thing is, the information to get at all these questions exists, it just doesn’t exist in an easy to access to form most of the time.</em></p></blockquote>



<p id="3a21">All of the questions above can be answered with metadata extracted via GitHub’s or Gitlab’s API. Even the dependency information, which was hard to get at several years ago, is now extracted by code platforms are a service and available from their APIs.</p>



<h2 id="3a57">Lawerence Livermore National Laboratory’s Software Catalog’s Explore Pages</h2>



<p id="aa53">A great example of harvesting this type of metadata using GitHub’s API and turning it into insightful visualizations is the&nbsp;<a href="https://software.llnl.gov/">explore&nbsp;</a>section of Lawerence Livermore National Laboratory’s Software (LLNL) Catalog.</p>



<p id="e697"><strong>Wanting to understand similar relationships for subsurface geoscience code, I decided to adapt LLNL’s project such that instead of visualization Lawerence Livermore National Laboratory’s code catalog, it was visualizing the code curated in&nbsp;</strong><a href="https://softwareunderground.org/"><strong>Software Underground</strong></a><strong>’s&nbsp;</strong><a href="https://github.com/softwareunderground/awesome-open-geoscience"><strong>Awesome-Open-Geoscience</strong></a><strong>&nbsp;awesome list.</strong></p>



<p id="c51c">The Awesome-Open-Geoscience awesome list was started by myself and several other members of&nbsp;<a href="https://softwareunderground.org/">Software Underground</a>, or SWUNG, in October of 2017. As of May 2021, it has 127 watchers, 720 stars, and 51 different contributors. It the most popular repository if you search “geoscience” on GitHub.com.</p>



<p id="7c70">Adapting&nbsp;<a href="https://github.com/LLNL/llnl.github.io">llnl.github.io</a>&nbsp;to make&nbsp;<a href="https://github.com/softwareunderground/open_geosciene_code_projects_viz">open_geosciene_code_projects_viz</a>&nbsp;wasn’t as easy as cloning it and re-running a script as the repository is less a tool and more a product. I had to remove lots of LLNL specific content, edit file paths, and replace bits of html, CSS, and JavaScript throughout the project. There’s still some work to get it to a place to where anyone else with a list of repositories they want to understand could clone the repository, change some lines in a configuration file, re-run a few scripts, and deploy as a GitHub pages page, but it’s getting there. Switching it from LLNL to SWUNG took me several days of work. Switching it for SWUNG to something else took me less than a day.</p>



<blockquote class="wp-block-quote"><p><em>Ideally, it would great if it only take a couple hours of work to repopulate all the pages and visualizations for another Awesome list.</em></p></blockquote>



<h2 id="67d9">Visualizations that show the community connections across the repositories curated in an Awesome List</h2>



<p class="has-text-align-center" id="5069"><strong><em>Beyond “curated list” and into “community level view”</em></strong></p>



<p id="c69b">The visualizations father down are static images, but the first one is an iframe embed. Most of the visualizations are interactive so best explored on the actual&nbsp;<a href="https://softwareunderground.github.io/open_geosciene_code_projects_viz/">website</a>. The data visualizations allow for many questions to answered that provide a community level view of the code projects curated on the Awesome list.</p>



<div class="wp-block-image is-style-default"><figure class="aligncenter size-large is-resized"><img loading="lazy" src="http://54.87.153.110/wp-content/uploads/2021/05/image-1024x439.png" alt="" class="wp-image-1403" width="1024" height="439" srcset="/wp-content/uploads/2021/05/image-1024x439.png 1024w, /wp-content/uploads/2021/05/image-300x129.png 300w, /wp-content/uploads/2021/05/image-768x329.png 768w, /wp-content/uploads/2021/05/image-1536x659.png 1536w, /wp-content/uploads/2021/05/image-2048x879.png 2048w" sizes="(max-width: 1024px) 100vw, 1024px" /></figure></div>



<p class="has-text-align-center" id="5721"><em>How often does a new code project in this space appear? How old are the older ones?</em></p>



<div class="wp-block-image is-style-default"><figure class="aligncenter size-large is-resized"><img loading="lazy" src="http://54.87.153.110/wp-content/uploads/2021/05/image-1-1024x429.png" alt="" class="wp-image-1404" width="781" height="326" srcset="/wp-content/uploads/2021/05/image-1-1024x429.png 1024w, /wp-content/uploads/2021/05/image-1-300x126.png 300w, /wp-content/uploads/2021/05/image-1-768x322.png 768w, /wp-content/uploads/2021/05/image-1-1536x644.png 1536w" sizes="(max-width: 781px) 100vw, 781px" /></figure></div>



<p class="has-text-align-center" id="3dbd"><em>How fast are people starting this new project versus older projects?</em></p>



<p class="has-text-align-center" id="69b8"><em>Has the number of new stars flatlined as people migrate to a new project?</em></p>



<figure class="wp-block-image size-large is-resized is-style-default"><img loading="lazy" src="http://54.87.153.110/wp-content/uploads/2021/05/image-2-1024x399.png" alt="" class="wp-image-1405" width="767" height="298" srcset="/wp-content/uploads/2021/05/image-2-1024x399.png 1024w, /wp-content/uploads/2021/05/image-2-300x117.png 300w, /wp-content/uploads/2021/05/image-2-768x299.png 768w, /wp-content/uploads/2021/05/image-2-1536x598.png 1536w, /wp-content/uploads/2021/05/image-2.png 2044w" sizes="(max-width: 767px) 100vw, 767px" /></figure>



<p class="has-text-align-center" id="0f08"><em>What are the most common languages within this Awesome list?</em></p>



<p class="has-text-align-center" id="2f05"><em>What topics are the most common across all projects?</em></p>



<figure class="wp-block-image size-large is-resized is-style-default"><img loading="lazy" src="http://54.87.153.110/wp-content/uploads/2021/05/image-3-1024x612.png" alt="" class="wp-image-1406" width="735" height="438" srcset="/wp-content/uploads/2021/05/image-3-1024x612.png 1024w, /wp-content/uploads/2021/05/image-3-300x179.png 300w, /wp-content/uploads/2021/05/image-3-768x459.png 768w, /wp-content/uploads/2021/05/image-3-1536x918.png 1536w, /wp-content/uploads/2021/05/image-3-2048x1224.png 2048w" sizes="(max-width: 735px) 100vw, 735px" /></figure>



<p class="has-text-align-center" id="0a06"><em>What organization or developer owns the most projects on the Awesome list?</em></p>



<p class="has-text-align-center" id="63e9"><em>What projects only have contributions from the code owners vs. contributions from many external parties and therefore might be better places to submit a pull request?</em></p>



<figure class="wp-block-image size-large is-resized is-style-default"><img loading="lazy" src="http://54.87.153.110/wp-content/uploads/2021/05/image-4-1024x395.png" alt="" class="wp-image-1407" width="726" height="279" srcset="/wp-content/uploads/2021/05/image-4-1024x395.png 1024w, /wp-content/uploads/2021/05/image-4-300x116.png 300w, /wp-content/uploads/2021/05/image-4-768x296.png 768w, /wp-content/uploads/2021/05/image-4-1536x593.png 1536w, /wp-content/uploads/2021/05/image-4-2048x790.png 2048w" sizes="(max-width: 726px) 100vw, 726px" /></figure>



<p class="has-text-align-center" id="9959">Has activity jumped around a conference or other event?</p>



<figure class="wp-block-image size-large is-resized is-style-default"><img loading="lazy" src="http://54.87.153.110/wp-content/uploads/2021/05/image-5-1024x520.png" alt="" class="wp-image-1408" width="735" height="373" srcset="/wp-content/uploads/2021/05/image-5-1024x520.png 1024w, /wp-content/uploads/2021/05/image-5-300x152.png 300w, /wp-content/uploads/2021/05/image-5-768x390.png 768w, /wp-content/uploads/2021/05/image-5-1536x780.png 1536w, /wp-content/uploads/2021/05/image-5-2048x1040.png 2048w" sizes="(max-width: 735px) 100vw, 735px" /></figure>



<p class="has-text-align-center" id="00bb"><em>What projects on the Awesome list are used as a dependency by other projects on the Awesome list?</em></p>



<p class="has-text-align-center" id="0ad1"><em>Where to make contributions such that your code is reused by the highest number of projects?</em></p>



<p class="has-text-align-center" id="0ebd"><em>What projects are built entirely different than the norm?</em></p>



<p class="has-text-align-center" id="9bbb"><em>What projects is it more likely you could jump in and contribute to as the dependencies are already very similar to your existing work?</em></p>



<figure class="wp-block-image size-large is-resized is-style-default"><img loading="lazy" src="http://54.87.153.110/wp-content/uploads/2021/05/image-6-1024x790.png" alt="" class="wp-image-1409" width="760" height="586" srcset="/wp-content/uploads/2021/05/image-6-1024x790.png 1024w, /wp-content/uploads/2021/05/image-6-300x232.png 300w, /wp-content/uploads/2021/05/image-6-768x593.png 768w, /wp-content/uploads/2021/05/image-6-1536x1185.png 1536w, /wp-content/uploads/2021/05/image-6.png 1866w" sizes="(max-width: 760px) 100vw, 760px" /></figure>



<p class="has-text-align-center" id="a792"><em>Picking a license can be hard. Is there a pattern in terms of what others in your community have gone with? Can you use this to help guide your choice?</em></p>



<h2 id="f3a0">Additional Questions that Could be Answered that Would “Nudge” Developers</h2>



<p id="7aba">As you might have already concluded from the questions that the visualizations help answer above, visualizing these type of information can nudge developers in ways the help direct development activity. This means visualizing the community of open source subsurface geoscience code has the potential to change how it develops in small ways. Thinking about it in this framing also helps suggest what future visualizations might have value.</p>



<p id="f751"><strong>Connection that could be made visible…&nbsp;</strong>What repositories share dependencies and therefore do somewhat similar stuff?&nbsp;<strong>…which could nudge&nbsp;</strong>developers to understand code as related groups and not hundreds of non-related entities</p>



<p id="6dd9"><strong>Connection that could be made visible…&nbsp;</strong>What code projects are used by projects I care about?&nbsp;<strong>…which could nudge&nbsp;</strong>developers to contribute to repositories that more people/projects depend on.</p>



<p id="5d7d"><strong>Connection that could be made visible…&nbsp;</strong>Do you and someone else contribute to the same repos? Is there a group of people that tend to contribute to the same repos?<strong>…which could nudge&nbsp;</strong>developers to reach out to specific people forming community.</p>



<h2 id="2936">The tech stack to get “Community Level View” from “Curated List”</h2>



<p id="c740"><em>So is this code at a place where anyone with an Awesome List, software catalog, or other type of list of repositories could easily re-run and deploy their own version?</em></p>



<p id="cc0e"><em>Unfortunately,&nbsp;</em><strong><em>Not yet.</em></strong></p>



<p id="5a9f">As noted above, converting the existing LLNL software catalog into&nbsp;<a href="https://github.com/softwareunderground/open_geosciene_code_projects_viz">open_geoscience_code_projects_visualization</a>&nbsp;took a while. It was started during a&nbsp;<a href="https://softwareunderground.org/events/transform-2021">hackathon</a>&nbsp;but probably took 2–3 days of full time work. The current version is easier to adapt to another list but it would probably take at least a full day for someone unfamiliar with the code base. Additionally, repositories aren’t being pulled directly from the Awesome List programmatically, so any additions in the Awesome List would need to be added manually currently.</p>



<p id="96a4">We can talk about possible futures, though.</p>



<blockquote class="wp-block-quote"><p><em>In an ideal world, it would be easy and quick to take an existing Awesome Lists and create all these visualizations for the repositories categorized on that list. The visualizations would also stay up to date with the Awesome List.</em></p></blockquote>



<p id="8778"><strong>Future Requirements:</strong></p>



<ol><li>An Awesome List scrapper to pull out GitHub repository links. [<em><a href="updated: don">done</a></em>]</li><li>A GitHub Actions script to do number 2 above and popular the input_list.json file of all the repositories to be visualized. This could be scheduled to check for updates on some interval. [<em>updated: done</em>]</li><li>Documentation for how to easily add new or update existing visualizations in the explore section pages, such that changes can be easily integrated into already deployed forks. [<em>No work done on this yet</em>]</li><li>Remove more of the list specific content in HTML and Markdown files and have it instead be populated programmatically from the key:value pairs in the _config.yml file in order to get the initial deployment down to a couple hours from several days. [<em>updated: this is 90% complete in <a href="https://github.com/JustinGOSSES/awsome-list-visual-explorer-template">this new template repository</a></em>]</li></ol>



<p id="8e44">More thoughts on this can be found in&nbsp;<a href="https://github.com/softwareunderground/open_geosciene_code_projects_viz">this</a>&nbsp;markdown file.</p>



<h2 id="ace2">How You Can Contribute</h2>



<p id="3b71">Since writing this blog post, I&#8217;ve made a reusable template repository at <a href="https://github.com/JustinGOSSES/awsome-list-visual-explorer-template">https://github.com/JustinGOSSES/awsome-list-visual-explorer-template</a>. You can use it to start a new repository, change a few lines in a configuration file, run two scripts, and a whole new website with visualizations to help you understand the code community documented in an Awesome List will be created. <br><br><a href="https://github.com/JustinGOSSES/awsome-list-visual-explorer-template">This</a> is still in beta, so there is lots to contribute towards in terms of making it easy and obvious how to use. </p>



<p></p>
]]></content:encoded>
					
					<wfw:commentRss>/what-if-awesome-lists-werent-just-lists-but-enabled-views-of-the-open-source-community/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>Visualizing Well Logs on the web with Wellio &#038; Wellioviz</title>
		<link>/wellio-wellioviz/</link>
					<comments>/wellio-wellioviz/#respond</comments>
		
		<dc:creator><![CDATA[Justin]]></dc:creator>
		<pubDate>Wed, 13 Jan 2021 03:04:08 +0000</pubDate>
				<category><![CDATA[code]]></category>
		<category><![CDATA[geology]]></category>
		<guid isPermaLink="false">https://54.87.153.110/?p=1348</guid>

					<description><![CDATA[Wellio &#38; Wellioviz are open source JavaScript libraries for converting LAS well log files into JSON and viewing them in the browser. Why? Like many side projects, they were built around the idea that certain experiences could be a little bit better. A number of government sites provide open-source well<a class="moretag" href="/wellio-wellioviz/"> Read more&#8230;</a>]]></description>
										<content:encoded><![CDATA[
<p><a href="https://github.com/JustinGOSSES/wellio.js">Wellio</a> &amp; <a href="https://github.com/JustinGOSSES/wellioviz">Wellioviz</a> are open source JavaScript libraries for converting LAS well log files into JSON and viewing them in the browser.</p>



<h3>Why?</h3>



<p>Like many side projects, they were built around the idea that certain experiences could be a little bit better.</p>



<p>A number of government sites provide open-source well log data in LAS format. To find out what&#8217;s in a LAS file though, you usually have to download the files and view them with proprietary products or open-source Python tools like <a href="https://github.com/kinverarity1/lasio">Lasio</a> &amp; <a href="https://github.com/agile-geoscience/welly">Welly</a>. But what if you just want to take a quick look to figure out if the data&#8217;s useful to your purpose? What if you don&#8217;t have proprietary tools or know Python? You&#8217;re out of luck. This is what prompted initial development of wellio and then wellioviz. </p>



<div class="wp-block-image"><figure class="aligncenter size-large"><img src="https://raw.githubusercontent.com/JustinGOSSES/wellioviz/release/docs/images/well_log_screenshot_new.png" alt=""/><figcaption>Image of what wellioviz produces.</figcaption></figure></div>



<h3>Demos</h3>



<p>The demo webpage at the button below lets you visualize any well log available from a link with only a browser. Nothing to download or learn. Example data sites with well logs in LAS 2.0 format are provided from USGS and Kansas Geological Survey. It is built into a Observable notebook, which is similar to a jupyter notebook, but all the code is live by default.</p>



<button style="background-color:#008CBA; color:white;padding:1em;align:right;margin-bottom:2em;!important"><a href="https://observablehq.com/@justingosses/a-notebook-using-wellio-js-wellioviz-js-for-quick-looks-of-la" style="color:white;">Go to Demo for Viewing Well Logs from Government Sites</a></button>



<p>There&#8217;s also a demo built into the docs for wellioviz.js. This demo either uses a default LAS 2.0 format well log embedded in the website or lets you upload a LAS file from your local computer. As it is only a front-end site, none of the data goes to a server. Everything stays in your browser. </p>



<button style="background-color:#008CBA; color:white;padding:1em;align:right;margin-bottom:2em;!important"><a href="https://observablehq.com/@justingosses/a-notebook-using-wellio-js-wellioviz-js-for-quick-looks-of-la" style="color:white;">Demo with an embedded well or upload a well from your computer</a></button>



<figure class="wp-block-image size-full is-resized is-style-default"><img loading="lazy" src="http://54.87.153.110/wp-content/uploads/2021/01/wellioviz_demo.png" alt="" class="wp-image-1352" width="579" height="546" srcset="/wp-content/uploads/2021/01/wellioviz_demo.png 976w, /wp-content/uploads/2021/01/wellioviz_demo-300x283.png 300w, /wp-content/uploads/2021/01/wellioviz_demo-768x726.png 768w" sizes="(max-width: 579px) 100vw, 579px" /><figcaption>Screenshot of the demo page in wellioviz docs.</figcaption></figure>



<div class="wp-block-jetpack-markdown"><h3>Development</h3>
</div>



<p>Wellio and Wellioviz both had a similar history in terms of getting unexpectedly far in a single weekend and taking a lot more time in small chunks over a long period to get where they are now. Both are side projects, to be sure, but are at a stage where they can be built into other projects. </p>



<p>Both have open source licenses and have been improved through the technical contributions of others beyond myself. <a href="https://github.com/dcslagel">DC Slagel</a> and <a href="https://github.com/nathangeology">nathangeology</a> have made substantial contributions. You can find the full list of contributors on the repos themselves. The main contributors to the most used python libraries in this space, LASIO (<a href="https://github.com/kinverarity1">kinverarity1</a>), and Welly  (<a href="https://github.com/">kwinkunks</a>) have been great at providing examples of &#8220;bad&#8221; wells, workflow examples, and loose coordination. Wellioviz received a lot of helpful attention in a <a href="https://softwareunderground.org/">SoftwareUnderground</a>&#8216;s online hackathon/conference/thing in mid 2020 called <a href="https://softwareunderground.org/blog/2020/6/29/the-transform-2020-hackathon-part-1">Transform2020</a>. Wellioviz was pushed from initial proof-of-concept to working package via a little funding from parties that wish to remain anonymous using <a href="https://github.com/sponsors">GithubSponsors</a>.</p>



<p>If you would like to help develop them further, please check out the &#8220;contributing&#8221; sections of the documentation for <a href="https://github.com/JustinGOSSES/wellio.js">wellio</a> and <a href="https://justingosses.github.io/wellioviz/#contributing">wellioviz</a>  on Github. If you&#8217;d like to learn more about parsing text with JavaScript, wellio is a good project to contribute to. In comparison, Wellioviz would be a good place to learn if you want to dive into JSON templates or visualization via d3.js. Both projects have issues tagged as good for beginners and an active backlog of issues. </p>



<p></p>
]]></content:encoded>
					
					<wfw:commentRss>/wellio-wellioviz/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>Creating New Metadata from Old Metadata Using Machine-Learning: A Poster Presentation at American Geophysical Union Conference 2019</title>
		<link>/creating-new-metadata-from-old-metadata-using-machine-learning-a-poster-presentation-at-american-geophysical-union-conference-2019/</link>
					<comments>/creating-new-metadata-from-old-metadata-using-machine-learning-a-poster-presentation-at-american-geophysical-union-conference-2019/#respond</comments>
		
		<dc:creator><![CDATA[Justin]]></dc:creator>
		<pubDate>Thu, 12 Dec 2019 01:44:44 +0000</pubDate>
				<category><![CDATA[code]]></category>
		<guid isPermaLink="false">https://54.87.153.110/?p=1267</guid>

					<description><![CDATA[Recently I was able to present at the American Geophysical Union&#8217;s annual conference. Not everything I work on is as easily made public, so this was a nice chance to share some of the team&#8217;s work and have good discussions with others working similar problems across multiple federal agencies, academia,<a class="moretag" href="/creating-new-metadata-from-old-metadata-using-machine-learning-a-poster-presentation-at-american-geophysical-union-conference-2019/"> Read more&#8230;</a>]]></description>
										<content:encoded><![CDATA[<p>Recently I was able to present at the American Geophysical Union&#8217;s annual conference. Not everything I work on is as easily made public, so this was a nice chance to share some of the team&#8217;s work and have good discussions with others working similar problems across multiple federal agencies, academia, and the public.</p>
<p>[gview file=&#8221;http://54.87.153.110/wp-content/uploads/2019/12/GOSSES_IN23D-0898_AGU_2019_POSTER_final.pdf&#8221;]</p>
<p>&nbsp;</p>
<p>The theme of the poster session I presented under was:</p>
<p style="text-align: center;"> <b>Achieving the &#8220;R&#8221; of the FAIR Data Principles: Reusability Is the Biggest Challenge but the Most Rewarding! </b></p>
<p>F.A.I.R. principles refer to the following:</p>
<p><strong>To be Findable:</strong></p>
<p>F1. (meta)data are assigned a <u>globally unique and eternally persistent identifier.</u><br />
F2. data are described with <u>rich metadata.</u><br />
F3. (meta)data are <u>registered or indexed in a searchable resource.</u><br />
F4. metadata <u>specify</u> the data identifier.</p>
<h4><strong>TO BE ACCESSIBLE:</strong></h4>
<p>A1  (meta)data are <u>retrievable by their identifier</u> using <u>a standardized communications protocol.</u><br />
A1.1 the <u>protocol</u> is open, free, and universally implementable.<br />
A1.2 the <u>protocol </u>allows for an authentication and authorization procedure, where necessary.<br />
A2 <u>metadata are accessible</u>, even when the data are no longer available.</p>
<h4><strong>TO BE INTEROPERABLE:</strong></h4>
<p>I1. (meta)data use a<u> formal, accessible, shared, and broadly applicable language</u> for knowledge representation.<br />
I2. (meta)data use <u>vocabularies that follow FAIR principles.</u><br />
I3. (meta)data include <u>qualified references</u> to other (meta)data.</p>
<h4><strong>TO BE RE-USABLE:</strong></h4>
<p>R1. meta(data) have a <u>plurality of accurate and relevant attributes.</u><br />
R1.1. (meta)data are released with a<u> clear and accessible data usage license.</u><br />
R1.2. (meta)data are associated with their <u>provenance.</u><br />
R1.3. (meta)data <u>meet domain-relevant community standards.</u></p>
<p>Our poster discussed two different projects we did to improve the F of F.A.I.R, &#8220;to be findable&#8221; by reusing metadata to create new metadata.</p>
<h3>Data.nasa.gov</h3>
<p>As described in the poster above, one of these focused on data.nasa.gov and was a failure due to our inability to routinely get an accurate download link across all tens of thousands of the datasets on data.nasa.gov. Data.nasa.gov ingests metadata about datasets from over 80 different NASA data sites. Although the standard required metadata fields on data.nasa.gov include &#8220;download link&#8221; many of the URLs in that field are actually to a front-page or a page where one link out of 50 links on the page is the download link. These limitations are minor for humans, but insurmountable if you&#8217;re trying to automate web scraping across 80+ sites.</p>
<p><em>If we had been able to programaticly get direct links to download each file</em>, our plan would have been to download files, run a series of Python profiling script to generate descriptions of files in terms of file type, file size, number of instances, etc. From these metadata, we had the idea that we could create a model to identify which datasets would be better for the general public and which would have been better scientists and other high-end end-users. We wanted to have this ability, because many of the people that land on data.nasa.gov from google are general public users who are interested simple easy to use NASA data. Most of the datasets on data.nasa.gov are large or complicated datasets, so those results tend to swamp the small, easy datasets that would actually be useful for the majority of the people who land on data.nasa.gov.</p>
<h3>Code.nasa.gov</h3>
<p>The other was focused on creating new and better keyword tags for the open-source code projects listed on code.nasa.gov. This was a success! You can see the keywords created by the machine-learning model on code.nasa.gov right now. Links on the poster further describe the model. Anthony Buonomo did the heavy lifting on the STI tagger model.</p>
<p>&nbsp;</p>
]]></content:encoded>
					
					<wfw:commentRss>/creating-new-metadata-from-old-metadata-using-machine-learning-a-poster-presentation-at-american-geophysical-union-conference-2019/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>Predictatops</title>
		<link>/predictatops/</link>
					<comments>/predictatops/#respond</comments>
		
		<dc:creator><![CDATA[Justin]]></dc:creator>
		<pubDate>Sat, 10 Aug 2019 20:34:18 +0000</pubDate>
				<category><![CDATA[code]]></category>
		<category><![CDATA[geology]]></category>
		<category><![CDATA[Canada]]></category>
		<category><![CDATA[Geology]]></category>
		<category><![CDATA[McMurray]]></category>
		<category><![CDATA[Predicatops]]></category>
		<category><![CDATA[python]]></category>
		<category><![CDATA[Sphinx]]></category>
		<category><![CDATA[stratigraphy]]></category>
		<guid isPermaLink="false">https://54.87.153.110/?p=1217</guid>

					<description><![CDATA[Stratigraphic pick prediction via supervised machine-learning: Predictatops Back in May, I presented a talk at the 2019 AAPG ACE (American Association of Petroleum Geologist Annual Conference and Exhibit) on using machine-learning to predict stratigraphic surfaces in well logs. I described a Python package I have been working on as a<a class="moretag" href="/predictatops/"> Read more&#8230;</a>]]></description>
										<content:encoded><![CDATA[<h2>Stratigraphic pick prediction via supervised machine-learning: Predictatops</h2>
<p>Back in May, I presented a talk at the 2019 AAPG ACE (American Association of Petroleum Geologist Annual Conference and Exhibit) on using machine-learning to predict stratigraphic surfaces in well logs. I described a Python package I have been working on as a side project called <a href="https://github.com/JustinGOSSES/predictatops">Predictatops</a>. Given I&#8217;ve mentioned working on the issue of stratigraphic top prediction using machine-learning in previous blog posts, I thought it wise to announce Predictatops here on my website as well.</p>
<p><div id="attachment_1227" style="width: 310px" class="wp-caption alignleft"><a href="http://54.87.153.110/wp-content/uploads/2019/08/Yale-Peabody-Triceratops-004Trp.png"><img aria-describedby="caption-attachment-1227" loading="lazy" class="size-medium wp-image-1227" src="http://54.87.153.110/wp-content/uploads/2019/08/Yale-Peabody-Triceratops-004Trp-300x199.png" alt="" width="300" height="199" srcset="/wp-content/uploads/2019/08/Yale-Peabody-Triceratops-004Trp-300x199.png 300w, /wp-content/uploads/2019/08/Yale-Peabody-Triceratops-004Trp-768x510.png 768w, /wp-content/uploads/2019/08/Yale-Peabody-Triceratops-004Trp-1024x680.png 1024w, /wp-content/uploads/2019/08/Yale-Peabody-Triceratops-004Trp-750x500.png 750w, /wp-content/uploads/2019/08/Yale-Peabody-Triceratops-004Trp.png 1280w" sizes="(max-width: 300px) 100vw, 300px" /></a><p id="caption-attachment-1227" class="wp-caption-text">Predictatops Logo</p></div></p>
<p>First, some definitions for the machine-learning folks who stumbled into a geologist blog post and the geologists who stumbled into a machine-learning blog post&#8230;</p>
<p><strong>Wells:</strong></p>
<p>Holes drilled in the ground.</p>
<p><strong>Well Logs:</strong></p>
<p>Well logs are created when a geophysical measurements are made along a well. These are usually 1D measurements in the sense that a measurement is made at the bottom, then the tool is pulled up a little bit and then another measur<span style="font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen-Sans, Ubuntu, Cantarell, 'Helvetica Neue', sans-serif;">ement is made. This continues until the entirety of the well is measured. Often, many different types of tools are used that measure different properties, resulting in multiple well logs for a single well. They measure things like how fast sound travels between two parts of the well or how much signal is bounced back and measured by a tool after a certain type of radiation is given off by a tool. These measurements are then turned into rock properties like density, grain size, etc. Further explanations of well log measurements are </span><a style="font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen-Sans, Ubuntu, Cantarell, 'Helvetica Neue', sans-serif;" href="https://www.rigzone.com/training/insight.asp?insight_id=298&amp;c_id=">here</a><span style="font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen-Sans, Ubuntu, Cantarell, 'Helvetica Neue', sans-serif;"> and </span><a style="font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen-Sans, Ubuntu, Cantarell, 'Helvetica Neue', sans-serif;" href="https://www.spec2000.net/05-logaliastable.htm">here</a><span style="font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen-Sans, Ubuntu, Cantarell, 'Helvetica Neue', sans-serif;">. The picture below is of a well log.</span></p>
<p><div id="attachment_1225" style="width: 233px" class="wp-caption alignleft"><a href="http://54.87.153.110/wp-content/uploads/2019/08/hall_et_all_2016_well_log.png"><img aria-describedby="caption-attachment-1225" loading="lazy" class="wp-image-1225 size-medium" src="http://54.87.153.110/wp-content/uploads/2019/08/hall_et_all_2016_well_log-223x300.png" alt="Well logs from a single well. Interpretation of lithology of the rocks on the right in colored bars." width="223" height="300" srcset="/wp-content/uploads/2019/08/hall_et_all_2016_well_log-223x300.png 223w, /wp-content/uploads/2019/08/hall_et_all_2016_well_log.png 375w" sizes="(max-width: 223px) 100vw, 223px" /></a><p id="caption-attachment-1225" class="wp-caption-text">Well logs from a single well. Interpretation of lithology of the rocks on the right in colored bars. Hall at al., 2015</p></div></p>
<p>&nbsp;</p>
<p><strong>Tops:</strong></p>
<p>Tops are markers for the tops of things. Specifically, tops of geologic units. Everything below a top is one geologic layer and everything above a top is another geology layer.</p>
<p><strong>Different Types of Tops:</strong></p>
<p>Tops can divide different categories of layers. Sometimes the layers are based on characteristics of the rock. For example a top can separate rock made from small grains from rock made of large grains. Tops based on physical make-up of rocks are often called lithologic tops. Lithology is term for describing what a rock is made up of. Facies is another term that refers to categories of rocks in a well with similar characteristics.</p>
<p>Alternatively, tops can be boundaries based on more actionable characteristics like the ability for fluids to flow. A top might separate a geologic layer where you think the rock will allow fast flow of fluids like water, oil, or gas from a layer below the top where fluids will flow very slowly.</p>
<p>Geologist&#8217;s favorite way to place a top, however, is to place tops based on time. A top can separate rock deposited at one point in time from rock deposited at the next point of time. This is a stratigraphic or chronostratigraphic top! Also, called a time surface.</p>
<p>You might have noticed that the lithologic, flow-based, and stratigraphic tops are increasingly abstract.</p>
<p>The first, lithologic-tops are based on what the rock is made up of, which can be measured, at least indirectly. Flow is a little harder to predict from well logs but the ability of fluids to flow is fundamentally also based on physical characteristics, which can be measured, just with more difficulty as very small characteristics at the level of pores in rocks are what matter.</p>
<p>Stratigraphic tops are based on age of the rocks. There is no measurement that relates to time that can be done routinely in well logs. You can collect fossils and interpret time based on the fossils found in different units (biostratigraphy). You can find volcanic ash and date it by looking at how much one type of element has turned into a different type of element due to decay (geochronology). However, neither of these can be done on all, or even most, wells. They&#8217;re too expensive and time consuming. Not all depth points will have fossils or ash layers for dating.</p>
<p><strong>Stratigraphic Correlation:</strong></p>
<p><em>How then does one go from well logs to stratigraphic tops representing time surfaces? That requires a model, and a head to put it in.</em></p>
<p>In practice, chronostratigraphic (mapping out time surfaces) well log correlation (correlation means interpreting where a top in well A exists in well B) is a combination of lithostratigraphic correlation (looking at 2 wells and matching curves of the well logs using the assumption that similar looking curves, have similar properties, and are the same layers) and application of conceptual models. These conceptual models cover how sediment is transported and deposited. They are very helpful for stratigraphic correlations as they predict the spatial distribution of different types rocks deposited at the same time and how those spatial associations can change over time. <span style="font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen-Sans, Ubuntu, Cantarell, 'Helvetica Neue', sans-serif;">These conceptual models come from two places, outcrop studies (going out in the field and looking at rocks) and modern analogues studies (going out to the valley, rivers, lakes, oceans, etc. and seeing how sediment gets deposited). The geology name for these conceptual models is depositional environments. Some additional information on them can be found <a href="https://wiki.aapg.org/Depositional_environments">here and</a> <a href="https://en.wikipedia.org/wiki/Depositional_environment">here.</a> Another key conceptual model is <a href="http://www.sepmstrata.org/page.aspx?&amp;pageid=32&amp;3">sequence stratigraphy</a>. </span></p>
<p>An example of lithostratigraphic vs. chronostratigraphic interpretation below.</p>
<p><div id="attachment_1224" style="width: 984px" class="wp-caption aligncenter"><a href="http://54.87.153.110/wp-content/uploads/2019/08/Gani_and_Bhattacharya_2006_.png"><img aria-describedby="caption-attachment-1224" loading="lazy" class="wp-image-1224 size-full" src="http://54.87.153.110/wp-content/uploads/2019/08/Gani_and_Bhattacharya_2006_.png" alt="The top picture shows lithostratigraph correlation where the assumption is that rocks with similar characteristics are deposited the same way. The bottom is a chronostratigraphic interpretation where models from outcrop studies of deltas are used as a guide. In this environment, the coarser grains are deposited first and then finer grains, which build up over time as sheets angled towards the deeper water." width="974" height="547" srcset="/wp-content/uploads/2019/08/Gani_and_Bhattacharya_2006_.png 974w, /wp-content/uploads/2019/08/Gani_and_Bhattacharya_2006_-300x168.png 300w, /wp-content/uploads/2019/08/Gani_and_Bhattacharya_2006_-768x431.png 768w" sizes="(max-width: 974px) 100vw, 974px" /></a><p id="caption-attachment-1224" class="wp-caption-text">The top picture shows lithostratigraph correlation where the assumption is that rocks with similar characteristics are deposited at the same time. The bottom is a chronostratigraphic interpretation where models from outcrop studies of deltas are used as a guide. In the deltaic depositional environment, the coarser grains are deposited first and then finer grains, which build up over time as sheets angled towards the deeper water. The lower interpretation is correct.</p></div></p>
<p>You can read more about stratigraphic well log correlation from <a href="http://www.sepmstrata.org/page.aspx?pageid=61">this page by SEPM </a>(a national sedimentology association).</p>
<p><em>Just to be clear, with Predictatops, we&#8217;re wanting to do chronostratigraphic correlation, not lithostratigraphic correlation.</em></p>
<p><strong>Supervised Machine-learning:</strong></p>
<p>In our context, supervised machine-learning means, instead of letting the computer going on fun field trips like geologists to gradually build up mental conceptual models to use for correlating well logs chronostratigraphically, we&#8217;ll give the computer a dataset of already human-picked tops for one time surface and ask the computer to figure out a model that lets it mimic the geologist.</p>
<p>For more detailed explanations of machine-learning, there are lots of things on the web that google will provide for you. I&#8217;m a fan of the <a href="https://towardsdatascience.com/explaining-supervised-learning-to-a-kid-c2236f423e0f?source=---------62------------------">medium articles</a> by &#8220;Cassie Kozyrkov&#8221; whose title is &#8220;Chief Decision Intelligence Engineer, Google&#8221; and does a good job at packaging key points in an entirely dense but fun to read space.</p>
<p><strong>Building Geologic Observations into Features:</strong></p>
<p>Features in a machine-learning context are new data characteristics built from the original data. An basic example might be the sum of three other original data characteristics. Feature creation is a very common part of machine-learning. Rarely would you only use original raw data.</p>
<p>Unlike some of the demo datasets traditionally used in machine-learning demos where each row of the dataset is an independent entity and features are only created within each row, a key aspect of building features for stratigraphy applications is that a lot of valuable information can be gleaned if one creates features based on comparisons or aggregate observations from multiple depth points or even across wells. One type of comparison is between each depth point in question and the depth points above, below, and around it within different length windows. Another type of comparison is between the characteristics of the well that holds the depth point being predicted for and the neighboring wells.</p>
<p>These comparison-based features are similar to what a geologist does visually when they put wells in a cross-section, or a sequence of wells&#8217; well logs, and attempt to pick where stratigraphic tops should be correlated as shown below.</p>
<p><div id="attachment_1091" style="width: 504px" class="wp-caption alignleft"><a style="font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen-Sans, Ubuntu, Cantarell, 'Helvetica Neue', sans-serif;" href="http://54.87.153.110/wp-content/uploads/2018/05/Mannville_Xsection_B.png"><img aria-describedby="caption-attachment-1091" loading="lazy" class="wp-image-1091" src="http://54.87.153.110/wp-content/uploads/2018/05/Mannville_Xsection_B-1024x723.png" alt="Alberta Geological Survey Open File Report 1994-14. Cross-section B to B&#96;." width="494" height="349" srcset="/wp-content/uploads/2018/05/Mannville_Xsection_B-1024x723.png 1024w, /wp-content/uploads/2018/05/Mannville_Xsection_B-300x212.png 300w, /wp-content/uploads/2018/05/Mannville_Xsection_B-768x542.png 768w, /wp-content/uploads/2018/05/Mannville_Xsection_B.png 2000w" sizes="(max-width: 494px) 100vw, 494px" /></a><p id="caption-attachment-1091" class="wp-caption-text">A cross-section showing different tops in different wells. Vertical curvy lines are gamma-ray well log curves. Alberta Geological Survey Open File Report 1994-14. Cross-section B to B`.</p></div></p>
<p><div id="attachment_1092" style="width: 251px" class="wp-caption alignright"><a href="http://54.87.153.110/wp-content/uploads/2018/05/MannvilleWellsMap.png"><img aria-describedby="caption-attachment-1092" loading="lazy" class="size-medium wp-image-1092" src="http://54.87.153.110/wp-content/uploads/2018/05/MannvilleWellsMap-241x300.png" alt="Map of Mannville wells in the Alberta Geological Survey open file report 1994-14 that are used in the project I'm doing at the github link." width="241" height="300" srcset="/wp-content/uploads/2018/05/MannvilleWellsMap-241x300.png 241w, /wp-content/uploads/2018/05/MannvilleWellsMap-768x954.png 768w, /wp-content/uploads/2018/05/MannvilleWellsMap-824x1024.png 824w, /wp-content/uploads/2018/05/MannvilleWellsMap.png 1102w" sizes="(max-width: 241px) 100vw, 241px" /></a><p id="caption-attachment-1092" class="wp-caption-text">Map of Mannville wells in the Alberta Geological Survey open file report 1994-14 that are used in the project I&#8217;m doing at the github link.</p></div></p>
<p>Only creating features based on data in individual depth points in individual wells would like cutting up all your well logs from all your wells into little bits, giving them to your geologist in a bucket, shaking the bucket, and then ask the geologist which depth point pieces are the same depth as the top you&#8217;re trying to predict for. Obviously, that wouldn&#8217;t work out so well. If you were to set up a stratigraphic machine-learning project and only create features from data at the same depth points for each well, you&#8217;d be doing the same thing to your machine-learning model.</p>
<h2>Predictatops: Supervised Machine-Learning of Stratigraphic Surfaces</h2>
<p><strong>Predictatops&#8217; Supervised Machine-learning Goal:</strong></p>
<p>The goal of Predictatops is to be able to give it a training datasets of wells (that include both well logs and trusted human-assigned tops) for a single time surface and a test datasets of just well logs and get back where it thinks the top should be in each well in the test dataset.</p>
<p><strong>How to judge success:</strong></p>
<p>We want to minimize the distance between where the ML model predicted the top should be in each well and where the human(s) put the top. That difference will be our error. For comparing different runs we&#8217;ll return the RMSE (root mean squared error) for the top we&#8217;re trying to predict across all the wells.</p>
<p>We could have picked a different way to judge prediction success, so I&#8217;ll explain a bit about why I think this is a better way.</p>
<p>You might be tempted to set the problem up as a classification problem where we don&#8217;t predict a single pick but rather for each depth point in every well predict what formation (another geology word for layer) that depth point is. The problem with doing it this way, is that geologist really don&#8217;t care whether you got the formation correct far away from any top. That might not even be a hard problem. Additionally, how good your statistics appear to be will be affected by how thick the layers are, which isn&#8217;t ideal.</p>
<p>You could also frame the problem in terms of a binary question of whether or not the top was predicted to be in the exact same place as the geologist put it. The problem with this approach is two-fold. First, you immediately have a huge imbalanced class problem on your hands. If your well logs have a different measurement every 1/3 of a meter and typically are 300 meters long, every well will have 1 instance of data to represent the top and 899 instances to represent not the top. This will make machine-learning very difficult. Second, a binary prediction approach will affect the way you judge accuracy resulting in some not particularly useful information. You might get 4% of the depths predicted exactly right and 96% wrong. However, if all your 96% wrong tops are within plus or minus 2 meters of the actual tops, that&#8217;s amazing good. If the average distance between the actual top and predicted top is plus or minus 56 meters, that&#8217;s not good. In both cases, you were only 4% accurate.</p>
<p><strong>Project setup:</strong></p>
<p>If we can&#8217;t set-up the problem as a binary machine-learning program or a classification machine-learning problem, how do we set up the problem?</p>
<p>In Predictatops, we handled this by making it a two-step prediction with the first step being classification, not on formation labels, but on distance zones away from the pick we were trying to predict. Imaginary zones were created at the pick, slightly away from the pick below, slightly away from pick above, farther form pick below, farther from pick above, and everything else. We then ran classification to predict the zone of each depth point in each well. Those results were then run through an additional process that produced higher numbers for depth points that had the most predictions for being at the top or very near to the top around it. More of this process is described in <a href="https://github.com/JustinGOSSES/predictatops/blob/master/docs/ACE2019_Gosses_theme8_StratigraphicTopML_201905018_submitted.pdf">this presentation given at AAPG ACE</a> and in the <a href="https://justingosses.github.io/predictatops/html/index.html">documentation of Predictatops</a>.</p>
<p><strong>Data Requirements:</strong></p>
<p>The supervised part of supervised machine-learning means you have to have human-labeled tops to start. In addition, you have to have enough wells from enough places that the full complexity of the stratigraphy is captured in the training wells. The exact number required is hard to define as it depends on the complexity of the problem, how generalizable we want to the solution, and the algorithms used. If you had to press me, I&#8217;ll say you&#8217;ll need several hundred tops, if not more than a thousand, for your training datasets.</p>
<p>While we&#8217;re discussing training dataset sizes, a point of interest here is that the number of required training wells goes down is someone is kinda enough to create and release open-source a pre-trained model on say 200,000+ wells in a depositional environment similar to yours. Then you might be able to use that model as a starting point and retrain it with your use-case specific training dataset. This is a over-simplistic description of transfer-learning, which has resulted in incredible gains in image and natural language processing machine-learning.</p>
<p>An additional data requirement is that these wells have the same, or at least very similar, well log types. Machine-learning likes all the inputs to be collected and prepped the same way. Although this may seem like a simple ask to those not in oil &amp; gas, the reality is that many wells will be drilled with different well logs. Some types will be always present. Some types will be mostly present. Others rarely present. Some types, like sonic, will be very common but different tool vendors used that measure the same property in different ways. Well log normalization by petrophysicists may be required.</p>
<p>In the demo dataset from the McMurray formation, a collection of well logs that were in the highest number of wells were found. <span style="font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen-Sans, Ubuntu, Cantarell, 'Helvetica Neue', sans-serif;">The impact of that constraint was that instead of 2000 wells used, just over 1200 wells were used. There are classes in Predictatops to help identify what well logs are the most common in a given dataset. </span></p>
<p><strong>Predictatops Project Status:</strong></p>
<p>Predictatops is functional but still changing. I tried to organize things such that large pieces could be skipped and others added without too much trouble. It has a demo data from the McMurray in Alberta, Canada and instructions for how to run it with that demo dataset. The documentation is still a work in process but the basics are all there.  I&#8217;ve made some changes to make it more generalizable, but there is more to be done in that area.</p>
<p><strong>Predictatops Performance:</strong></p>
<p>The top McMurray currently has a RMSE (root mean squared error) of 6.6 meters. More information is available in <a href="https://github.com/JustinGOSSES/predictatops/blob/master/docs/ACE2019_Gosses_theme8_StratigraphicTopML_201905018_submitted.pdf">this presentation given at AAPG ACE</a> and in the <a href="https://justingosses.github.io/predictatops/html/index.html">documentation of Predictatops</a>.</p>
<p><div id="attachment_1229" style="width: 1022px" class="wp-caption aligncenter"><a href="http://54.87.153.110/wp-content/uploads/2019/08/Histogram_Error_predictatops_6.6_vA.png"><img aria-describedby="caption-attachment-1229" loading="lazy" class="wp-image-1229 size-full" src="http://54.87.153.110/wp-content/uploads/2019/08/Histogram_Error_predictatops_6.6_vA.png" alt="" width="1012" height="387" srcset="/wp-content/uploads/2019/08/Histogram_Error_predictatops_6.6_vA.png 1012w, /wp-content/uploads/2019/08/Histogram_Error_predictatops_6.6_vA-300x115.png 300w, /wp-content/uploads/2019/08/Histogram_Error_predictatops_6.6_vA-768x294.png 768w" sizes="(max-width: 1012px) 100vw, 1012px" /></a><p id="caption-attachment-1229" class="wp-caption-text">A histogram showing the distribution of McMurray Top prediction error. Bars count how many wells where in each group. Groups are based on difference in depth between actual human-picked top and machine-picked top. RMSE is 6.6 m.</p></div></p>
<h4>Wait, but I don&#8217;t trust my geologist.</h4>
<p>Yes, one limitation of all of this is that fundamentally the machine-learning model is trying to mimic a person&#8217;s (or multiple people&#8217;s) top interpretations. The best you&#8217;ll get out of the machine-learning model in terms of performance accuracy is slightly worse than the training dataset supplied by human geologist(s).</p>
<h4>When would you want to use this type of approach?</h4>
<ol>
<li>When you don&#8217;t have enough time for a geologist to interpret all the wells, but you have enough time to interpret 1000 out of 7000 wells.</li>
<li>When you have two areas worked by different geologists and you want to see how the interpretation of geologist A transfers to the neighboring area worked by geologist B.</li>
<li>When you want to identify the 5% of the wells with the most uncertainty and have your best geologists focus on those.</li>
</ol>
<h4 class="graf graf--h4">Are there uses for this type of approach even if I already have human tops for all my wells?</h4>
<p class="graf graf--p">Yes, the great thing about this type of approach is it scores each depth point in every well. That score can be normalized to a probability of how likely each depth point is to actually be the top. There are wells where only one depth point or a small cluster of depth points have higher scores. Other wells have high scores spread more widely throughout the well. Additionally, some wells have predicted tops at similar depths to their neighbors. Other wells do not. <em class="markup--em markup--p-em">This information can be used to generate uncertainty scores/maps/curves and help geologists know where to focus their efforts.</em> I haven’t done this with Predictatops yet, but it is totally possible!</p>
<h2><strong>Making it easy to use the demo dataset:</strong></h2>
<p>As mentioned before, the <a href="https://ags.aer.ca/publications/SPE_006.html">demo dataset</a> comes from the McMurray formation in Alberta, Canada. There&#8217;s information on it in the <a href="https://github.com/JustinGOSSES/predictatops">README.md</a> and <a href="https://justingosses.github.io/predictatops/html/index.html">documentation of Predictatops</a>. The full reference is: Wynne et al., (1994) Athabasca Oil Sands Database McMurray/Wabiskaw Deposit, Open-File-Report 1994–14, Alberta, Canada; Alberta Geological Survey. Links to <a class="markup--anchor markup--p-anchor" href="https://ags.aer.ca/document/OFR/OFR_1994_14.PDF" target="_blank" rel="noopener" data-href="https://ags.aer.ca/document/OFR/OFR_1994_14.PDF">report</a> &amp; <a class="markup--anchor markup--p-anchor" href="http://ags.aer.ca/publications/SPE_006.html" target="_blank" rel="noopener" data-href="http://ags.aer.ca/publications/SPE_006.html">dataset</a>. This is a great open-source dataset from the Alberta Energy Regulator and Alberta Geological Survey that could be used in a lot of other machine-learning focused work as it is one of the larger open-source datasets of a single formation already compiled and prepped by a single group.</p>
<p>Discovering, evaluating, loading, and transforming data takes a lot of time. There&#8217;s always a risk you&#8217;ll get through some or all of those steps and then discovery the dataset won&#8217;t work for your purposes. This dataset is already put together and can be used for both stratigraphic top prediction and facies prediction.</p>
<p>I&#8217;ve been working on a pull request for the <a href="https://github.com/fatiando/rockhound">Rockhound</a> Python package, a project to make loading geologic demo datasets super quick and easy, that will let you pull in the fully prepped and merged McMurray dataset with two lines of code. Currently, <a href="https://github.com/JustinGOSSES/rockhound">there is this pull request</a> for the McMurray dataset prepped for facies prediction. Once that pull request is accepted, I&#8217;ll push another dataset prepped for stratigraphic prediction.</p>
<h2>Other Machine-Learning Approaches to Stratigraphy</h2>
<p><strong>Lithostratigraphy:</strong></p>
<p>Lithostratigraphy is basically curve matching, so computational approaches go back to the 1970s. Some of the better results seem to be geologic specific variations on dynamic time warping. One example is <a href="http://www.kgs.ku.edu/Publications/OFR/2002/OFR02_51/ManualOFR2002-51.pdf">CORRELATOR</a> from Kansas Geological Survey, but there are more modern approaches in Python as well.</p>
<p>The reasons for why this type of computational approach seemed to have never caught on are likely complex. I don&#8217;t claim to understand all of them, but I suspect it was related to the fact that they often didn&#8217;t return a single surface but rather an arbitrary number of surfaces. This meant the geologist still had to look at the well logs in order to use the results. Hence, the time savings aren&#8217;t there.</p>
<p><strong>Chronostratigraphy:</strong></p>
<p>If you&#8217;re interesting in this type of thing, here are two other recent examples of applying machine-learning to stratigraphy that I think are very interesting.</p>
<ol>
<li>Alex Bayeh, Michael Ashby, Darrin Burton, and Seth Brazell at Anadarko (now Occidental) published &#8220;<a href="https://www.onepetro.org/journal-paper/SPWLA-2019-v60n4a1?sort=&amp;start=0&amp;q=brazell&amp;from_year=&amp;peer_reviewed=&amp;published_between=&amp;fromSearchResults=true&amp;to_year=&amp;rows=25">A Machine-Learning-Based Approach to Assistive Well-Log Correlation</a>&#8220;, which uses thousands of pairs of well logs that are and are not representing the same layer to train a model, which is then used with a small number of tops from a specific formation and tops for that formation predicted. I was excited to see this type of approach because (1) I thought an approach sort of like this might be possible but don&#8217;t have access to large enough open-source dataset to actually attempt it myself (2) it demonstrates a different approach to supervised machine-learning applied to stratigraphy.</li>
<li>Additionally, there&#8217;s been a variety of papers trying to apply wavelet transform theory to well log correlation for the past two decades. My opinion of these approaches has typically been that there is a lot of complexity without that much to show for it in terms of useful predictions. A recent exemption to this was <a style="font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen-Sans, Ubuntu, Cantarell, 'Helvetica Neue', sans-serif;" href="https://www.onepetro.org/conference-paper/SPE-183860-MS">Ye at al., 2017</a><span style="font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen-Sans, Ubuntu, Cantarell, 'Helvetica Neue', sans-serif;">&#8216;s &#8220;</span><em style="font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen-Sans, Ubuntu, Cantarell, 'Helvetica Neue', sans-serif;">Rapid and Consistent Identification of Stratigraphic Boundaries and Stacking Patterns in Well Logs &#8211; An Automated Process Utilizing Wavelet Transforms and Beta Distributions</em><span style="font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen-Sans, Ubuntu, Cantarell, 'Helvetica Neue', sans-serif;">&#8220;, which looks like it would be an excellent feature creation step to use in supervised, or event unsupervised machine-learning, applied to stratigraphy.</span></li>
</ol>
<h3 class="graf graf--h3">Contributing to Predictatops</h3>
<p class="graf graf--p">Pulls requests and issues (in the form of bugs, enhancements, comments, and even idle observations) are very welcome on Predictatops. I currently have 18+ issues on the repository for things to do. It is a side project, so please don’t expect it to be perfect, but I&#8217;m interested in hearing feedback as well as other peoples’ approaches to this type of problem.</p>
<p>References are available on the last slide of <a href="https://github.com/JustinGOSSES/predictatops/blob/master/docs/ACE2019_Gosses_theme8_StratigraphicTopML_201905018_submitted.pdf">this presentation</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>/predictatops/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>Geoscience to Data Science Starter Pack</title>
		<link>/geologist-to-data-science-starter-pack/</link>
					<comments>/geologist-to-data-science-starter-pack/#comments</comments>
		
		<dc:creator><![CDATA[Justin]]></dc:creator>
		<pubDate>Fri, 25 Jan 2019 03:10:47 +0000</pubDate>
				<category><![CDATA[code]]></category>
		<category><![CDATA[advice]]></category>
		<category><![CDATA[career]]></category>
		<category><![CDATA[data science]]></category>
		<category><![CDATA[geoscience]]></category>
		<category><![CDATA[learning]]></category>
		<category><![CDATA[machine-learning]]></category>
		<category><![CDATA[starting out]]></category>
		<guid isPermaLink="false">https://54.87.153.110/?p=1152</guid>

					<description><![CDATA[Why Write this and Who is it targeting? I wrote a post,&#160;LEARNING TO CODE, in early 2016, three years ago. The premise of that blog post was a summary of the different styles of learning you could pick from when trying to learn how to code.&#160;Not everyone prefers to learn<a class="moretag" href="/geologist-to-data-science-starter-pack/"> Read more&#8230;</a>]]></description>
										<content:encoded><![CDATA[<h2>Why Write this and Who is it targeting?</h2>
<p>I wrote a post,&nbsp;<a href="https://54.87.153.110/learning-to-code/">LEARNING TO CODE</a>, in early 2016, three years ago. The premise of that blog post was a summary of the different styles of learning you could pick from when trying to learn how to code.&nbsp;Not everyone prefers to learn the same way, and I hadn&#8217;t at the time read any breakdowns of the different ways to learn how to code.</p>
<p>This blog post, like that one, was prompted by the realization that I had the same conversation with two different people within a single week. They were asking the same questions, so might as well write everything down.</p>
<blockquote><p><em>This post is directed at houston-based geoscience types starting off on a month to years long process of improving their skills in data science and maybe eventually getting a job in data science. It lays out the things I&#8217;ve found myself telling people in real life.</em></p></blockquote>
<h3></h3>
<p>&nbsp;</p>
<h2></h2>
<h2>Step 1: Figure out if you&#8217;re interested in this type of thing&#8230;.</h2>
<p>I&#8217;ve not seen a lot of writing on the best way to do this. The best path forward may be a personal decision to a large degree.</p>
<p>If you have kids and want to involve them in your first steps,<a href="https://code.org/"> code.org</a> and <a href="https://scratch.mit.edu/">Scratch</a> are two resources to try out if you haven&#8217;t written any code. Both are designed for kids but still kinda cool. They&#8217;ll let you see what kind of logic writing code uses but often doing so in a pictorial form that doesn&#8217;t require memorizing any syntax.</p>
<p>You might also want to try some shorter lessons of 1-5 hour length on sites like <a href="https://www.codecademy.com/">code academy</a> or take your time going through any of the languages on <a href="https://www.w3schools.com/">w3schools</a>.</p>
<p>If you&#8217;re more motivated by what you can eventually do, you might try watching a few videos of talks from any of the&nbsp;<a href="https://www.youtube.com/playlist?list=PLYx7XA2nY5GfdAFycPLBdUDOUtdQIVoMf">SciPy</a>&nbsp; conferences or the machine-learning videos from&nbsp;<a href="https://www.youtube.com/channel/UCsX05-2sVSH7Nx3zuk3NYuQ">PyCon</a>. They&#8217;ll be partially over your head, but they can still be very interesting. You can also take a look at the blog posts summarizing what projects were made during <a href="https://agilescientific.com/blog/2018/12/17/the-london-hackathon">geology hackathons by AgileScientific</a>.</p>
<p>&nbsp;</p>
<h2>What Language to Learn?</h2>
<h4>Python</h4>
<p>The favorite. Different computer languages are better for different tasks. They also change in popularity over time. There used to be Python vs. R for data science debates, but those have faded recently as Python has more or less won over more people. Two libraries you&#8217;ll use often that also have good documentation &amp; lots of video tutorials are <a href="https://scipy.org/scipylib/">SciPy</a> and <a href="https://scikit-learn.org/stable/">Scikit-learn</a>. If you want to try NLP (natural language processing) <a href="https://spacy.io/">SpaCy</a> has maybe the best documentation of major Python machine-learning libraries.</p>
<h4>R</h4>
<p>While Python tends to dominate the hard sciences and to a decent extent machine-learning, R leads among the social sciences. There&#8217;s interesting geoscience computing done in R, just most of it is done in Python.</p>
<h4>Other languages that don&#8217;t start with Pytho</h4>
<p>Python is a very intuitive computer language as far as these things go, so jumping to another language can be a relatively painful experience, at least initially. If you start in Python and are starting to grasp the language, I&#8217;d encourage you <em>not to stay with only Python</em>. One, it limits what you can do. Although capable of a lot, Python isn&#8217;t good at everything. Two, you&#8217;ll become better at programming once you can hope between languages. There will be people, sometimes people with an incentive, who might say things at a SciPy conference like, &#8220;I am only an astrophysics PhD, I can&#8217;t be expected to understand something difficult like JavaScript&#8221; or &#8220;If you learn JavaScript then you&#8217;ll be a web developer and not a scientist&#8221;. Those people are wrong. Ignore them.</p>
<h5>JavaScript (and HTML,CSS)</h5>
<p>Although you will probably start off with Python. Picking up JavaScript as language number two is worth your while. The web runs on HTML, CSS, JavaScript, browsers, and pictures of cats. If you want to build anything with a decent human interface, visualize data in a slightly unusual way, or reach people online, having some JavaScript knowledge is powerful.</p>
<p>An important point to make when you talk about JavaScript is that&nbsp;<a href="https://www.w3schools.com/js/default.asp">plain JavaScript</a>, or what is sometimes called <a href="https://snipcart.com/blog/learn-vanilla-javascript-before-using-js-frameworks">Vanilla JavaScript</a>, is perfectly fine most of the time. There are lots of JavaScript frameworks you could theoretically pick up, <a href="https://reactjs.org/">React</a>, <a href="https://vuejs.org/">Vue</a>, <a href="https://angularjs.org/">Angular</a>, etc., but I tend to have a <em>&#8220;use it only if you have well demonstrated need&#8221;</em> perspective on JavaScript frameworks. If you end up doing a large <a href="https://en.wikipedia.org/wiki/Front_and_back_ends">front-end project</a>, that&#8217;s when you should consider a JavaScript framework.</p>
<h5>C++</h5>
<p>C++ and Java are the languages most often learned by Computer Science majors in university. There are good reasons for this and not quite so good reasons for this. Certain things, like highly dependable applications, embedded applications, and low-level high performance computing is done in C++. If you are a geophysicist and did some in school, it might be a place to continue. If not, it probably isn&#8217;t the place to start.</p>
<h5>Java</h5>
<p>Some of the things that could be said about C++ could also be said about Java. There is a fair amount of machine-learning done using Java when it is done via <a href="https://en.wikipedia.org/wiki/Distributed_computing">distributed computing</a> on big data.&nbsp;<a href="https://towardsdatascience.com/deep-learning-with-apache-spark-part-1-6d397c16abd">Spark</a>&nbsp;is an important tool in that space to at least know about. If you&#8217;re interested in Spark but want to stick to Python, there is also <a href="https://towardsdatascience.com/a-brief-introduction-to-pyspark-ff4284701873">PySpark</a>.</p>
<p>&nbsp;</p>
<h2>How to learn?</h2>
<h3>In-person Bootcamps, Online Courses, Online Lessons, etc.</h3>
<p>As mentioned above, I previously wrote a blog post in 2016 about the <a href="https://54.87.153.110/learning-to-code/">different types of ways to learn how to code</a>. Its worth taking a look at it. Much of what was written ties in closely with this post but from a more generic learning to code perspective and less data science centric view.</p>
<h4>Useful Things that Didn&#8217;t Exist (I think) in January 2016</h4>
<p>One thing of importance to note is that <a href="https://notebooks.azure.com/">Microsoft Azure notebook</a>s and <a href="https://colab.research.google.com/notebooks/welcome.ipynb#recent=true">Google Colab</a> didn&#8217;t exist in January 2016. If they would have, and I knew about them, I would noted them in the previous blog post. These are similar to a <a href="https://jupyter.org/">Jupyter Notebook</a> but run in the cloud and are accessed via your browser. They will let you get started writing Python without having to deal (at least initially) with the often messy process of installing languages, editors, and code libraries locally on your computer. If you do install things on your local computer, the <a href="https://www.anaconda.com/">Anaconda</a> installation method is probably the easiest path forward.</p>
<p>&nbsp;</p>
<h2>Build Things People Can Find</h2>
<h3>Start a Github Profile</h3>
<p>Why? =&nbsp;<strong>Because if you&#8217;re self-taught you need to show evidence you can create things and write actual code.</strong> The commonly acceptable way to do this is to give people a link to your github profile where you have a bunch of public code projects. These can be data visualizations, machine-learning baby-scale projects, whatever. Make sure not all of them are forks or class work where you followed instructions.</p>
<p>If you&#8217;re not familiar with the terms, <a href="https://www.coredna.com/blogs/what-is-git-and-github-part-two">here</a> are some definitions of <a href="https://en.wikipedia.org/wiki/Git">Git</a> and <a href="https://en.wikipedia.org/wiki/GitHub">Github</a>. There are other services than github you can use, like gitlab or bitbucket, but GitHub is the most common.</p>
<p>While on the topic of github, I will note that <a href="https://github.com/softwareunderground/awesome-open-geoscience">this repository of <em>&#8220;AWESOME OPEN GEOSCIENCE&#8221;</em></a> code projects is something to check out. It lives on github. It contains a wide variety of lesser known geoscience-domain-specific tools you can use. It started as a conversation I had with others in the <a href="https://softwareunderground.org/slack/">Software Undergound Slack channel</a>. It is one of the many &#8220;Awesome lists&#8221; out there for code in a specific domain or application area.</p>
<h3>Personal website</h3>
<p>Why? =&nbsp;Because it is good web programming practice and shows you can build something. Additionally, it can be a way to do personal branding.</p>
<p>The two easiest ways to do this are a <a href="https://wordpress.com/">WordPress</a>&nbsp;website or a <a href="https://pages.github.com/">github pages</a> website. WordPress is a content management system or CMS. You technically don&#8217;t need to code at all if you use WordPress though you can do some small edits in HTML, CSS, and JavaScript if you&#8217;d like to. On the back-end side, WordPress runs PHP. WordPress may cost you depending where it is hosted and whether you want a more professional web address. Github pages&nbsp;is free, but only front-end (<em>HTML,CSS,JS</em>), meaning no connection to a database or back-end scripts (<em>Python or PHP</em>).&nbsp;There are plenty of open-source, free static page templates you can use to get started with a&nbsp;<a href="https://pages.github.com/">github.io page</a>.</p>
<h3></h3>
<p>&nbsp;</p>
<h2>Active In-person Learning</h2>
<h3>Tutorials at Tech Conferences</h3>
<p>Why? =&nbsp;Because they&#8217;re really good at getting as much of the information coming out of the firehose to go directly in your brain. They can also serve as starter material for a project on your github. Often the tutorials will be based around a library or a type of task. You&#8217;ll usually leave with a link to not just slides but also all the code the instructor ran, which sets you up to learn it even deeper later on. Conferences can be a good way to network too.</p>
<ul>
<li><a href="https://scipy2018.scipy.org/ehome/299527/648139/">https://scipy2018.scipy.org/ehome/299527/648139/</a></li>
<li><a href="https://us.pycon.org/2018/schedule/tutorials/">https://us.pycon.org/2018/schedule/tutorials/</a></li>
</ul>
<h3>Hackathons</h3>
<p>Why? =&nbsp;Because hackathons are the fastest way to build things that demonstrate your ability to combine concepts and techniques to solve a real world problem. They&#8217;re also great for networking and learning new things through collaborative problem solving.</p>
<p>The factors that have differentiated good from less good hackathons in my limited experience were a length of at least 5 hours if not 2 days, interesting project ideas, project ideas scaled to the time and skillsets of participants, most participants knowing how to code at least a little, and enough coffee/food that you don&#8217;t have to leave.</p>
<p>Good Hackathons likely to be in Houston in the future:</p>
<ul>
<li><a href="https://events.agilescientific.com/">https://events.agilescientific.com/</a> : Agile runs several a year, typically around conferences that I can attest are quite good.</li>
<li><a href="http://houstonhackathon.com/">http://houstonhackathon.com/</a> : I&#8217;ve never been able to go myself as I&#8217;ve always been out of town, but I&#8217;m told its worth your time.</li>
</ul>
<h3>Single-Speaker-Style Meet-ups</h3>
<p>Why? =&nbsp;There&#8217;s a reason schools spend a lot of time filling peoples&#8217; heads via the single-speaker at front of room format. It is generally effective. There are a variety of Houston meet-ups in the machine-learning, data science, python space. They vary in quality. Sometimes when they&#8217;re not good, it can be because they&#8217;ve turned into a vendor pitch or the content was different than what was listed. The two meet-ups I mention below have good content and are good for networking. The houston energy data science meet-up sometimes falls into the trap of speakers being just a bit too vendor-ish, but usually it is okay. SPE (Society of Petroleum Engineers) sometimes has oil and gas data science &#8220;meet-ups&#8221;, but they aren&#8217;t free so I never go.</p>
<ul>
<li><a href="https://www.meetup.com/Houston-Data-Science/">https://www.meetup.com/Houston-Data-Science/</a></li>
<li><a href="https://www.meetup.com/Houston-Energy-Data-Science-Meetup/">https://www.meetup.com/Houston-Energy-Data-Science-Meetup/</a></li>
</ul>
<h3>Non-Just-A-Speaker Meet-ups</h3>
<p>Why? =&nbsp;Because not all meet-ups are just a person talking and that&#8217;s a good thing. Some of them are more about doing.</p>
<p><a href="https://www.meetup.com/sketchcity/">Sketch city</a> regularly has people, local government agencies, and non-profits come in to share a bit about their open-data and what problems/solutions/visualizations/predictions a data-literate member of the public might make from their data. It is a good meet-up to attend for getting project ideas and networking within the local civic tech or civic-tech-interested crowd.</p>
<p><a href="http://www.meetup.com/Houston-Data-Visualization-Meetup/">The Houston Data Visualization Meet-up</a> (<em>disclaimer I help co-lead this one</em>) has both single-speaker format and data-jam format meetings. Data-jams are often on Saturday morning and consist of 10-30 people working in small groups to visualize a dataset they were just given that morning. Often these datasets come from a local community group or the city of Houston, though we&#8217;ve also used non-local datasets like ChemCam data from the Mars rover Curiosity or a dataset of Russion-bots&#8217; posting on Twitter. In addition to being great starter projects for your portfolio and good networking, this type of meet-up exposes you to a wide variety of GUI and code library data visualization toolsets. You&#8217;ll find out what tools are good for what use cases.</p>
<ul>
<li><a href="https://www.meetup.com/sketchcity/">https://www.meetup.com/sketchcity/</a></li>
<li><a href="http://www.meetup.com/Houston-Data-Visualization-Meetup/">http://www.meetup.com/Houston-Data-Visualization-Meetup/</a></li>
</ul>
<h2></h2>
<p>&nbsp;</p>
<h2>Filling Your Head Digitally</h2>
<p>Once you get a certain level of proficiency, learning will start to become more about keeping up and continuing to grow. The rate of &#8220;new&#8221; in data science greatly outstrips geology. It also occurs in different places. &#8220;New&#8221; in oil &amp; gas geology tends to mostly occur in&nbsp;yearly conferences, monthly or quarterly journal publications, new corporate best practice documents from on high, and major software updates. &#8220;New&#8221; in data science occurs in those places. It also occurs to a much larger extent on Slack, Twitter, Podcasts, and Medium articles. New techniques, new results, entirely new libraries are often announced via those methods before they are published in a journal or integrated into a GUI software application your organization might purchase. The flip side of using the methods below to ingest new data science content is the deluge can sometimes get overwhelming.</p>
<h3>Slack Communities</h3>
<p>Why? =&nbsp;Because your niche interest area may not perfectly overlap with the people you interact with on a daily basis. Even if it does, the number of people is going to be small. Slack is a way to expand that community discussion digitally. Slack is an asynchronous communication platform built around channels, which each have a different topic. The <a href="https://softwareunderground.org/slack/">softwareunderground</a> slack team is all about computing &amp; geoscience. Anyone can join. A few example channels are geospatial, houston, js, kaggle, open-geoscience, python, r-users, reading, and viz.</p>
<ul>
<li><a href="https://softwareunderground.org/slack/">https://softwareunderground.org/slack/</a> : You can join at this link. Cheers to the&nbsp;<a href="https://agilescientific.com/">Agile Scientific</a> group for setting it up.</li>
</ul>
<h3>Twitter</h3>
<p>Why? =&nbsp;Because if Slack, PodCasts, Medium, Journals, etc. all have a frequency, Twitter is the fastest. New libraries, cool examples, interesting discussions of connected threads, will all appear here first before they appear elsewhere. The girl who builds the crazy visualizations that inspire your next project. She&#8217;ll post drafts to Twitter. Someone recently discovered a rarely used but super useful function for your domain in a general purpose Python library. They&#8217;ll post that to Twitter. Twitter isn&#8217;t just data science, of course. You&#8217;ll have to curate your feed by following people with good content, and that takes time, but it is an option for ingesting content at the cutting edge.</p>
<ul>
<li><a class="ProfileHeaderCard-screennameLink u-linkComplex js-nav" href="https://twitter.com/JustinGosses"><span class="username u-dir" dir="ltr">@<b class="u-linkComplex-target">JustinGosses</b></span></a></li>
<li><a href="https://twitter.com/januaryadvisors">@januaryadvisors</a></li>
<li><a href="https://twitter.com/landlabtoolkit">@landlabtoolkit</a></li>
<li><a href="https://twitter.com/fatiandoaterra">@fatiandoaterra</a></li>
<li><a href="https://twitter.com/PaulHCleverley">@PaulHCleverley</a></li>
<li><a href="https://twitter.com/vaex_io">@vaex_io</a></li>
<li><a href="https://twitter.com/ncasenmare">@ncasenmare</a></li>
<li><a href="https://twitter.com/jordansread">@jordansread</a></li>
</ul>
<h3>PodCasts</h3>
<p>Why? =&nbsp;Because data science isn&#8217;t just in text form.</p>
<ul>
<li><a href="https://dataskeptic.com/">DataSkeptic</a>&nbsp;: Data Science Explanations &amp; Discussion</li>
<li><a href="https://undersampledrad.io/">under sampled radio</a>&nbsp;: Geology + Computing</li>
</ul>
<h3>Medium</h3>
<p>Why? =&nbsp;Because getting a few things into your head via 5-30 minutes of reading is sometimes the exact right size of learning.</p>
<ul>
<li><a href="https://hackernoon.com/@kozyrkov?source=user_profile---------0---------------------">https://hackernoon.com/@kozyrkov</a> : <a class="ds-link ds-link--styleSubtle link link--darken link--accent u-accentColor--textNormal u-accentColor--textDarken" dir="auto" href="https://hackernoon.com/@kozyrkov?source=user_profile---------0---------------------" data-action="show-user-card" data-action-source="user_profile---------0---------------------" data-action-value="2fccb851bb5e" data-action-type="hover" data-user-id="2fccb851bb5e" data-collection-slug="hacker-daily">Cassie Kozyrkov</a>&nbsp;Chief Data Intelligence Engineer at Google. She&nbsp;does a great job condensing down the subject matter into small useful bits of explanation you can use with other people without becoming fluffy like so many other pieces in&nbsp;Forbes or Business Insider that cover similar ground.</li>
<li><a href="https://medium.com/multiple-views-visualization-research-explained">https://medium.com/multiple-views-visualization-research-explained</a> : Explains data visualization research just like the name says. Written by a collection of academic data visualization researchers.</li>
<li><a href="https://medium.com/vis-gl">https://medium.com/vis-gl</a> : Uber&#8217;s data visualization group does some great stuff and open-sources a lot of it. This is a place to learn about new tools that combine JavaScript, data visualization, and geospatial.</li>
</ul>
<h3>LinkedIN</h3>
<p>Why? =&nbsp;Well to be honest, I&#8217;m not sure I get that much from LinkedIN, but it is good for finding out about small conferences or meetings with a data science focus that intersect with geology or oil &amp; gas.</p>
<ul>
<li><a href="https://www.linkedin.com/company/spe-gulf-coast-section/">https://www.linkedin.com/company/spe-gulf-coast-section/</a> : Society of Petroleum Engineers has an active data analytics section in Houston</li>
</ul>
<p>&nbsp;</p>
<p>&nbsp;</p>
<h2>Happy Coding!</h2>
<h2><iframe loading="lazy" class="giphy-embed" src="https://giphy.com/embed/JIX9t2j0ZTN9S" width="480" height="480" frameborder="0" allowfullscreen="allowfullscreen"></iframe></h2>
<p>Caption: In reality the cat should spend a third of this time googling things he forgot while looking frustrated.</p>
]]></content:encoded>
					
					<wfw:commentRss>/geologist-to-data-science-starter-pack/feed/</wfw:commentRss>
			<slash:comments>2</slash:comments>
		
		
			</item>
		<item>
		<title>Shortening the distance between creators and creation in geo-computing</title>
		<link>/shortening-the-distance-between-creators-and-creation/</link>
					<comments>/shortening-the-distance-between-creators-and-creation/#respond</comments>
		
		<dc:creator><![CDATA[Justin]]></dc:creator>
		<pubDate>Mon, 04 Jun 2018 04:33:51 +0000</pubDate>
				<category><![CDATA[code]]></category>
		<category><![CDATA[geology]]></category>
		<category><![CDATA[Bret Victor]]></category>
		<category><![CDATA[Geology]]></category>
		<category><![CDATA[javascript]]></category>
		<category><![CDATA[python]]></category>
		<category><![CDATA[wellio.js]]></category>
		<category><![CDATA[widget]]></category>
		<guid isPermaLink="false">https://54.87.153.110/?p=1066</guid>

					<description><![CDATA[Inspiration Bret Victor is a well known thinker on the future and possibilities of human &#8211; computer interface. His website contains a variety of thought provoking projects, and his talks have inspired many other works. Currently, he&#8217;s leading development of Dynamicland, a new way of interacting with and creating computer<a class="moretag" href="/shortening-the-distance-between-creators-and-creation/"> Read more&#8230;</a>]]></description>
										<content:encoded><![CDATA[<h3>Inspiration</h3>
<p><a href="https://en.wikipedia.org/wiki/Bret_Victor">Bret Victor</a> is a well known thinker on the future and possibilities of human &#8211; computer interface. <em>His <a href="http://worrydream.com/">website</a> contains a variety of thought provoking projects, and his talks have inspired many other <a href="https://hacks.mozilla.org/2012/04/bret-victors-inventing-on-principle-and-a-few-things-it-inspired/">works</a>.</em></p>
<p>Currently, he&#8217;s leading development of <a href="https://dynamicland.org/">Dynamicland</a>, a new way of interacting with and creating computer programs that involves image recognition, paper, and projectors. The best way to understand it is by watching <a href="https://twitter.com/dynamicland1?lang=en">videos of people using it</a>.</p>
<p>In one of his most well known talks &#8220;<a href="https://www.youtube.com/watch?v=PUv66718DII">Inventing on Principle</a>&#8221; he discusses his principle that <em><strong>&#8220;creators need an immediate connection to what they create&#8221;</strong></em>. <span style="text-align: center;">Although it can be interpreted as a call to create completely new ways for interacting with computers, like in </span><a style="text-align: center;" href="https://dynamicland.org/">Dynamicland</a><span style="text-align: center;">, or creating reactive programming interfaces with more immediate feedback, like Nicky Case&#8217;s <a href="http://ncase.me/joy/">joy.js</a>, we can also read this as an encouragement to look for more incremental improvements that shorten the distance between creator and what they create. </span><strong style="text-align: center;">I think the incremental version of this concept is illustrative in regards to what open-source side products people might work on in geo-computing. </strong></p>
<h3>State of things</h3>
<p>I previously worked for nine years in the oil and gas industry. Most oil and gas software is a collection of clicks and drop-down menus. Sometimes the steps users follow are not too different from the original process done with paper and pencil. Although I no longer work with that type of data professionally, I still play with geoscience data via side projects. I leverage open-source libraries and although they are more flexible, I&#8217;ve sometimes found myself struggling to quickly try different things, visualize the result, and iterate. Too often I have to re-type code, hit return, repeat and see the result. Additionally, getting geoscience data into open-source software built for other types of data at times feels either hacky or too great a leap. This is especially true in JavaScript where, I would argue, most of the current amazing new things in data visualization tend to occur but few geoscientists venture, as they tend to stay to Python. In all of these cases, the distance between creator and creation is a bit larger than it could be, which makes exploring hypothesis spaces slow. This slowness limits what you can or might end up doing.</p>
<blockquote>
<p style="text-align: center;"><em>How can we shrink the distance between creator and creation in geo-computing?</em></p>
<p>&nbsp;</p></blockquote>
<p>I often see two ways.</p>
<p><em>First</em>, we can make it easier to leverage the wide variety of open-source libraries when working with geoscience data, <em><strong>a glue and adapter approach</strong>.</em> Too often getting data into the right form is either slow and hacky or simply doesn&#8217;t exist. Small tools that solve common problems.</p>
<p><em>Second</em>, we can make it easier to do many iterations quickly, <strong><em>a widgetization approach</em></strong>. Specifically, iterate more through mouse movements and other inputs that are continuous more and iterate less through discrete inputs like typing, clicking, or recalculating. This makes it faster and more enjoyable to explore a hypothesis space and stumble onto different ways to visualize raw data in aggregate or other form.</p>
<h2>Glue &amp; adapters</h2>
<p>Working with geoscience data in any open-source library requires getting the data in. This is less of a problem in analytics focused Python libraries like SciPy and Pandas, in part because people have built great tools like <a href="https://github.com/Statoil/segyio">SEGYIO (seismic)</a>, <a href="https://github.com/kinverarity1/lasio">LASIO</a> (well logs), and <a href="https://github.com/agile-geoscience/welly">WELLY</a> (well logs). Adapters and glue libraries in JavaScript are more lacking. This is understandable as most scientists learn Python, for <a href="https://www.researchgate.net/journal/0885-7156_Powder_Diffraction">good reasons</a>, but unfortunate because many of the cool new projects in data visualization are written in JavaScript, as that&#8217;s the language of the web. To give an example of the limitations, I can&#8217;t find a library for loading and displaying seismic in HTML, CSS, JavaScript that is open-source. This isn&#8217;t because it isn&#8217;t possible to do. <a href="https://info.drillinginfo.com/seismic-analysis-drillinginfo-acquired-transform-software/">Several</a> <a href="https://www.int.com/products/geotoolkit/">companies</a> offer seismic web visualization as part off their cloud services. It is either that no one has made an open-source version, or it isn&#8217;t used much so is hard to find.</p>
<h4>Wellio.js</h4>
<p>As an example of trying to fill this glue and adapter gap for getting well log data to be easily usable in JavaScript data visualization libraries, I&#8217;ve started <a href="https://github.com/JustinGOSSES/wellio.js">Wellio.js</a> as a side project. Wellio.js is both a front-end and back-end (node.js) JavaScript library. It takes in native well log files in LAS 2.0 format and transforms them to <a href="https://en.wikipedia.org/wiki/JSON">JSON</a> format, which JavaScript libraries can read.</p>
<p>Some libraries and tasks that now become easier include:</p>
<ul>
<li><a href="https://github.com/d3/d3/wiki/gallery">D3.js</a>
<ul>
<li>One of the most popular data visualization libraries, it lets you access lower level control so can make pretty much <a href="https://github.com/d3/d3/wiki/gallery">anything.</a></li>
</ul>
</li>
<li><a href="https://vega.github.io/vega/">Vega.js</a>
<ul>
<li>Sorta like d3.js but based on a visualization grammar. You trade some power and flexibility for speed and ease of use.</li>
</ul>
</li>
<li><a href="https://threejs.org/">Three.js</a>
<ul>
<li>Arguably the current standard for quickly making three-dimensional content on the web. You can go in a million directions with it and people <a href="https://threejs.org/examples/#webgl_camera_cinematic">do</a>.</li>
</ul>
</li>
<li><a href="https://github.com/jeromeetienne/AR.js/blob/master/README.md">AR.js</a>
<ul>
<li>Augmented reality without an app or headset, just your browser and your regular smart phone.</li>
</ul>
</li>
</ul>
<p>So what could you do with seismic or well data with the libraries above? With d3.js you can replicate just about any traditional visualization of well log data. <a href="https://github.com/agile-geoscience/g3">G3.js</a> is a partially completed library but still pretty cool library that attempts this. The Wellio.js github page has <a href="https://justingosses.github.io/wellio.js/">a demo that uses g3.js.</a> One of the advantages of using JavaScript is all the computation can be done client side. This means you can upload to a web application your own well logs to be visualized or analyzed and no data gets sent to a cloud server, it all stays in your browser. Additionally, you don&#8217;t have to install any software or code.</p>
<p>With vega.js, wellio.js, and ObservableHQ you can then quickly &amp; interactively <a href="https://beta.observablehq.com/@justingosses/spearman-correlation-coefficient-using-i-spearmanrho-i">visualize</a> &amp; <a href="https://beta.observablehq.com/@justingosses/spearman-correlation-coefficient-using-i-spearmanrho-i">analyze</a> well curves in the browser and write little bits of code to interactively try new things. Here is <a href="https://beta.observablehq.com/@justingosses/spearman-correlation-coefficient-using-i-spearmanrho-i">an example</a> that plays around with the spearman&#8217;s correlation coefficient.</p>
<p><div id="attachment_1102" style="width: 650px" class="wp-caption aligncenter"><a href="https://beta.observablehq.com/@justingosses/three-js-well-log-demo-geology"><img aria-describedby="caption-attachment-1102" loading="lazy" class="wp-image-1102 size-large" src="http://54.87.153.110/wp-content/uploads/2018/06/Screen-Shot-2018-06-03-at-11.38.55-PM-1024x731.png" alt="3D well logs in three.js" width="640" height="457" srcset="/wp-content/uploads/2018/06/Screen-Shot-2018-06-03-at-11.38.55-PM-1024x731.png 1024w, /wp-content/uploads/2018/06/Screen-Shot-2018-06-03-at-11.38.55-PM-300x214.png 300w, /wp-content/uploads/2018/06/Screen-Shot-2018-06-03-at-11.38.55-PM-768x549.png 768w, /wp-content/uploads/2018/06/Screen-Shot-2018-06-03-at-11.38.55-PM.png 1890w" sizes="(max-width: 640px) 100vw, 640px" /></a><p id="caption-attachment-1102" class="wp-caption-text">3D well logs in three.js</p></div></p>
<p>Once well log data is in JSON, it becomes easy to work with it in <a href="https://threejs.org/">three.js</a> to make <a href="https://beta.observablehq.com/@justingosses/three-js-well-log-demo-geology">3D visualizations as shown in this basic example</a> on Observable that you can edit and change.</p>
<p>AR.js is a library I have some experience with in the augmented reality space. I&#8217;ve used it to create <a href="https://twitter.com/JustinGosses/status/848636777028096001">an Augmented Reality business card with a 3D depiction of Gale Crater on Mars</a>. AR.js can use three dimensional visualizations created in three.js. As shown above, we can visualize well logs in three.js after converting the well logs LAS 2.0 formatted file into JSON. There is nothing stopping us from having a paper map with symbols on it that bring up augmented reality well logs and surfaces such that we could look at the subsurface in field using only a paper map and the cell phone you already have in your pocket.</p>
<h2>Widgetization</h2>
<p>How do we make exploring hypothesis spaces faster and easier and less constrained with widgets? I&#8217;ll start off by saying I&#8217;m not entirely satisfied with any of the solutions out there. The level of immediate feedback depicted in <a href="https://www.youtube.com/watch?v=PUv66718DII">this Bret Victor video</a> with the programmatically drawn tree is hard to get to and still be flexible enough to tackle a different problem quickly. Generally the approaches to these types of problems describe themselves as either a GUI (graphic user interface) library, a widget library, or a reactive computer library or language. GUIs are all about building a graphic user interface for the end-user where code is probably not exposed. Widgets are sliders, buttons, wheels, and other sorts of graphical conventions that users can use to quickly change a variable&#8217;s value across a continuous range. Reactive libraries like <a href="http://ncase.me/joy/">joy.js</a> attempt to mimic some of the magic depicted in Bret Victor&#8217;s talk while flexible enough to allow people to build their own.</p>
<h4>Example tools for widgetization:</h4>
<ul>
<li><a href="https://beta.observablehq.com/collection/explorables">ObservableHQ (webpage that executes end-user-typed JavaScript in real time inside notebook like enviornment)</a></li>
<li><a href="http://ipywidgets.readthedocs.io/en/stable/user_guide.html">Jupyter Widgets (widget add-on for Jupyter notebooks)</a></li>
<li><a href="https://bokeh.pydata.org/en/latest/docs/user_guide/interaction/widgets.html">Bokeh Widgets (Like Jupyter widgets but for Python Bokeh data visualization library)</a></li>
<li><a href="https://wiki.python.org/moin/Intro%20to%20programming%20with%20Python%20and%20Tkinter">TKinter (Old school but still works GUI builder for Python)</a></li>
<li><a href="https://wxpython.org/pages/overview/">WXpython </a><a href="https://wiki.python.org/moin/Intro%20to%20programming%20with%20Python%20and%20Tkinter">(Old school but still works GUI builder for Python)</a></li>
<li><a href="https://idyll-lang.org/gallery">Idyll-lang(JavaScript library, for explorable explanations)</a></li>
<li><a href="http://ncase.me/joy/">Joy.js (reactive style JavaScript Library, the closest to Bret Victor flower demo)</a></li>
</ul>
<h4>Two Small Examples</h4>
<p>Examples of some experiments I&#8217;ve done recently in ObservableHQ with a little widgetization include <a href="https://beta.observablehq.com/@justingosses/spearman-correlation-coefficient-using-i-spearmanrho-i">this quick demo of well logs and a correlation coefficient </a> and this experiment in <a href="https://beta.observablehq.com/@justingosses/1st-try-converting-well-log-data-into-audio-not-very-success">sonifying well logs</a>.</p>
<h4>Example of a widget-ed data visualization I want that doesn&#8217;t exist yet:</h4>
<p>There&#8217;s a widget I&#8217;ve been wanting but haven&#8217;t built yet. It would be useful for machine-learning predictions of either stratigraphic surfaces or facies. I would like to have a function that creates a new feature from original features along a well bore. All the variables in the function would be draggable widgets like in <a href="http://ncase.me/joy/demo/nonlinear/">this</a> joy.js example. There would be immediate linkage between this function and several other visualization on the page, similar to how <a href="https://dc-js.github.io/dc.js/">dc.js works</a>. One would be a <a href="https://www.spec2000.net/01-beginnersguide.htm">typical vertical well curve visualization</a>. The other a scatter plot with points colored by label class. Labels might be facies or at &#8220;pick&#8221;, &#8220;near pick&#8221;, and &#8220;away from pick&#8221;. Lastly, there would be a random forest tree visualized as a tree of links and nodes. I would be able to select all the data downstream of a specific node and use that data in the visualizations. Both the well curve plot and the scatter plot would be <a href="https://www.visualcinnamon.com/2016/07/brush-bar-chart-d3.html">brushable</a>, meaning data selected in one visualization is highlighted in the others. I think this type setup, where you can immediately see the effect of different choices in your feature creation function on how labels are clustered could greatly speed up the process of engineering effective features as a replacement for all the different types of observations we make when we look at a log.</p>
<h4>And now for something completely different: Alternative Means of User Input?</h4>
<p><a href="http://54.87.153.110/wp-content/uploads/2018/06/KinectPottery.jpg"><img loading="lazy" class="wp-image-1101 size-medium alignleft" src="http://54.87.153.110/wp-content/uploads/2018/06/KinectPottery-225x300.jpg" alt="KinectPottery" width="225" height="300" srcset="/wp-content/uploads/2018/06/KinectPottery-225x300.jpg 225w, /wp-content/uploads/2018/06/KinectPottery-768x1024.jpg 768w, /wp-content/uploads/2018/06/KinectPottery.jpg 900w" sizes="(max-width: 225px) 100vw, 225px" /></a></p>
<p>Another way to make user input and exploration continuous instead of discrete and get real-time feedback, is to change the means of input away from mouse and keyword entirely. This is related to widgetization but maybe another step down the line? In <a href="https://twitter.com/JustinGosses/status/999417519877312512">the</a> image above taken at the Cleveland Museum of Art, a user is molding a digital representation of clay with their hands. Could the same technique work for salt bodies in 3D seismic? Clicking takes a lot of time for seismic interpretation and has health and safety implications. Why not drawing? I can draw lines over seismic with a digital pen significantly better than I can with a mouse click hold. Kinect cameras capture 3D surfaces and create digital topography on a small human scale. A popular geoscience education use of Kinect cameras is an <a href="https://arsandbox.ucdavis.edu/">augmented reality sandboxes</a>. Can kinect&#8217;s be used for input into technical problems too? Additionally <a href="https://webgazer.cs.brown.edu/">eye tracking</a> and <a href="https://github.com/CMU-Perceptual-Computing-Lab/openpose">body tracking</a> technology that leverage machine-learning is getting good enough to start considering practical use. Are there use-cases where these types of inputs are preferred or could be used in addition to mouse clicking?</p>
<h3></h3>
<h3>Conclusion</h3>
<p>I&#8217;m not Bret Victor, and you&#8217;re probably not either (if you&#8217;re actually Bret Victor, hi). Although creating things at his level is inspiring, it is also difficult. Aiming for a little in that direction, however, is perhaps instructive in terms of identifying  opportunities to make something cool and even potentially useful.</p>
<p>&nbsp;</p>
]]></content:encoded>
					
					<wfw:commentRss>/shortening-the-distance-between-creators-and-creation/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>half-baked thoughts on predicting chronostratigraphic surfaces</title>
		<link>/thoughts-on-machine-learning-predictions-of-chronostratigraphic-surfaces/</link>
					<comments>/thoughts-on-machine-learning-predictions-of-chronostratigraphic-surfaces/#comments</comments>
		
		<dc:creator><![CDATA[Justin]]></dc:creator>
		<pubDate>Fri, 18 May 2018 02:45:29 +0000</pubDate>
				<category><![CDATA[Uncategorized]]></category>
		<guid isPermaLink="false">https://54.87.153.110/?p=1075</guid>

					<description><![CDATA[EDIT: Released a package for predicting well log tops called, Predictatops &#8212;&#8212;&#8212;&#8212;&#8212;&#8212;- Why make half-baked thoughts public? / Disclaimer I think predicting stratigraphic surfaces in well logs programmatically is a really interesting, if difficult, problem.  I&#8217;ve been working on it from time to time over the last few months as<a class="moretag" href="/thoughts-on-machine-learning-predictions-of-chronostratigraphic-surfaces/"> Read more&#8230;</a>]]></description>
										<content:encoded><![CDATA[<h2>EDIT: Released a package for predicting well log tops called, <a href=" https://justingosses.github.io/predictatops/html/index.html">Predictatops</a></h2>
<p>&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;-</p>
<h3>Why make half-baked thoughts public? / Disclaimer</h3>
<p>I think predicting stratigraphic surfaces in well logs programmatically is a really interesting, if difficult, problem.  I&#8217;ve been working on it from time to time over the last few months as a side project after starting it as a hackathon project. A person I know from the twitter-verse is going to this years version of the same AAPG hackathon and wanted to work on the same problem. He contacted me for suggestions. Although I&#8217;ve gotten some encouraging results, there are lots of paths to improvement that have not been to be tested. That means I have a lot of interesting but very likely wrong ideas in my head, which I&#8217;m sharing below. I&#8217;m also coming of 13 hours of jet lag. I apologize in advance for everything being a bulleted list and maybe not entirely making sense at times. Good luck!</p>
<p>&nbsp;</p>
<h3>Some Basics for the non-geologists:</h3>
<h4>What are well logs?</h4>
<p>Well logs are basically point measurements taken at set intervals along a well bore drilled into the earth. Typically, a half a foot is a common interval. These measurements are often visualized as line graphs tilted on their side. Depth is the y axis. Measurement of some physical property is the x axis. The number of different types of measurements, well curves, in a well varies. Typically, it might be three to twelve different curves. Wikipedia has some <a href="https://en.wikipedia.org/wiki/Well_logging">good general information</a> on well logs.</p>
<h4>What type of correlation?</h4>
<p>Geologists like to break things into formations and units. Basically, to say this bit of well A is the same as well B. Often, the implication is the rocks in unit A in one well are the same age as rocks in unit A in another well, hence chronostratigraphic correlation.</p>
<p>Due to the fact that well logs don&#8217;t directly measure age, chronostratigraphic correlations are interpretations by a geologist based on what they think formation A and formation B <em>should</em> look like.</p>
<p>If you&#8217;re not doing chronostratigraphic correlation, you&#8217;re likely doing lithostratigraphic correlation. In this type of correlation, you just correlating rocks with similar lithology. Sands to sands. Shales to Shales.</p>
<p>Lithostratigraphic correlation has an advantage in being done programmatically in that it doesn&#8217;t attempt to make very long correlations and the variance that has to be dealt with is smaller. For this reason, machine-learning or programmatic lithostratigraphic correlation between only two wells is possible, and probably preferred, where as you need a larger population of wells to do chronostratigraphic correlation using machine-learning.</p>
<p>A good example of programmatic lithostratigraphic correlation is the <a href="http://www.kgs.ku.edu/Publications/OFR/2002/OFR02_51/ManualOFR2002-51.pdf">CORRELATOR</a> Fortran-based software out of the <a href="http://www.kgs.ku.edu/software/softwareIndex.html">Kansas Geological Survey</a>.</p>
<h3></h3>
<h3>Geologic Truths that would be nice to include some how in any sort of automated approach?</h3>
<ol>
<li>Shales are more important than sands for correlating.</li>
<li>Surfaces have appearances than change both gradually over a region and over very short distances.</li>
<li>Usually if certain primary characteristics of a surface are not locally present, other secondary characteristics will still be present.</li>
<li>Very large changes in characteristics are unlikely to only appear once. They are commonly caused by salt dissolution, faults, or channelized erosion, which means their distribution may be localized but unlikely to just one well.</li>
</ol>
<p>&nbsp;</p>
<h3>Big simplistic concepts I like</h3>
<ol>
<li>If we think carefully about the types of observations geologists make while looking at logs and correlating them, we can come up with good ways to mimic those observations with quantitative programmatically generated features for machine-learning.</li>
<li>Class expression (whether or not a point is the surface in question) is highly variable. Your program should be able to deal with high variance and a some noise.</li>
</ol>
<p>&nbsp;</p>
<h3>Big simplistic concepts I don&#8217;t like</h3>
<ol>
<li>The idea that applying a single fancy math technique to raw data will work, because there is an underlying mathematical pattern to well log curves that makes them predictable (This is typically said by physicist or physics-inclined and really could be any domain they stumble into).</li>
<li>Fractals (just because you can squint and see them everywhere doesn&#8217;t mean they are useful for prediction).</li>
</ol>
<p>&nbsp;</p>
<h3>Parts I&#8217;m very certain about</h3>
<ol>
<li>To predict whether or not a point in a well is a specific time surface, you need to leverage information about that point, the points above and below it, the transition of points above and below it, points in neighboring wells, and information about known surfaces both locally and regionally &#8211; all in regards to that point in question that you are trying to determine whether or not is ___ chronostratigraphic surface.</li>
</ol>
<p>&nbsp;</p>
<h3>Thoughts I like but might be wrong</h3>
<ol>
<li>The need for many engineered features (and more than I have right now 40-60 features in total)</li>
<li>Tree-based machine-learning algorithms, like random forests or xgboost, are a way to go both as they are more self-explanatory (not a black box as you can see all the decision points) and deal well with spatial differences in class characteristics.</li>
<li>The <a href="http://www.kgs.ku.edu/Publications/OFR/2002/OFR02_51/ManualOFR2002-51.pdf">pearson correlation &amp; shale character based approach</a> for programmatic lithostratigraphic correlation taken by the CORRELATOR software can be used in a machine-learning based approach as additional features.</li>
</ol>
<p>&nbsp;</p>
<h3>Thoughts I give less weights but might be useful</h3>
<ol>
<li>Ideally, you&#8217;d leverage as many logs as possible but should start with Gamma-ray.</li>
<li>Learning more and more towards some sort of multi-step approach in which a first round of prediction is done and then leveraged in second round.</li>
<li>Leveraging aggregate and map-based information on groupings from known wells and applying those groupings manually is a good idea.</li>
<li>Doing a two step machine-learning process where first step generates a class of unit name for each point and second step predicts a probability of each of the points being the pick in question. This might deal with some of the false positives and better take advantage of the some of the higher certainty information away from the point in question or away from the actual pick position.</li>
<li>Wavelet transform and <a href="https://ieeexplore.ieee.org/abstract/document/993193/">other approaches </a>have been useful in ECG waveform classification in the medical field. Although, I think these approaches won&#8217;t be as useful in well log correlation due to the wide variance in surface character, there might be a way to use them for local comparison of 2-5 wells where appearances are more likely to be similar, though this risks becoming strongly lithostratigraphic.</li>
</ol>
<p>&nbsp;</p>
<h3>Things I wonder about</h3>
<ol>
<li>What is the best way to included information about the the sequence of log curve data significantly above or below the point in question?
<ol>
<li>What would be the best way to combine LSTM (long-short term memory) into the process?</li>
<li>Is LSTM even needed or can that information be included in other ways?</li>
<li>What are other ways?</li>
</ol>
</li>
<li>What other features can I create from the well curve data?</li>
<li>Normalization:
<ol>
<li>To what degree do I need to normalize both raw and calculated data?</li>
<li>How much could this be throwing off the results?</li>
<li>What would be the best way to go about doing that given the raw data isn&#8217;t collected the same way every time?</li>
</ol>
</li>
</ol>
<h3></h3>
<h3>My current work in this problem space</h3>
<ul>
<li><a href="https://github.com/JustinGOSSES/MannvilleGroup_Strat_Hackathon">MannvilleGroup_Strat_Hackathon</a></li>
</ul>
<p>&nbsp;</p>
<h3>Good Reads</h3>
<ol>
<li><a href="http://www.kgs.ku.edu/Publications/OFR/2002/OFR02_51/ManualOFR2002-51.pdf">CORRELATOR User&#8217;s Manual : Lithostratigraphic Correlation in Fortran</a></li>
<li>&#8220;<a href="https://csegrecorder.com/articles/view/using-the-scattering-transform-to-predict-strat-units-from-well-logs">Using the Scattering Transform to Predict Stratigraphic Units from Well Logs</a>&#8220;, by Ben Bougher, Felix J. Herrmann</li>
</ol>
<h3></h3>
<h3>Possible algorithms<strong><br />
</strong></h3>
<p>I like tree-based algorithms for this problem it seems like they would deal well with class characteristics changing spatially and there are ways to visualizing the resulting leaves of a decision tree, which eliminates a lot of the black-box problem some people have with machine-learning. Additionally, if you can see into the algorithm decision making process, it might inspire creation of additional features or even new ways of looking at the geology.</p>
<ol>
<li>Extreme boosted trees or <a href="http://xgboost.readthedocs.io/en/latest/model.html">XGBoost</a></li>
<li>Random Forest</li>
<li>Some combination of LSTM and random forest&#8230;. not sure the best way to combine? Do LTSM only locally?</li>
</ol>
<h3></h3>
<h3>Notes on setting up the problem</h3>
<ul>
<li>If you judge success by trying to predict the formation of every point, you&#8217;ll appear to get decent results pretty easily. What you should really be going for is the picks. Error should not be % of formation points predicted successfully but rather the average error between predicted pick depth and actual pick depth.</li>
<li>There are 3-4 wells in the Mannville dataset that might give you problems with certain types of feature creation as there is &#8220;bad&#8221; or &#8220;odd&#8221; data in them.</li>
<li>Always useful to look at the actual wells before, during, and after trying to do machine-learning projects.</li>
</ul>
<p><div id="attachment_1091" style="width: 650px" class="wp-caption aligncenter"><a href="http://54.87.153.110/wp-content/uploads/2018/05/Mannville_Xsection_B.png"><img aria-describedby="caption-attachment-1091" loading="lazy" class="size-large wp-image-1091" src="http://54.87.153.110/wp-content/uploads/2018/05/Mannville_Xsection_B-1024x723.png" alt="Alberta Geological Survey Open File Report 1994-14. Cross-section B to B&#96;." width="640" height="452" srcset="/wp-content/uploads/2018/05/Mannville_Xsection_B-1024x723.png 1024w, /wp-content/uploads/2018/05/Mannville_Xsection_B-300x212.png 300w, /wp-content/uploads/2018/05/Mannville_Xsection_B-768x542.png 768w, /wp-content/uploads/2018/05/Mannville_Xsection_B.png 2000w" sizes="(max-width: 640px) 100vw, 640px" /></a><p id="caption-attachment-1091" class="wp-caption-text">Alberta Geological Survey Open File Report 1994-14. Cross-section B to B`.</p></div></p>
<p><div id="attachment_1092" style="width: 650px" class="wp-caption aligncenter"><a href="http://54.87.153.110/wp-content/uploads/2018/05/MannvilleWellsMap.png"><img aria-describedby="caption-attachment-1092" loading="lazy" class="size-large wp-image-1092" src="http://54.87.153.110/wp-content/uploads/2018/05/MannvilleWellsMap-824x1024.png" alt="Map of Mannville wells in the Alberta Geological Survey open file report 1994-14 that are used in the project I'm doing at the github link." width="640" height="795" srcset="/wp-content/uploads/2018/05/MannvilleWellsMap-824x1024.png 824w, /wp-content/uploads/2018/05/MannvilleWellsMap-241x300.png 241w, /wp-content/uploads/2018/05/MannvilleWellsMap-768x954.png 768w, /wp-content/uploads/2018/05/MannvilleWellsMap.png 1102w" sizes="(max-width: 640px) 100vw, 640px" /></a><p id="caption-attachment-1092" class="wp-caption-text">Map of Mannville wells in the Alberta Geological Survey open file report 1994-14 that are used in the project I&#8217;m doing at the github link. The data is <a href="http://ags.aer.ca/publications/SPE_006.html">here</a> and the <a href="http://ags.aer.ca/document/OFR/OFR_1994_14.PDF">Open File 1994-14</a> report is useful reading.</p></div></p>
<p>&nbsp;</p>
<h3>Basic Features</h3>
<ol>
<li>Raw values at a depth in a well &amp; normalized values</li>
<li>For different windows above, below, around a point in question:
<ol>
<li>average, sum, max, min, max/min</li>
<li>ranges</li>
<li>slopes</li>
<li>variance</li>
<li>slope variance</li>
<li>same as everything above but for higher or lower ___ number of points</li>
</ol>
</li>
<li>Thickness of unit in question in nearby wells</li>
<li>Where surface would be in well in question if thickness didn&#8217;t change from nearby well</li>
<li>All characteristics from 1 &amp; 2 in nearby wells with known surfaces</li>
</ol>
<h3></h3>
<h3>Things that would make this problem easier but don&#8217;t exist yet?</h3>
<ol>
<li>Multiple datasets of equal size to the Manville dataset. These would be handy to test the degree of generalization of the methods (not the model).</li>
<li>A widget for playing / creating new features that would let me see how new features relate to class identification across single and multiple wells without a lot of clicks but mostly just drags and rotates, such that the hypothesis space can be explored quickly.
<ol>
<li>EXAMPLE:
<ol>
<li>Elements of :
<ol>
<li>code input box</li>
<li>Widgets that let your drag to change values of variables in the code.
<ol>
<li>Examples of variables changed via a slider:
<ol>
<li>window length</li>
<li>Minimum slope angle</li>
<li>etc.</li>
</ol>
</li>
</ol>
</li>
<li>cross-section of well log(s)</li>
<li>scatter plot in 3D with colors being classes (probably unit names or pick, near pick, and not pick.)</li>
</ol>
</li>
<li>Behavior:
<ol>
<li>In real-time dragging the sliders back and forth changes the display of the feature along the well curve in each well. At the same time, the data for the well(s) in question is automatically altered in a scatter plot generated using three features as the x, y, z axis and class name (probably something like pick, within 5 meters of pick, and not pick) as the color of the point.</li>
<li>By moving many sliders back and forth I can explore the hypothesis space quickly and find features that separate the classes better.</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
<li>Need better way to visualize pick uncertainty and multiple pick possibilities in single well, multiple ways, and all wells.</li>
</ol>
<h3></h3>
<h3>Hackathon-sized sub-problems to tackle</h3>
<ol>
<li>See number 2 in section directly above.</li>
<li>See number 3 in section directly above.</li>
<li>What&#8217;s the best way to identify sub-regional trends like thickness, background shale value, chance of confusing erosion surfaces, etc. that might correlate with surface appearance changes and be identified as within certain spatial areas from known wells.</li>
<li>CORRELATOR used a small expert knowledge system with their more programmatic work. Can something similar be done here?</li>
<li>What are the different ways to visualize error in pick prediction or multiple different potential pick positions based on probability?</li>
<li>Optimize the feature creation code here: <a href="https://github.com/JustinGOSSES/MannvilleGroup_Strat_Hackathon">MannvilleGroup_Strat_Hackathon</a></li>
<li>In the mannville dataset, there are a large number of wells with facies identified as well. Can the distribution of facies be used as another feature? What would it add?</li>
<li>Re-build at least part of CORRELATOR in python, instead of Fortran, and then use comparisons of neighbor wells for features. Alternatively, use a completely different correlation coefficient approach that does something roughly similar (but easier) that could at least provide some ballpark constraints on where the other features should be looking.</li>
<li>Can we create an expert system to quantitatively identify and describe circumstances where lithostratigraphy is likely fine or likely not fine?
<ol>
<li>Prograding parasquences?</li>
<li>Transgressive surface hard grounds?</li>
</ol>
</li>
</ol>
]]></content:encoded>
					
					<wfw:commentRss>/thoughts-on-machine-learning-predictions-of-chronostratigraphic-surfaces/feed/</wfw:commentRss>
			<slash:comments>2</slash:comments>
		
		
			</item>
		<item>
		<title>Using Machine-learning to Extend Stratigraphic Surfaces</title>
		<link>/stratigraphicpicks/</link>
					<comments>/stratigraphicpicks/#respond</comments>
		
		<dc:creator><![CDATA[Justin]]></dc:creator>
		<pubDate>Wed, 27 Sep 2017 23:25:57 +0000</pubDate>
				<category><![CDATA[code]]></category>
		<category><![CDATA[geology]]></category>
		<category><![CDATA[Geology]]></category>
		<category><![CDATA[machine-learning]]></category>
		<category><![CDATA[ML]]></category>
		<category><![CDATA[stratigraphic]]></category>
		<guid isPermaLink="false">https://54.87.153.110/?p=965</guid>

					<description><![CDATA[[BLOG POST COMING SOON] This weekend I finally got to do a hackathon project I&#8217;ve been wanting to try for more than two years. It leverages machine-learning to mimic human-created stratigraphic picks. It uses a dataset of 2000 wells with picks from the Alberta Energy Regulator, which is one of<a class="moretag" href="/stratigraphicpicks/"> Read more&#8230;</a>]]></description>
										<content:encoded><![CDATA[<p>[BLOG POST COMING SOON]</p>
<p>This weekend I finally got to do a hackathon project I&#8217;ve been wanting to try for more than two years. It leverages machine-learning to mimic human-created stratigraphic picks. It uses a <a href="http://ags.aer.ca/publications/SPE_006.html">dataset</a> of 2000 wells with picks from the Alberta Energy Regulator, which is one of the only public datasets I&#8217;m aware of with that many picks of the same surfaces done by people trying to pick in the same way. We only got the first pass done, as is the nature of hackathons, but we&#8217;re going to keep working on the idea. I think it has a lot of potential. We&#8217;re trying to take a more geologic approach and a less geophysicist or mathematical approach, which has been more typically been used in past efforts.</p>
<p>I&#8217;ll edit this to be a longer post later, but for now here is the link to the project on github.</p>
<p><a href="https://github.com/JustinGOSSES/MannvilleGroup_Strat_Hackathon">https://github.com/JustinGOSSES/MannvilleGroup_Strat_Hackathon</a></p>
<p><div id="attachment_967" style="width: 894px" class="wp-caption aligncenter"><a href="http://54.87.153.110/wp-content/uploads/2017/09/Screen-Shot-2017-09-27-at-6.22.31-PM.png"><img aria-describedby="caption-attachment-967" loading="lazy" class="size-full wp-image-967" src="http://54.87.153.110/wp-content/uploads/2017/09/Screen-Shot-2017-09-27-at-6.22.31-PM.png" alt="Predicted (blue) vs. true depth (red) of the top McMurray pick. " width="884" height="552" srcset="/wp-content/uploads/2017/09/Screen-Shot-2017-09-27-at-6.22.31-PM.png 884w, /wp-content/uploads/2017/09/Screen-Shot-2017-09-27-at-6.22.31-PM-300x187.png 300w" sizes="(max-width: 884px) 100vw, 884px" /></a><p id="caption-attachment-967" class="wp-caption-text">Predicted (blue) vs. true depth (red) of the top McMurray pick.</p></div></p>
<p>&nbsp;</p>
]]></content:encoded>
					
					<wfw:commentRss>/stratigraphicpicks/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
	</channel>
</rss>
