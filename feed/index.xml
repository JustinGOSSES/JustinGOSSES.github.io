<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	xmlns:georss="http://www.georss.org/georss" xmlns:geo="http://www.w3.org/2003/01/geo/wgs84_pos#" >

<channel>
	<title>Justin Gosses Home</title>
	<atom:link href="/feed/" rel="self" type="application/rss+xml" />
	<link>/</link>
	<description>Geology, GIS, and CODE + Resumes</description>
	<lastBuildDate>Mon, 12 Aug 2019 00:35:31 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>hourly</sy:updatePeriod>
	<sy:updateFrequency>1</sy:updateFrequency>
	<generator>https://wordpress.org/?v=4.9.11</generator>

<image>
	<url>https://i1.wp.com/justingosses.com/wp-content/uploads/2017/02/cropped-JustinGosses_logo.jpg?fit=32%2C32</url>
	<title>Justin Gosses Home</title>
	<link>/</link>
	<width>32</width>
	<height>32</height>
</image> 
<site xmlns="com-wordpress:feed-additions:1">102288347</site>	<item>
		<title>Predictatops</title>
		<link>/predictatops/</link>
		<comments>/predictatops/#respond</comments>
		<pubDate>Sat, 10 Aug 2019 20:34:18 +0000</pubDate>
		<dc:creator><![CDATA[Justin]]></dc:creator>
				<category><![CDATA[code]]></category>
		<category><![CDATA[geology]]></category>
		<category><![CDATA[Canada]]></category>
		<category><![CDATA[Geology]]></category>
		<category><![CDATA[McMurray]]></category>
		<category><![CDATA[Predicatops]]></category>
		<category><![CDATA[python]]></category>
		<category><![CDATA[Sphinx]]></category>
		<category><![CDATA[stratigraphy]]></category>

		<guid isPermaLink="false">/?p=1217</guid>
		<description><![CDATA[<p>Stratigraphic pick prediction via supervised machine-learning: PredictatopsBack in May, I presented a talk at the 2019 AAPG ACE (American Association of Petroleum Geologist Annual Conference and Exhibit) on using machine-learning to predict stratigraphic surfaces in well logs. I described a Python package I have been working on as a side project called Predictatops. Given I&#8217;ve<a href="/predictatops/">[...]</a></p>
<p>The post <a rel="nofollow" href="/predictatops/">Predictatops</a> appeared first on <a rel="nofollow" href="/">Justin Gosses Home</a>.</p>
]]></description>
				<content:encoded><![CDATA[<h2>Stratigraphic pick prediction via supervised machine-learning: Predictatops</h2><p>Back in May, I presented a talk at the 2019 AAPG ACE (American Association of Petroleum Geologist Annual Conference and Exhibit) on using machine-learning to predict stratigraphic surfaces in well logs. I described a Python package I have been working on as a side project called <a href="https://github.com/JustinGOSSES/predictatops">Predictatops</a>. Given I&#8217;ve mentioned working on the issue of stratigraphic top prediction using machine-learning in previous blog posts, I thought it wise to announce Predictatops here on my website as well.</p>
<div id="attachment_1227" style="width: 310px" class="wp-caption alignleft"><a href="https://i0.wp.com/justingosses.com/wp-content/uploads/2019/08/Yale-Peabody-Triceratops-004Trp.png"><img data-attachment-id="1227" data-permalink="/predictatops/yale-peabody-triceratops-004trp/" data-orig-file="https://i0.wp.com/justingosses.com/wp-content/uploads/2019/08/Yale-Peabody-Triceratops-004Trp.png?fit=1280%2C850" data-orig-size="1280,850" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Yale-Peabody-Triceratops-004Trp" data-image-description="" data-medium-file="https://i0.wp.com/justingosses.com/wp-content/uploads/2019/08/Yale-Peabody-Triceratops-004Trp.png?fit=300%2C199" data-large-file="https://i0.wp.com/justingosses.com/wp-content/uploads/2019/08/Yale-Peabody-Triceratops-004Trp.png?fit=640%2C425" class="size-medium wp-image-1227" src="https://i0.wp.com/justingosses.com/wp-content/uploads/2019/08/Yale-Peabody-Triceratops-004Trp.png?resize=300%2C199" alt="" width="300" height="199" srcset="https://i0.wp.com/justingosses.com/wp-content/uploads/2019/08/Yale-Peabody-Triceratops-004Trp.png?resize=300%2C199 300w, https://i0.wp.com/justingosses.com/wp-content/uploads/2019/08/Yale-Peabody-Triceratops-004Trp.png?resize=768%2C510 768w, https://i0.wp.com/justingosses.com/wp-content/uploads/2019/08/Yale-Peabody-Triceratops-004Trp.png?resize=1024%2C680 1024w, https://i0.wp.com/justingosses.com/wp-content/uploads/2019/08/Yale-Peabody-Triceratops-004Trp.png?resize=750%2C500 750w, https://i0.wp.com/justingosses.com/wp-content/uploads/2019/08/Yale-Peabody-Triceratops-004Trp.png?w=1280 1280w" sizes="(max-width: 300px) 100vw, 300px" data-recalc-dims="1" /></a></p>
<p class="wp-caption-text">Predictatops Logo</p>
</div><p>First, some definitions for the machine-learning folks who stumbled into a geologist blog post and the geologists who stumbled into a machine-learning blog post&#8230;</p><p><strong>Wells:</strong></p><p>Holes drilled in the ground.</p><p><strong>Well Logs:</strong></p><p>Well logs are created when a geophysical measurements are made along a well. These are usually 1D measurements in the sense that a measurement is made at the bottom, then the tool is pulled up a little bit and then another measur<span style="font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen-Sans, Ubuntu, Cantarell, 'Helvetica Neue', sans-serif;">ement is made. This continues until the entirety of the well is measured. Often, many different types of tools are used that measure different properties, resulting in multiple well logs for a single well. They measure things like how fast sound travels between two parts of the well or how much signal is bounced back and measured by a tool after a certain type of radiation is given off by a tool. These measurements are then turned into rock properties like density, grain size, etc. Further explanations of well log measurements are </span><a style="font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen-Sans, Ubuntu, Cantarell, 'Helvetica Neue', sans-serif;" href="https://www.rigzone.com/training/insight.asp?insight_id=298&c_id=">here</a><span style="font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen-Sans, Ubuntu, Cantarell, 'Helvetica Neue', sans-serif;"> and </span><a style="font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen-Sans, Ubuntu, Cantarell, 'Helvetica Neue', sans-serif;" href="https://www.spec2000.net/05-logaliastable.htm">here</a><span style="font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen-Sans, Ubuntu, Cantarell, 'Helvetica Neue', sans-serif;">. The picture below is of a well log.</span></p>
<div id="attachment_1225" style="width: 233px" class="wp-caption alignleft"><a href="https://i0.wp.com/justingosses.com/wp-content/uploads/2019/08/hall_et_all_2016_well_log.png"><img data-attachment-id="1225" data-permalink="/predictatops/hall_et_all_2016_well_log/" data-orig-file="https://i0.wp.com/justingosses.com/wp-content/uploads/2019/08/hall_et_all_2016_well_log.png?fit=375%2C504" data-orig-size="375,504" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="hall_et_all_2016_well_log" data-image-description="" data-medium-file="https://i0.wp.com/justingosses.com/wp-content/uploads/2019/08/hall_et_all_2016_well_log.png?fit=223%2C300" data-large-file="https://i0.wp.com/justingosses.com/wp-content/uploads/2019/08/hall_et_all_2016_well_log.png?fit=375%2C504" class="wp-image-1225 size-medium" src="https://i0.wp.com/justingosses.com/wp-content/uploads/2019/08/hall_et_all_2016_well_log.png?resize=223%2C300" alt="Well logs from a single well. Interpretation of lithology of the rocks on the right in colored bars." width="223" height="300" srcset="https://i0.wp.com/justingosses.com/wp-content/uploads/2019/08/hall_et_all_2016_well_log.png?resize=223%2C300 223w, https://i0.wp.com/justingosses.com/wp-content/uploads/2019/08/hall_et_all_2016_well_log.png?w=375 375w" sizes="(max-width: 223px) 100vw, 223px" data-recalc-dims="1" /></a></p>
<p class="wp-caption-text">Well logs from a single well. Interpretation of lithology of the rocks on the right in colored bars. Hall at al., 2015</p>
</div><p>&nbsp;</p><p><strong>Tops:</strong></p><p>Tops are markers for the tops of things. Specifically, tops of geologic units. Everything below a top is one geologic layer and everything above a top is another geology layer.</p><p><strong>Different Types of Tops:</strong></p><p>Tops can divide different categories of layers. Sometimes the layers are based on characteristics of the rock. For example a top can separate rock made from small grains from rock made of large grains. Tops based on physical make-up of rocks are often called lithologic tops. Lithology is term for describing what a rock is made up of. Facies is another term that refers to categories of rocks in a well with similar characteristics.</p><p>Alternatively, tops can be boundaries based on more actionable characteristics like the ability for fluids to flow. A top might separate a geologic layer where you think the rock will allow fast flow of fluids like water, oil, or gas from a layer below the top where fluids will flow very slowly.</p><p>Geologist&#8217;s favorite way to place a top, however, is to place tops based on time. A top can separate rock deposited at one point in time from rock deposited at the next point of time. This is a stratigraphic or chronostratigraphic top! Also, called a time surface.</p><p>You might have noticed that the lithologic, flow-based, and stratigraphic tops are increasingly abstract.</p><p>The first, lithologic-tops are based on what the rock is made up of, which can be measured, at least indirectly. Flow is a little harder to predict from well logs but the ability of fluids to flow is fundamentally also based on physical characteristics, which can be measured, just with more difficulty as very small characteristics at the level of pores in rocks are what matter.</p><p>Stratigraphic tops are based on age of the rocks. There is no measurement that relates to time that can be done routinely in well logs. You can collect fossils and interpret time based on the fossils found in different units (biostratigraphy). You can find volcanic ash and date it by looking at how much one type of element has turned into a different type of element due to decay (geochronology). However, neither of these can be done on all, or even most, wells. They&#8217;re too expensive and time consuming. Not all depth points will have fossils or ash layers for dating.</p><p><strong>Stratigraphic Correlation:</strong></p><p><em>How then does one go from well logs to stratigraphic tops representing time surfaces? That requires a model, and a head to put it in.</em></p><p>In practice, chronostratigraphic (mapping out time surfaces) well log correlation (correlation means interpreting where a top in well A exists in well B) is a combination of lithostratigraphic correlation (looking at 2 wells and matching curves of the well logs using the assumption that similar looking curves, have similar properties, and are the same layers) and application of conceptual models. These conceptual models cover how sediment is transported and deposited. They are very helpful for stratigraphic correlations as they predict the spatial distribution of different types rocks deposited at the same time and how those spatial associations can change over time. <span style="font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen-Sans, Ubuntu, Cantarell, 'Helvetica Neue', sans-serif;">These conceptual models come from two places, outcrop studies (going out in the field and looking at rocks) and modern analogues studies (going out to the valley, rivers, lakes, oceans, etc. and seeing how sediment gets deposited). The geology name for these conceptual models is depositional environments. Some additional information on them can be found <a href="https://wiki.aapg.org/Depositional_environments">here and</a> <a href="https://en.wikipedia.org/wiki/Depositional_environment">here.</a> Another key conceptual model is <a href="http://www.sepmstrata.org/page.aspx?&pageid=32&3">sequence stratigraphy</a>. </span></p><p>An example of lithostratigraphic vs. chronostratigraphic interpretation below.</p>
<div id="attachment_1224" style="width: 984px" class="wp-caption aligncenter"><a href="https://i2.wp.com/justingosses.com/wp-content/uploads/2019/08/Gani_and_Bhattacharya_2006_.png"><img data-attachment-id="1224" data-permalink="/predictatops/gani_and_bhattacharya_2006_/" data-orig-file="https://i2.wp.com/justingosses.com/wp-content/uploads/2019/08/Gani_and_Bhattacharya_2006_.png?fit=974%2C547" data-orig-size="974,547" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Gani_and_Bhattacharya_2006_" data-image-description="" data-medium-file="https://i2.wp.com/justingosses.com/wp-content/uploads/2019/08/Gani_and_Bhattacharya_2006_.png?fit=300%2C168" data-large-file="https://i2.wp.com/justingosses.com/wp-content/uploads/2019/08/Gani_and_Bhattacharya_2006_.png?fit=640%2C359" class="wp-image-1224 size-full" src="https://i2.wp.com/justingosses.com/wp-content/uploads/2019/08/Gani_and_Bhattacharya_2006_.png?resize=640%2C359" alt="The top picture shows lithostratigraph correlation where the assumption is that rocks with similar characteristics are deposited the same way. The bottom is a chronostratigraphic interpretation where models from outcrop studies of deltas are used as a guide. In this environment, the coarser grains are deposited first and then finer grains, which build up over time as sheets angled towards the deeper water." width="640" height="359" srcset="https://i2.wp.com/justingosses.com/wp-content/uploads/2019/08/Gani_and_Bhattacharya_2006_.png?w=974 974w, https://i2.wp.com/justingosses.com/wp-content/uploads/2019/08/Gani_and_Bhattacharya_2006_.png?resize=300%2C168 300w, https://i2.wp.com/justingosses.com/wp-content/uploads/2019/08/Gani_and_Bhattacharya_2006_.png?resize=768%2C431 768w" sizes="(max-width: 640px) 100vw, 640px" data-recalc-dims="1" /></a></p>
<p class="wp-caption-text">The top picture shows lithostratigraph correlation where the assumption is that rocks with similar characteristics are deposited at the same time. The bottom is a chronostratigraphic interpretation where models from outcrop studies of deltas are used as a guide. In the deltaic depositional environment, the coarser grains are deposited first and then finer grains, which build up over time as sheets angled towards the deeper water. The lower interpretation is correct.</p>
</div><p>You can read more about stratigraphic well log correlation from <a href="http://www.sepmstrata.org/page.aspx?pageid=61">this page by SEPM </a>(a national sedimentology association).</p><p><em>Just to be clear, with Predictatops, we&#8217;re wanting to do chronostratigraphic correlation, not lithostratigraphic correlation.</em></p><p><strong>Supervised Machine-learning:</strong></p><p>In our context, supervised machine-learning means, instead of letting the computer going on fun field trips like geologists to gradually build up mental conceptual models to use for correlating well logs chronostratigraphically, we&#8217;ll give the computer a dataset of already human-picked tops for one time surface and ask the computer to figure out a model that lets it mimic the geologist.</p><p>For more detailed explanations of machine-learning, there are lots of things on the web that google will provide for you. I&#8217;m a fan of the <a href="https://towardsdatascience.com/explaining-supervised-learning-to-a-kid-c2236f423e0f?source=---------62------------------">medium articles</a> by &#8220;Cassie Kozyrkov&#8221; whose title is &#8220;Chief Decision Intelligence Engineer, Google&#8221; and does a good job at packaging key points in an entirely dense but fun to read space.</p><p><strong>Building Geologic Observations into Features:</strong></p><p>Features in a machine-learning context are new data characteristics built from the original data. An basic example might be the sum of three other original data characteristics. Feature creation is a very common part of machine-learning. Rarely would you only use original raw data.</p><p>Unlike some of the demo datasets traditionally used in machine-learning demos where each row of the dataset is an independent entity and features are only created within each row, a key aspect of building features for stratigraphy applications is that a lot of valuable information can be gleaned if one creates features based on comparisons or aggregate observations from multiple depth points or even across wells. One type of comparison is between each depth point in question and the depth points above, below, and around it within different length windows. Another type of comparison is between the characteristics of the well that holds the depth point being predicted for and the neighboring wells.</p><p>These comparison-based features are similar to what a geologist does visually when they put wells in a cross-section, or a sequence of wells&#8217; well logs, and attempt to pick where stratigraphic tops should be correlated as shown below.</p>
<div id="attachment_1091" style="width: 504px" class="wp-caption alignleft"><a style="font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen-Sans, Ubuntu, Cantarell, 'Helvetica Neue', sans-serif;" href="https://i2.wp.com/justingosses.com/wp-content/uploads/2018/05/Mannville_Xsection_B.png"><img data-attachment-id="1091" data-permalink="/thoughts-on-machine-learning-predictions-of-chronostratigraphic-surfaces/mannville_xsection_b/" data-orig-file="https://i2.wp.com/justingosses.com/wp-content/uploads/2018/05/Mannville_Xsection_B.png?fit=2000%2C1412" data-orig-size="2000,1412" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Mannville_Xsection_B" data-image-description="&lt;p&gt;Alberta Geological Survey Open File Report 1994-14. Cross-section B to B`.&lt;/p&gt;
" data-medium-file="https://i2.wp.com/justingosses.com/wp-content/uploads/2018/05/Mannville_Xsection_B.png?fit=300%2C212" data-large-file="https://i2.wp.com/justingosses.com/wp-content/uploads/2018/05/Mannville_Xsection_B.png?fit=640%2C452" class="wp-image-1091" src="https://i2.wp.com/justingosses.com/wp-content/uploads/2018/05/Mannville_Xsection_B.png?resize=494%2C349" alt="Alberta Geological Survey Open File Report 1994-14. Cross-section B to B&#96;." width="494" height="349" srcset="https://i2.wp.com/justingosses.com/wp-content/uploads/2018/05/Mannville_Xsection_B.png?resize=1024%2C723 1024w, https://i2.wp.com/justingosses.com/wp-content/uploads/2018/05/Mannville_Xsection_B.png?resize=300%2C212 300w, https://i2.wp.com/justingosses.com/wp-content/uploads/2018/05/Mannville_Xsection_B.png?resize=768%2C542 768w, https://i2.wp.com/justingosses.com/wp-content/uploads/2018/05/Mannville_Xsection_B.png?w=1280 1280w, https://i2.wp.com/justingosses.com/wp-content/uploads/2018/05/Mannville_Xsection_B.png?w=1920 1920w" sizes="(max-width: 494px) 100vw, 494px" data-recalc-dims="1" /></a></p>
<p class="wp-caption-text">A cross-section showing different tops in different wells. Vertical curvy lines are gamma-ray well log curves. Alberta Geological Survey Open File Report 1994-14. Cross-section B to B`.</p>
</div>
<div id="attachment_1092" style="width: 251px" class="wp-caption alignright"><a href="https://i1.wp.com/justingosses.com/wp-content/uploads/2018/05/MannvilleWellsMap.png"><img data-attachment-id="1092" data-permalink="/thoughts-on-machine-learning-predictions-of-chronostratigraphic-surfaces/mannvillewellsmap/" data-orig-file="https://i1.wp.com/justingosses.com/wp-content/uploads/2018/05/MannvilleWellsMap.png?fit=1102%2C1369" data-orig-size="1102,1369" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="MannvilleWellsMap" data-image-description="&lt;p&gt;Map of Mannville wells in the Alberta Geological Survey open file report 1994-14 that are used in the project I&#8217;m doing at the github link.&lt;/p&gt;
" data-medium-file="https://i1.wp.com/justingosses.com/wp-content/uploads/2018/05/MannvilleWellsMap.png?fit=241%2C300" data-large-file="https://i1.wp.com/justingosses.com/wp-content/uploads/2018/05/MannvilleWellsMap.png?fit=640%2C795" class="size-medium wp-image-1092" src="https://i1.wp.com/justingosses.com/wp-content/uploads/2018/05/MannvilleWellsMap.png?resize=241%2C300" alt="Map of Mannville wells in the Alberta Geological Survey open file report 1994-14 that are used in the project I'm doing at the github link." width="241" height="300" srcset="https://i1.wp.com/justingosses.com/wp-content/uploads/2018/05/MannvilleWellsMap.png?resize=241%2C300 241w, https://i1.wp.com/justingosses.com/wp-content/uploads/2018/05/MannvilleWellsMap.png?resize=768%2C954 768w, https://i1.wp.com/justingosses.com/wp-content/uploads/2018/05/MannvilleWellsMap.png?resize=824%2C1024 824w, https://i1.wp.com/justingosses.com/wp-content/uploads/2018/05/MannvilleWellsMap.png?w=1102 1102w" sizes="(max-width: 241px) 100vw, 241px" data-recalc-dims="1" /></a></p>
<p class="wp-caption-text">Map of Mannville wells in the Alberta Geological Survey open file report 1994-14 that are used in the project I&#8217;m doing at the github link.</p>
</div><p>Only creating features based on data in individual depth points in individual wells would like cutting up all your well logs from all your wells into little bits, giving them to your geologist in a bucket, shaking the bucket, and then ask the geologist which depth point pieces are the same depth as the top you&#8217;re trying to predict for. Obviously, that wouldn&#8217;t work out so well. If you were to set up a stratigraphic machine-learning project and only create features from data at the same depth points for each well, you&#8217;d be doing the same thing to your machine-learning model.</p>
<h2>Predictatops: Supervised Machine-Learning of Stratigraphic Surfaces</h2><p><strong>Predictatops&#8217; Supervised Machine-learning Goal:</strong></p><p>The goal of Predictatops is to be able to give it a training datasets of wells (that include both well logs and trusted human-assigned tops) for a single time surface and a test datasets of just well logs and get back where it thinks the top should be in each well in the test dataset.</p><p><strong>How to judge success:</strong></p><p>We want to minimize the distance between where the ML model predicted the top should be in each well and where the human(s) put the top. That difference will be our error. For comparing different runs we&#8217;ll return the RMSE (root mean squared error) for the top we&#8217;re trying to predict across all the wells.</p><p>We could have picked a different way to judge prediction success, so I&#8217;ll explain a bit about why I think this is a better way.</p><p>You might be tempted to set the problem up as a classification problem where we don&#8217;t predict a single pick but rather for each depth point in every well predict what formation (another geology word for layer) that depth point is. The problem with doing it this way, is that geologist really don&#8217;t care whether you got the formation correct far away from any top. That might not even be a hard problem. Additionally, how good your statistics appear to be will be affected by how thick the layers are, which isn&#8217;t ideal.</p><p>You could also frame the problem in terms of a binary question of whether or not the top was predicted to be in the exact same place as the geologist put it. The problem with this approach is two-fold. First, you immediately have a huge imbalanced class problem on your hands. If your well logs have a different measurement every 1/3 of a meter and typically are 300 meters long, every well will have 1 instance of data to represent the top and 899 instances to represent not the top. This will make machine-learning very difficult. Second, a binary prediction approach will affect the way you judge accuracy resulting in some not particularly useful information. You might get 4% of the depths predicted exactly right and 96% wrong. However, if all your 96% wrong tops are within plus or minus 2 meters of the actual tops, that&#8217;s amazing good. If the average distance between the actual top and predicted top is plus or minus 56 meters, that&#8217;s not good. In both cases, you were only 4% accurate.</p><p><strong>Project setup:</strong></p><p>If we can&#8217;t set-up the problem as a binary machine-learning program or a classification machine-learning problem, how do we set up the problem?</p><p>In Predictatops, we handled this by making it a two-step prediction with the first step being classification, not on formation labels, but on distance zones away from the pick we were trying to predict. Imaginary zones were created at the pick, slightly away from the pick below, slightly away from pick above, farther form pick below, farther from pick above, and everything else. We then ran classification to predict the zone of each depth point in each well. Those results were then run through an additional process that produced higher numbers for depth points that had the most predictions for being at the top or very near to the top around it. More of this process is described in <a href="https://github.com/JustinGOSSES/predictatops/blob/master/docs/ACE2019_Gosses_theme8_StratigraphicTopML_201905018_submitted.pdf">this presentation given at AAPG ACE</a> and in the <a href="https://justingosses.github.io/predictatops/html/index.html">documentation of Predictatops</a>.</p><p><strong>Data Requirements:</strong></p><p>The supervised part of supervised machine-learning means you have to have human-labeled tops to start. In addition, you have to have enough wells from enough places that the full complexity of the stratigraphy is captured in the training wells. The exact number required is hard to define as it depends on the complexity of the problem, how generalizable we want to the solution, and the algorithms used. If you had to press me, I&#8217;ll say you&#8217;ll need several hundred tops, if not more than a thousand, for your training datasets.</p><p>While we&#8217;re discussing training dataset sizes, a point of interest here is that the number of required training wells goes down is someone is kinda enough to create and release open-source a pre-trained model on say 200,000+ wells in a depositional environment similar to yours. Then you might be able to use that model as a starting point and retrain it with your use-case specific training dataset. This is a over-simplistic description of transfer-learning, which has resulted in incredible gains in image and natural language processing machine-learning.</p><p>An additional data requirement is that these wells have the same, or at least very similar, well log types. Machine-learning likes all the inputs to be collected and prepped the same way. Although this may seem like a simple ask to those not in oil & gas, the reality is that many wells will be drilled with different well logs. Some types will be always present. Some types will be mostly present. Others rarely present. Some types, like sonic, will be very common but different tool vendors used that measure the same property in different ways. Well log normalization by petrophysicists may be required.</p><p>In the demo dataset from the McMurray formation, a collection of well logs that were in the highest number of wells were found. <span style="font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen-Sans, Ubuntu, Cantarell, 'Helvetica Neue', sans-serif;">The impact of that constraint was that instead of 2000 wells used, just over 1200 wells were used. There are classes in Predictatops to help identify what well logs are the most common in a given dataset. </span></p><p><strong>Predictatops Project Status:</strong></p><p>Predictatops is functional but still changing. I tried to organize things such that large pieces could be skipped and others added without too much trouble. It has a demo data from the McMurray in Alberta, Canada and instructions for how to run it with that demo dataset. The documentation is still a work in process but the basics are all there.  I&#8217;ve made some changes to make it more generalizable, but there is more to be done in that area.</p><p><strong>Predictatops Performance:</strong></p><p>The top McMurray currently has a RMSE (root mean squared error) of 6.6 meters. More information is available in <a href="https://github.com/JustinGOSSES/predictatops/blob/master/docs/ACE2019_Gosses_theme8_StratigraphicTopML_201905018_submitted.pdf">this presentation given at AAPG ACE</a> and in the <a href="https://justingosses.github.io/predictatops/html/index.html">documentation of Predictatops</a>.</p>
<div id="attachment_1229" style="width: 1022px" class="wp-caption aligncenter"><a href="https://i0.wp.com/justingosses.com/wp-content/uploads/2019/08/Histogram_Error_predictatops_6.6_vA.png"><img data-attachment-id="1229" data-permalink="/predictatops/histogram_error_predictatops_6-6_va/" data-orig-file="https://i0.wp.com/justingosses.com/wp-content/uploads/2019/08/Histogram_Error_predictatops_6.6_vA.png?fit=1012%2C387" data-orig-size="1012,387" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Histogram_Error_predictatops_6.6_vA" data-image-description="" data-medium-file="https://i0.wp.com/justingosses.com/wp-content/uploads/2019/08/Histogram_Error_predictatops_6.6_vA.png?fit=300%2C115" data-large-file="https://i0.wp.com/justingosses.com/wp-content/uploads/2019/08/Histogram_Error_predictatops_6.6_vA.png?fit=640%2C245" class="wp-image-1229 size-full" src="https://i0.wp.com/justingosses.com/wp-content/uploads/2019/08/Histogram_Error_predictatops_6.6_vA.png?resize=640%2C245" alt="" width="640" height="245" srcset="https://i0.wp.com/justingosses.com/wp-content/uploads/2019/08/Histogram_Error_predictatops_6.6_vA.png?w=1012 1012w, https://i0.wp.com/justingosses.com/wp-content/uploads/2019/08/Histogram_Error_predictatops_6.6_vA.png?resize=300%2C115 300w, https://i0.wp.com/justingosses.com/wp-content/uploads/2019/08/Histogram_Error_predictatops_6.6_vA.png?resize=768%2C294 768w" sizes="(max-width: 640px) 100vw, 640px" data-recalc-dims="1" /></a></p>
<p class="wp-caption-text">A histogram showing the distribution of McMurray Top prediction error. Bars count how many wells where in each group. Groups are based on difference in depth between actual human-picked top and machine-picked top. RMSE is 6.6 m.</p>
</div>
<h4>Wait, but I don&#8217;t trust my geologist.</h4><p>Yes, one limitation of all of this is that fundamentally the machine-learning model is trying to mimic a person&#8217;s (or multiple people&#8217;s) top interpretations. The best you&#8217;ll get out of the machine-learning model in terms of performance accuracy is slightly worse than the training dataset supplied by human geologist(s).</p>
<h4>When would you want to use this type of approach?</h4>
<ol>
<li>When you don&#8217;t have enough time for a geologist to interpret all the wells, but you have enough time to interpret 1000 out of 7000 wells.</li>
<li>When you have two areas worked by different geologists and you want to see how the interpretation of geologist A transfers to the neighboring area worked by geologist B.</li>
<li>When you want to identify the 5% of the wells with the most uncertainty and have your best geologists focus on those.</li>
</ol>
<h4 class="graf graf--h4">Are there uses for this type of approach even if I already have human tops for all my wells?</h4>
<p class="graf graf--p">Yes, the great thing about this type of approach is it scores each depth point in every well. That score can be normalized to a probability of how likely each depth point is to actually be the top. There are wells where only one depth point or a small cluster of depth points have higher scores. Other wells have high scores spread more widely throughout the well. Additionally, some wells have predicted tops at similar depths to their neighbors. Other wells do not. <em class="markup--em markup--p-em">This information can be used to generate uncertainty scores/maps/curves and help geologists know where to focus their efforts.</em> I haven’t done this with Predictatops yet, but it is totally possible!</p>
<h2><strong>Making it easy to use the demo dataset:</strong></h2><p>As mentioned before, the <a href="https://ags.aer.ca/publications/SPE_006.html">demo dataset</a> comes from the McMurray formation in Alberta, Canada. There&#8217;s information on it in the <a href="https://github.com/JustinGOSSES/predictatops">README.md</a> and <a href="https://justingosses.github.io/predictatops/html/index.html">documentation of Predictatops</a>. The full reference is: Wynne et al., (1994) Athabasca Oil Sands Database McMurray/Wabiskaw Deposit, Open-File-Report 1994–14, Alberta, Canada; Alberta Geological Survey. Links to <a class="markup--anchor markup--p-anchor" href="https://ags.aer.ca/document/OFR/OFR_1994_14.PDF" target="_blank" rel="noopener" data-href="https://ags.aer.ca/document/OFR/OFR_1994_14.PDF">report</a> & <a class="markup--anchor markup--p-anchor" href="http://ags.aer.ca/publications/SPE_006.html" target="_blank" rel="noopener" data-href="http://ags.aer.ca/publications/SPE_006.html">dataset</a>. This is a great open-source dataset from the Alberta Energy Regulator and Alberta Geological Survey that could be used in a lot of other machine-learning focused work as it is one of the larger open-source datasets of a single formation already compiled and prepped by a single group.</p><p>Discovering, evaluating, loading, and transforming data takes a lot of time. There&#8217;s always a risk you&#8217;ll get through some or all of those steps and then discovery the dataset won&#8217;t work for your purposes. This dataset is already put together and can be used for both stratigraphic top prediction and facies prediction.</p><p>I&#8217;ve been working on a pull request for the <a href="https://github.com/fatiando/rockhound">Rockhound</a> Python package, a project to make loading geologic demo datasets super quick and easy, that will let you pull in the fully prepped and merged McMurray dataset with two lines of code. Currently, <a href="https://github.com/JustinGOSSES/rockhound">there is this pull request</a> for the McMurray dataset prepped for facies prediction. Once that pull request is accepted, I&#8217;ll push another dataset prepped for stratigraphic prediction.</p>
<h2>Other Machine-Learning Approaches to Stratigraphy</h2><p><strong>Lithostratigraphy:</strong></p><p>Lithostratigraphy is basically curve matching, so computational approaches go back to the 1970s. Some of the better results seem to be geologic specific variations on dynamic time warping. One example is <a href="http://www.kgs.ku.edu/Publications/OFR/2002/OFR02_51/ManualOFR2002-51.pdf">CORRELATOR</a> from Kansas Geological Survey, but there are more modern approaches in Python as well.</p><p>The reasons for why this type of computational approach seemed to have never caught on are likely complex. I don&#8217;t claim to understand all of them, but I suspect it was related to the fact that they often didn&#8217;t return a single surface but rather an arbitrary number of surfaces. This meant the geologist still had to look at the well logs in order to use the results. Hence, the time savings aren&#8217;t there.</p><p><strong>Chronostratigraphy:</strong></p><p>If you&#8217;re interesting in this type of thing, here are two other recent examples of applying machine-learning to stratigraphy that I think are very interesting.</p>
<ol>
<li>Alex Bayeh, Michael Ashby, Darrin Burton, and Seth Brazell at Anadarko (now Occidental) published &#8220;<a href="https://www.onepetro.org/journal-paper/SPWLA-2019-v60n4a1?sort=&start=0&q=brazell&from_year=&peer_reviewed=&published_between=&fromSearchResults=true&to_year=&rows=25">A Machine-Learning-Based Approach to Assistive Well-Log Correlation</a>&#8220;, which uses thousands of pairs of well logs that are and are not representing the same layer to train a model, which is then used with a small number of tops from a specific formation and tops for that formation predicted. I was excited to see this type of approach because (1) I thought an approach sort of like this might be possible but don&#8217;t have access to large enough open-source dataset to actually attempt it myself (2) it demonstrates a different approach to supervised machine-learning applied to stratigraphy.</li>
<li>Additionally, there&#8217;s been a variety of papers trying to apply wavelet transform theory to well log correlation for the past two decades. My opinion of these approaches has typically been that there is a lot of complexity without that much to show for it in terms of useful predictions. A recent exemption to this was <a style="font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen-Sans, Ubuntu, Cantarell, 'Helvetica Neue', sans-serif;" href="https://www.onepetro.org/conference-paper/SPE-183860-MS">Ye at al., 2017</a><span style="font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen-Sans, Ubuntu, Cantarell, 'Helvetica Neue', sans-serif;">&#8216;s &#8220;</span><em style="font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen-Sans, Ubuntu, Cantarell, 'Helvetica Neue', sans-serif;">Rapid and Consistent Identification of Stratigraphic Boundaries and Stacking Patterns in Well Logs &#8211; An Automated Process Utilizing Wavelet Transforms and Beta Distributions</em><span style="font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen-Sans, Ubuntu, Cantarell, 'Helvetica Neue', sans-serif;">&#8220;, which looks like it would be an excellent feature creation step to use in supervised, or event unsupervised machine-learning, applied to stratigraphy.</span></li>
</ol>
<h3 class="graf graf--h3">Contributing to Predictatops</h3>
<p class="graf graf--p">Pulls requests and issues (in the form of bugs, enhancements, comments, and even idle observations) are very welcome on Predictatops. I currently have 18+ issues on the repository for things to do. It is a side project, so please don’t expect it to be perfect, but I&#8217;m interested in hearing feedback as well as other peoples’ approaches to this type of problem.</p><p>References are available on the last slide of <a href="https://github.com/JustinGOSSES/predictatops/blob/master/docs/ACE2019_Gosses_theme8_StratigraphicTopML_201905018_submitted.pdf">this presentation</a>.</p>
<p>The post <a rel="nofollow" href="/predictatops/">Predictatops</a> appeared first on <a rel="nofollow" href="/">Justin Gosses Home</a>.</p>
]]></content:encoded>
			<wfw:commentRss>/predictatops/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
	<post-id xmlns="com-wordpress:feed-additions:1">1217</post-id>	</item>
		<item>
		<title>Geoscience to Data Science Starter Pack</title>
		<link>/geologist-to-data-science-starter-pack/</link>
		<comments>/geologist-to-data-science-starter-pack/#comments</comments>
		<pubDate>Fri, 25 Jan 2019 03:10:47 +0000</pubDate>
		<dc:creator><![CDATA[Justin]]></dc:creator>
				<category><![CDATA[code]]></category>
		<category><![CDATA[advice]]></category>
		<category><![CDATA[career]]></category>
		<category><![CDATA[data science]]></category>
		<category><![CDATA[geoscience]]></category>
		<category><![CDATA[learning]]></category>
		<category><![CDATA[machine-learning]]></category>
		<category><![CDATA[starting out]]></category>

		<guid isPermaLink="false">/?p=1152</guid>
		<description><![CDATA[<p>Why Write this and Who is it targeting?I wrote a post, LEARNING TO CODE, in early 2016, three years ago. The premise of that blog post was a summary of the different styles of learning you could pick from when trying to learn how to code. Not everyone prefers to learn the same way, and I hadn&#8217;t<a href="/geologist-to-data-science-starter-pack/">[...]</a></p>
<p>The post <a rel="nofollow" href="/geologist-to-data-science-starter-pack/">Geoscience to Data Science Starter Pack</a> appeared first on <a rel="nofollow" href="/">Justin Gosses Home</a>.</p>
]]></description>
				<content:encoded><![CDATA[<h2>Why Write this and Who is it targeting?</h2><p>I wrote a post, <a href="/learning-to-code/">LEARNING TO CODE</a>, in early 2016, three years ago. The premise of that blog post was a summary of the different styles of learning you could pick from when trying to learn how to code. Not everyone prefers to learn the same way, and I hadn&#8217;t at the time read any breakdowns of the different ways to learn how to code.</p><p>This blog post, like that one, was prompted by the realization that I had the same conversation with two different people within a single week. They were asking the same questions, so might as well write everything down.</p>
<blockquote><p><em>This post is directed at houston-based geoscience types starting off on a month to years long process of improving their skills in data science and maybe eventually getting a job in data science. It lays out the things I&#8217;ve found myself telling people in real life.</em></p></blockquote>
<h3></h3><p>&nbsp;</p>
<h2></h2>
<h2>Step 1: Figure out if you&#8217;re interested in this type of thing&#8230;.</h2><p>I&#8217;ve not seen a lot of writing on the best way to do this. The best path forward may be a personal decision to a large degree.</p><p>If you have kids and want to involve them in your first steps,<a href="https://code.org/"> code.org</a> and <a href="https://scratch.mit.edu/">Scratch</a> are two resources to try out if you haven&#8217;t written any code. Both are designed for kids but still kinda cool. They&#8217;ll let you see what kind of logic writing code uses but often doing so in a pictorial form that doesn&#8217;t require memorizing any syntax.</p><p>You might also want to try some shorter lessons of 1-5 hour length on sites like <a href="https://www.codecademy.com/">code academy</a> or take your time going through any of the languages on <a href="https://www.w3schools.com/">w3schools</a>.</p><p>If you&#8217;re more motivated by what you can eventually do, you might try watching a few videos of talks from any of the <a href="https://www.youtube.com/playlist?list=PLYx7XA2nY5GfdAFycPLBdUDOUtdQIVoMf">SciPy</a>  conferences or the machine-learning videos from <a href="https://www.youtube.com/channel/UCsX05-2sVSH7Nx3zuk3NYuQ">PyCon</a>. They&#8217;ll be partially over your head, but they can still be very interesting. You can also take a look at the blog posts summarizing what projects were made during <a href="https://agilescientific.com/blog/2018/12/17/the-london-hackathon">geology hackathons by AgileScientific</a>.</p><p>&nbsp;</p>
<h2>What Language to Learn?</h2>
<h4>Python</h4><p>The favorite. Different computer languages are better for different tasks. They also change in popularity over time. There used to be Python vs. R for data science debates, but those have faded recently as Python has more or less won over more people. Two libraries you&#8217;ll use often that also have good documentation & lots of video tutorials are <a href="https://scipy.org/scipylib/">SciPy</a> and <a href="https://scikit-learn.org/stable/">Scikit-learn</a>. If you want to try NLP (natural language processing) <a href="https://spacy.io/">SpaCy</a> has maybe the best documentation of major Python machine-learning libraries.</p>
<h4>R</h4><p>While Python tends to dominate the hard sciences and to a decent extent machine-learning, R leads among the social sciences. There&#8217;s interesting geoscience computing done in R, just most of it is done in Python.</p>
<h4>Other languages that don&#8217;t start with Pytho</h4><p>Python is a very intuitive computer language as far as these things go, so jumping to another language can be a relatively painful experience, at least initially. If you start in Python and are starting to grasp the language, I&#8217;d encourage you <em>not to stay with only Python</em>. One, it limits what you can do. Although capable of a lot, Python isn&#8217;t good at everything. Two, you&#8217;ll become better at programming once you can hope between languages. There will be people, sometimes people with an incentive, who might say things at a SciPy conference like, &#8220;I am only an astrophysics PhD, I can&#8217;t be expected to understand something difficult like JavaScript&#8221; or &#8220;If you learn JavaScript then you&#8217;ll be a web developer and not a scientist&#8221;. Those people are wrong. Ignore them.</p>
<h5>JavaScript (and HTML,CSS)</h5><p>Although you will probably start off with Python. Picking up JavaScript as language number two is worth your while. The web runs on HTML, CSS, JavaScript, browsers, and pictures of cats. If you want to build anything with a decent human interface, visualize data in a slightly unusual way, or reach people online, having some JavaScript knowledge is powerful.</p><p>An important point to make when you talk about JavaScript is that <a href="https://www.w3schools.com/js/default.asp">plain JavaScript</a>, or what is sometimes called <a href="https://snipcart.com/blog/learn-vanilla-javascript-before-using-js-frameworks">Vanilla JavaScript</a>, is perfectly fine most of the time. There are lots of JavaScript frameworks you could theoretically pick up, <a href="https://reactjs.org/">React</a>, <a href="https://vuejs.org/">Vue</a>, <a href="https://angularjs.org/">Angular</a>, etc., but I tend to have a <em>&#8220;use it only if you have well demonstrated need&#8221;</em> perspective on JavaScript frameworks. If you end up doing a large <a href="https://en.wikipedia.org/wiki/Front_and_back_ends">front-end project</a>, that&#8217;s when you should consider a JavaScript framework.</p>
<h5>C++</h5><p>C++ and Java are the languages most often learned by Computer Science majors in university. There are good reasons for this and not quite so good reasons for this. Certain things, like highly dependable applications, embedded applications, and low-level high performance computing is done in C++. If you are a geophysicist and did some in school, it might be a place to continue. If not, it probably isn&#8217;t the place to start.</p>
<h5>Java</h5><p>Some of the things that could be said about C++ could also be said about Java. There is a fair amount of machine-learning done using Java when it is done via <a href="https://en.wikipedia.org/wiki/Distributed_computing">distributed computing</a> on big data. <a href="https://towardsdatascience.com/deep-learning-with-apache-spark-part-1-6d397c16abd">Spark</a> is an important tool in that space to at least know about. If you&#8217;re interested in Spark but want to stick to Python, there is also <a href="https://towardsdatascience.com/a-brief-introduction-to-pyspark-ff4284701873">PySpark</a>.</p><p>&nbsp;</p>
<h2>How to learn?</h2>
<h3>In-person Bootcamps, Online Courses, Online Lessons, etc.</h3><p>As mentioned above, I previously wrote a blog post in 2016 about the <a href="/learning-to-code/">different types of ways to learn how to code</a>. Its worth taking a look at it. Much of what was written ties in closely with this post but from a more generic learning to code perspective and less data science centric view.</p>
<h4>Useful Things that Didn&#8217;t Exist (I think) in January 2016</h4><p>One thing of importance to note is that <a href="https://notebooks.azure.com/">Microsoft Azure notebook</a>s and <a href="https://colab.research.google.com/notebooks/welcome.ipynb#recent=true">Google Colab</a> didn&#8217;t exist in January 2016. If they would have, and I knew about them, I would noted them in the previous blog post. These are similar to a <a href="https://jupyter.org/">Jupyter Notebook</a> but run in the cloud and are accessed via your browser. They will let you get started writing Python without having to deal (at least initially) with the often messy process of installing languages, editors, and code libraries locally on your computer. If you do install things on your local computer, the <a href="https://www.anaconda.com/">Anaconda</a> installation method is probably the easiest path forward.</p><p>&nbsp;</p>
<h2>Build Things People Can Find</h2>
<h3>Start a Github Profile</h3><p>Why? = <strong>Because if you&#8217;re self-taught you need to show evidence you can create things and write actual code.</strong> The commonly acceptable way to do this is to give people a link to your github profile where you have a bunch of public code projects. These can be data visualizations, machine-learning baby-scale projects, whatever. Make sure not all of them are forks or class work where you followed instructions.</p><p>If you&#8217;re not familiar with the terms, <a href="https://www.coredna.com/blogs/what-is-git-and-github-part-two">here</a> are some definitions of <a href="https://en.wikipedia.org/wiki/Git">Git</a> and <a href="https://en.wikipedia.org/wiki/GitHub">Github</a>. There are other services than github you can use, like gitlab or bitbucket, but GitHub is the most common.</p><p>While on the topic of github, I will note that <a href="https://github.com/softwareunderground/awesome-open-geoscience">this repository of <em>&#8220;AWESOME OPEN GEOSCIENCE&#8221;</em></a> code projects is something to check out. It lives on github. It contains a wide variety of lesser known geoscience-domain-specific tools you can use. It started as a conversation I had with others in the <a href="https://softwareunderground.org/slack/">Software Undergound Slack channel</a>. It is one of the many &#8220;Awesome lists&#8221; out there for code in a specific domain or application area.</p>
<h3>Personal website</h3><p>Why? = Because it is good web programming practice and shows you can build something. Additionally, it can be a way to do personal branding.</p><p>The two easiest ways to do this are a <a href="https://wordpress.com/">WordPress</a> website or a <a href="https://pages.github.com/">github pages</a> website. WordPress is a content management system or CMS. You technically don&#8217;t need to code at all if you use WordPress though you can do some small edits in HTML, CSS, and JavaScript if you&#8217;d like to. On the back-end side, WordPress runs PHP. WordPress may cost you depending where it is hosted and whether you want a more professional web address. Github pages is free, but only front-end (<em>HTML,CSS,JS</em>), meaning no connection to a database or back-end scripts (<em>Python or PHP</em>). There are plenty of open-source, free static page templates you can use to get started with a <a href="https://pages.github.com/">github.io page</a>.</p>
<h3></h3><p>&nbsp;</p>
<h2>Active In-person Learning</h2>
<h3>Tutorials at Tech Conferences</h3><p>Why? = Because they&#8217;re really good at getting as much of the information coming out of the firehose to go directly in your brain. They can also serve as starter material for a project on your github. Often the tutorials will be based around a library or a type of task. You&#8217;ll usually leave with a link to not just slides but also all the code the instructor ran, which sets you up to learn it even deeper later on. Conferences can be a good way to network too.</p>
<ul>
<li><a href="https://scipy2018.scipy.org/ehome/299527/648139/">https://scipy2018.scipy.org/ehome/299527/648139/</a></li>
<li><a href="https://us.pycon.org/2018/schedule/tutorials/">https://us.pycon.org/2018/schedule/tutorials/</a></li>
</ul>
<h3>Hackathons</h3><p>Why? = Because hackathons are the fastest way to build things that demonstrate your ability to combine concepts and techniques to solve a real world problem. They&#8217;re also great for networking and learning new things through collaborative problem solving.</p><p>The factors that have differentiated good from less good hackathons in my limited experience were a length of at least 5 hours if not 2 days, interesting project ideas, project ideas scaled to the time and skillsets of participants, most participants knowing how to code at least a little, and enough coffee/food that you don&#8217;t have to leave.</p><p>Good Hackathons likely to be in Houston in the future:</p>
<ul>
<li><a href="https://events.agilescientific.com/">https://events.agilescientific.com/</a> : Agile runs several a year, typically around conferences that I can attest are quite good.</li>
<li><a href="http://houstonhackathon.com/">http://houstonhackathon.com/</a> : I&#8217;ve never been able to go myself as I&#8217;ve always been out of town, but I&#8217;m told its worth your time.</li>
</ul>
<h3>Single-Speaker-Style Meet-ups</h3><p>Why? = There&#8217;s a reason schools spend a lot of time filling peoples&#8217; heads via the single-speaker at front of room format. It is generally effective. There are a variety of Houston meet-ups in the machine-learning, data science, python space. They vary in quality. Sometimes when they&#8217;re not good, it can be because they&#8217;ve turned into a vendor pitch or the content was different than what was listed. The two meet-ups I mention below have good content and are good for networking. The houston energy data science meet-up sometimes falls into the trap of speakers being just a bit too vendor-ish, but usually it is okay. SPE (Society of Petroleum Engineers) sometimes has oil and gas data science &#8220;meet-ups&#8221;, but they aren&#8217;t free so I never go.</p>
<ul>
<li><a href="https://www.meetup.com/Houston-Data-Science/">https://www.meetup.com/Houston-Data-Science/</a></li>
<li><a href="https://www.meetup.com/Houston-Energy-Data-Science-Meetup/">https://www.meetup.com/Houston-Energy-Data-Science-Meetup/</a></li>
</ul>
<h3>Non-Just-A-Speaker Meet-ups</h3><p>Why? = Because not all meet-ups are just a person talking and that&#8217;s a good thing. Some of them are more about doing.</p><p><a href="https://www.meetup.com/sketchcity/">Sketch city</a> regularly has people, local government agencies, and non-profits come in to share a bit about their open-data and what problems/solutions/visualizations/predictions a data-literate member of the public might make from their data. It is a good meet-up to attend for getting project ideas and networking within the local civic tech or civic-tech-interested crowd.</p><p><a href="http://www.meetup.com/Houston-Data-Visualization-Meetup/">The Houston Data Visualization Meet-up</a> (<em>disclaimer I help co-lead this one</em>) has both single-speaker format and data-jam format meetings. Data-jams are often on Saturday morning and consist of 10-30 people working in small groups to visualize a dataset they were just given that morning. Often these datasets come from a local community group or the city of Houston, though we&#8217;ve also used non-local datasets like ChemCam data from the Mars rover Curiosity or a dataset of Russion-bots&#8217; posting on Twitter. In addition to being great starter projects for your portfolio and good networking, this type of meet-up exposes you to a wide variety of GUI and code library data visualization toolsets. You&#8217;ll find out what tools are good for what use cases.</p>
<ul>
<li><a href="https://www.meetup.com/sketchcity/">https://www.meetup.com/sketchcity/</a></li>
<li><a href="http://www.meetup.com/Houston-Data-Visualization-Meetup/">http://www.meetup.com/Houston-Data-Visualization-Meetup/</a></li>
</ul>
<h2></h2><p>&nbsp;</p>
<h2>Filling Your Head Digitally</h2><p>Once you get a certain level of proficiency, learning will start to become more about keeping up and continuing to grow. The rate of &#8220;new&#8221; in data science greatly outstrips geology. It also occurs in different places. &#8220;New&#8221; in oil & gas geology tends to mostly occur in yearly conferences, monthly or quarterly journal publications, new corporate best practice documents from on high, and major software updates. &#8220;New&#8221; in data science occurs in those places. It also occurs to a much larger extent on Slack, Twitter, Podcasts, and Medium articles. New techniques, new results, entirely new libraries are often announced via those methods before they are published in a journal or integrated into a GUI software application your organization might purchase. The flip side of using the methods below to ingest new data science content is the deluge can sometimes get overwhelming.</p>
<h3>Slack Communities</h3><p>Why? = Because your niche interest area may not perfectly overlap with the people you interact with on a daily basis. Even if it does, the number of people is going to be small. Slack is a way to expand that community discussion digitally. Slack is an asynchronous communication platform built around channels, which each have a different topic. The <a href="https://softwareunderground.org/slack/">softwareunderground</a> slack team is all about computing & geoscience. Anyone can join. A few example channels are geospatial, houston, js, kaggle, open-geoscience, python, r-users, reading, and viz.</p>
<ul>
<li><a href="https://softwareunderground.org/slack/">https://softwareunderground.org/slack/</a> : You can join at this link. Cheers to the <a href="https://agilescientific.com/">Agile Scientific</a> group for setting it up.</li>
</ul>
<h3>Twitter</h3><p>Why? = Because if Slack, PodCasts, Medium, Journals, etc. all have a frequency, Twitter is the fastest. New libraries, cool examples, interesting discussions of connected threads, will all appear here first before they appear elsewhere. The girl who builds the crazy visualizations that inspire your next project. She&#8217;ll post drafts to Twitter. Someone recently discovered a rarely used but super useful function for your domain in a general purpose Python library. They&#8217;ll post that to Twitter. Twitter isn&#8217;t just data science, of course. You&#8217;ll have to curate your feed by following people with good content, and that takes time, but it is an option for ingesting content at the cutting edge.</p>
<ul>
<li><a class="ProfileHeaderCard-screennameLink u-linkComplex js-nav" href="https://twitter.com/JustinGosses"><span class="username u-dir" dir="ltr">@<b class="u-linkComplex-target">JustinGosses</b></span></a></li>
<li><a href="https://twitter.com/januaryadvisors">@januaryadvisors</a></li>
<li><a href="https://twitter.com/landlabtoolkit">@landlabtoolkit</a></li>
<li><a href="https://twitter.com/fatiandoaterra">@fatiandoaterra</a></li>
<li><a href="https://twitter.com/PaulHCleverley">@PaulHCleverley</a></li>
<li><a href="https://twitter.com/vaex_io">@vaex_io</a></li>
<li><a href="https://twitter.com/ncasenmare">@ncasenmare</a></li>
<li><a href="https://twitter.com/jordansread">@jordansread</a></li>
</ul>
<h3>PodCasts</h3><p>Why? = Because data science isn&#8217;t just in text form.</p>
<ul>
<li><a href="https://dataskeptic.com/">DataSkeptic</a> : Data Science Explanations & Discussion</li>
<li><a href="https://undersampledrad.io/">under sampled radio</a> : Geology + Computing</li>
</ul>
<h3>Medium</h3><p>Why? = Because getting a few things into your head via 5-30 minutes of reading is sometimes the exact right size of learning.</p>
<ul>
<li><a href="https://hackernoon.com/@kozyrkov?source=user_profile---------0---------------------">https://hackernoon.com/@kozyrkov</a> : <a class="ds-link ds-link--styleSubtle link link--darken link--accent u-accentColor--textNormal u-accentColor--textDarken" dir="auto" href="https://hackernoon.com/@kozyrkov?source=user_profile---------0---------------------" data-action="show-user-card" data-action-source="user_profile---------0---------------------" data-action-value="2fccb851bb5e" data-action-type="hover" data-user-id="2fccb851bb5e" data-collection-slug="hacker-daily">Cassie Kozyrkov</a> Chief Data Intelligence Engineer at Google. She does a great job condensing down the subject matter into small useful bits of explanation you can use with other people without becoming fluffy like so many other pieces in Forbes or Business Insider that cover similar ground.</li>
<li><a href="https://medium.com/multiple-views-visualization-research-explained">https://medium.com/multiple-views-visualization-research-explained</a> : Explains data visualization research just like the name says. Written by a collection of academic data visualization researchers.</li>
<li><a href="https://medium.com/vis-gl">https://medium.com/vis-gl</a> : Uber&#8217;s data visualization group does some great stuff and open-sources a lot of it. This is a place to learn about new tools that combine JavaScript, data visualization, and geospatial.</li>
</ul>
<h3>LinkedIN</h3><p>Why? = Well to be honest, I&#8217;m not sure I get that much from LinkedIN, but it is good for finding out about small conferences or meetings with a data science focus that intersect with geology or oil & gas.</p>
<ul>
<li><a href="https://www.linkedin.com/company/spe-gulf-coast-section/">https://www.linkedin.com/company/spe-gulf-coast-section/</a> : Society of Petroleum Engineers has an active data analytics section in Houston</li>
</ul><p>&nbsp;</p><p>&nbsp;</p>
<h2>Happy Coding!</h2>
<h2><iframe class="giphy-embed" src="https://giphy.com/embed/JIX9t2j0ZTN9S" width="480" height="480" frameborder="0" allowfullscreen="allowfullscreen"></iframe></h2><p>Caption: In reality the cat should spend a third of this time googling things he forgot while looking frustrated.</p>
<p>The post <a rel="nofollow" href="/geologist-to-data-science-starter-pack/">Geoscience to Data Science Starter Pack</a> appeared first on <a rel="nofollow" href="/">Justin Gosses Home</a>.</p>
]]></content:encoded>
			<wfw:commentRss>/geologist-to-data-science-starter-pack/feed/</wfw:commentRss>
		<slash:comments>2</slash:comments>
	<post-id xmlns="com-wordpress:feed-additions:1">1152</post-id>	</item>
		<item>
		<title>Shortening the distance between creators and creation in geo-computing</title>
		<link>/shortening-the-distance-between-creators-and-creation/</link>
		<comments>/shortening-the-distance-between-creators-and-creation/#respond</comments>
		<pubDate>Mon, 04 Jun 2018 04:33:51 +0000</pubDate>
		<dc:creator><![CDATA[Justin]]></dc:creator>
				<category><![CDATA[code]]></category>
		<category><![CDATA[geology]]></category>
		<category><![CDATA[Bret Victor]]></category>
		<category><![CDATA[Geology]]></category>
		<category><![CDATA[javascript]]></category>
		<category><![CDATA[python]]></category>
		<category><![CDATA[wellio.js]]></category>
		<category><![CDATA[widget]]></category>

		<guid isPermaLink="false">/?p=1066</guid>
		<description><![CDATA[<p>InspirationBret Victor is a well known thinker on the future and possibilities of human &#8211; computer interface. His website contains a variety of thought provoking projects, and his talks have inspired many other works.Currently, he&#8217;s leading development of Dynamicland, a new way of interacting with and creating computer programs that involves image recognition, paper, and<a href="/shortening-the-distance-between-creators-and-creation/">[...]</a></p>
<p>The post <a rel="nofollow" href="/shortening-the-distance-between-creators-and-creation/">Shortening the distance between creators and creation in geo-computing</a> appeared first on <a rel="nofollow" href="/">Justin Gosses Home</a>.</p>
]]></description>
				<content:encoded><![CDATA[<h3>Inspiration</h3><p><a href="https://en.wikipedia.org/wiki/Bret_Victor">Bret Victor</a> is a well known thinker on the future and possibilities of human &#8211; computer interface. <em>His <a href="http://worrydream.com/">website</a> contains a variety of thought provoking projects, and his talks have inspired many other <a href="https://hacks.mozilla.org/2012/04/bret-victors-inventing-on-principle-and-a-few-things-it-inspired/">works</a>.</em></p><p>Currently, he&#8217;s leading development of <a href="https://dynamicland.org/">Dynamicland</a>, a new way of interacting with and creating computer programs that involves image recognition, paper, and projectors. The best way to understand it is by watching <a href="https://twitter.com/dynamicland1?lang=en">videos of people using it</a>.</p><p>In one of his most well known talks &#8220;<a href="https://www.youtube.com/watch?v=PUv66718DII">Inventing on Principle</a>&#8221; he discusses his principle that <em><strong>&#8220;creators need an immediate connection to what they create&#8221;</strong></em>. <span style="text-align: center;">Although it can be interpreted as a call to create completely new ways for interacting with computers, like in </span><a style="text-align: center;" href="https://dynamicland.org/">Dynamicland</a><span style="text-align: center;">, or creating reactive programming interfaces with more immediate feedback, like Nicky Case&#8217;s <a href="http://ncase.me/joy/">joy.js</a>, we can also read this as an encouragement to look for more incremental improvements that shorten the distance between creator and what they create. </span><strong style="text-align: center;">I think the incremental version of this concept is illustrative in regards to what open-source side products people might work on in geo-computing. </strong></p>
<h3>State of things</h3><p>I previously worked for nine years in the oil and gas industry. Most oil and gas software is a collection of clicks and drop-down menus. Sometimes the steps users follow are not too different from the original process done with paper and pencil. Although I no longer work with that type of data professionally, I still play with geoscience data via side projects. I leverage open-source libraries and although they are more flexible, I&#8217;ve sometimes found myself struggling to quickly try different things, visualize the result, and iterate. Too often I have to re-type code, hit return, repeat and see the result. Additionally, getting geoscience data into open-source software built for other types of data at times feels either hacky or too great a leap. This is especially true in JavaScript where, I would argue, most of the current amazing new things in data visualization tend to occur but few geoscientists venture, as they tend to stay to Python. In all of these cases, the distance between creator and creation is a bit larger than it could be, which makes exploring hypothesis spaces slow. This slowness limits what you can or might end up doing.</p>
<blockquote>
<p style="text-align: center;"><em>How can we shrink the distance between creator and creation in geo-computing?</em></p><p>&nbsp;</p></blockquote><p>I often see two ways.</p><p><em>First</em>, we can make it easier to leverage the wide variety of open-source libraries when working with geoscience data, <em><strong>a glue and adapter approach</strong>.</em> Too often getting data into the right form is either slow and hacky or simply doesn&#8217;t exist. Small tools that solve common problems.</p><p><em>Second</em>, we can make it easier to do many iterations quickly, <strong><em>a widgetization approach</em></strong>. Specifically, iterate more through mouse movements and other inputs that are continuous more and iterate less through discrete inputs like typing, clicking, or recalculating. This makes it faster and more enjoyable to explore a hypothesis space and stumble onto different ways to visualize raw data in aggregate or other form.</p>
<h2>Glue & adapters</h2><p>Working with geoscience data in any open-source library requires getting the data in. This is less of a problem in analytics focused Python libraries like SciPy and Pandas, in part because people have built great tools like <a href="https://github.com/Statoil/segyio">SEGYIO (seismic)</a>, <a href="https://github.com/kinverarity1/lasio">LASIO</a> (well logs), and <a href="https://github.com/agile-geoscience/welly">WELLY</a> (well logs). Adapters and glue libraries in JavaScript are more lacking. This is understandable as most scientists learn Python, for <a href="https://www.researchgate.net/journal/0885-7156_Powder_Diffraction">good reasons</a>, but unfortunate because many of the cool new projects in data visualization are written in JavaScript, as that&#8217;s the language of the web. To give an example of the limitations, I can&#8217;t find a library for loading and displaying seismic in HTML, CSS, JavaScript that is open-source. This isn&#8217;t because it isn&#8217;t possible to do. <a href="https://info.drillinginfo.com/seismic-analysis-drillinginfo-acquired-transform-software/">Several</a> <a href="https://www.int.com/products/geotoolkit/">companies</a> offer seismic web visualization as part off their cloud services. It is either that no one has made an open-source version, or it isn&#8217;t used much so is hard to find.</p>
<h4>Wellio.js</h4><p>As an example of trying to fill this glue and adapter gap for getting well log data to be easily usable in JavaScript data visualization libraries, I&#8217;ve started <a href="https://github.com/JustinGOSSES/wellio.js">Wellio.js</a> as a side project. Wellio.js is both a front-end and back-end (node.js) JavaScript library. It takes in native well log files in LAS 2.0 format and transforms them to <a href="https://en.wikipedia.org/wiki/JSON">JSON</a> format, which JavaScript libraries can read.</p><p>Some libraries and tasks that now become easier include:</p>
<ul>
<li><a href="https://github.com/d3/d3/wiki/gallery">D3.js</a>
<ul>
<li>One of the most popular data visualization libraries, it lets you access lower level control so can make pretty much <a href="https://github.com/d3/d3/wiki/gallery">anything.</a></li>
</ul>
</li>
<li><a href="https://vega.github.io/vega/">Vega.js</a>
<ul>
<li>Sorta like d3.js but based on a visualization grammar. You trade some power and flexibility for speed and ease of use.</li>
</ul>
</li>
<li><a href="https://threejs.org/">Three.js</a>
<ul>
<li>Arguably the current standard for quickly making three-dimensional content on the web. You can go in a million directions with it and people <a href="https://threejs.org/examples/#webgl_camera_cinematic">do</a>.</li>
</ul>
</li>
<li><a href="https://github.com/jeromeetienne/AR.js/blob/master/README.md">AR.js</a>
<ul>
<li>Augmented reality without an app or headset, just your browser and your regular smart phone.</li>
</ul>
</li>
</ul><p>So what could you do with seismic or well data with the libraries above? With d3.js you can replicate just about any traditional visualization of well log data. <a href="https://github.com/agile-geoscience/g3">G3.js</a> is a partially completed library but still pretty cool library that attempts this. The Wellio.js github page has <a href="https://justingosses.github.io/wellio.js/">a demo that uses g3.js.</a> One of the advantages of using JavaScript is all the computation can be done client side. This means you can upload to a web application your own well logs to be visualized or analyzed and no data gets sent to a cloud server, it all stays in your browser. Additionally, you don&#8217;t have to install any software or code.</p><p>With vega.js, wellio.js, and ObservableHQ you can then quickly & interactively <a href="https://beta.observablehq.com/@justingosses/spearman-correlation-coefficient-using-i-spearmanrho-i">visualize</a> & <a href="https://beta.observablehq.com/@justingosses/spearman-correlation-coefficient-using-i-spearmanrho-i">analyze</a> well curves in the browser and write little bits of code to interactively try new things. Here is <a href="https://beta.observablehq.com/@justingosses/spearman-correlation-coefficient-using-i-spearmanrho-i">an example</a> that plays around with the spearman&#8217;s correlation coefficient.</p>
<div id="attachment_1102" style="width: 650px" class="wp-caption aligncenter"><a href="https://beta.observablehq.com/@justingosses/three-js-well-log-demo-geology"><img data-attachment-id="1102" data-permalink="/shortening-the-distance-between-creators-and-creation/screen-shot-2018-06-03-at-11-38-55-pm/" data-orig-file="https://i1.wp.com/justingosses.com/wp-content/uploads/2018/06/Screen-Shot-2018-06-03-at-11.38.55-PM.png?fit=1890%2C1350" data-orig-size="1890,1350" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screen Shot 2018-06-03 at 11.38.55 PM" data-image-description="" data-medium-file="https://i1.wp.com/justingosses.com/wp-content/uploads/2018/06/Screen-Shot-2018-06-03-at-11.38.55-PM.png?fit=300%2C214" data-large-file="https://i1.wp.com/justingosses.com/wp-content/uploads/2018/06/Screen-Shot-2018-06-03-at-11.38.55-PM.png?fit=640%2C457" class="wp-image-1102 size-large" src="https://i1.wp.com/justingosses.com/wp-content/uploads/2018/06/Screen-Shot-2018-06-03-at-11.38.55-PM.png?resize=640%2C457" alt="3D well logs in three.js" width="640" height="457" srcset="https://i1.wp.com/justingosses.com/wp-content/uploads/2018/06/Screen-Shot-2018-06-03-at-11.38.55-PM.png?resize=1024%2C731 1024w, https://i1.wp.com/justingosses.com/wp-content/uploads/2018/06/Screen-Shot-2018-06-03-at-11.38.55-PM.png?resize=300%2C214 300w, https://i1.wp.com/justingosses.com/wp-content/uploads/2018/06/Screen-Shot-2018-06-03-at-11.38.55-PM.png?resize=768%2C549 768w, https://i1.wp.com/justingosses.com/wp-content/uploads/2018/06/Screen-Shot-2018-06-03-at-11.38.55-PM.png?w=1280 1280w" sizes="(max-width: 640px) 100vw, 640px" data-recalc-dims="1" /></a></p>
<p class="wp-caption-text">3D well logs in three.js</p>
</div><p>Once well log data is in JSON, it becomes easy to work with it in <a href="https://threejs.org/">three.js</a> to make <a href="https://beta.observablehq.com/@justingosses/three-js-well-log-demo-geology">3D visualizations as shown in this basic example</a> on Observable that you can edit and change.</p><p>AR.js is a library I have some experience with in the augmented reality space. I&#8217;ve used it to create <a href="https://twitter.com/JustinGosses/status/848636777028096001">an Augmented Reality business card with a 3D depiction of Gale Crater on Mars</a>. AR.js can use three dimensional visualizations created in three.js. As shown above, we can visualize well logs in three.js after converting the well logs LAS 2.0 formatted file into JSON. There is nothing stopping us from having a paper map with symbols on it that bring up augmented reality well logs and surfaces such that we could look at the subsurface in field using only a paper map and the cell phone you already have in your pocket.</p>
<h2>Widgetization</h2><p>How do we make exploring hypothesis spaces faster and easier and less constrained with widgets? I&#8217;ll start off by saying I&#8217;m not entirely satisfied with any of the solutions out there. The level of immediate feedback depicted in <a href="https://www.youtube.com/watch?v=PUv66718DII">this Bret Victor video</a> with the programmatically drawn tree is hard to get to and still be flexible enough to tackle a different problem quickly. Generally the approaches to these types of problems describe themselves as either a GUI (graphic user interface) library, a widget library, or a reactive computer library or language. GUIs are all about building a graphic user interface for the end-user where code is probably not exposed. Widgets are sliders, buttons, wheels, and other sorts of graphical conventions that users can use to quickly change a variable&#8217;s value across a continuous range. Reactive libraries like <a href="http://ncase.me/joy/">joy.js</a> attempt to mimic some of the magic depicted in Bret Victor&#8217;s talk while flexible enough to allow people to build their own.</p>
<h4>Example tools for widgetization:</h4>
<ul>
<li><a href="https://beta.observablehq.com/collection/explorables">ObservableHQ (webpage that executes end-user-typed JavaScript in real time inside notebook like enviornment)</a></li>
<li><a href="http://ipywidgets.readthedocs.io/en/stable/user_guide.html">Jupyter Widgets (widget add-on for Jupyter notebooks)</a></li>
<li><a href="https://bokeh.pydata.org/en/latest/docs/user_guide/interaction/widgets.html">Bokeh Widgets (Like Jupyter widgets but for Python Bokeh data visualization library)</a></li>
<li><a href="https://wiki.python.org/moin/Intro%20to%20programming%20with%20Python%20and%20Tkinter">TKinter (Old school but still works GUI builder for Python)</a></li>
<li><a href="https://wxpython.org/pages/overview/">WXpython </a><a href="https://wiki.python.org/moin/Intro%20to%20programming%20with%20Python%20and%20Tkinter">(Old school but still works GUI builder for Python)</a></li>
<li><a href="https://idyll-lang.org/gallery">Idyll-lang(JavaScript library, for explorable explanations)</a></li>
<li><a href="http://ncase.me/joy/">Joy.js (reactive style JavaScript Library, the closest to Bret Victor flower demo)</a></li>
</ul>
<h4>Two Small Examples</h4><p>Examples of some experiments I&#8217;ve done recently in ObservableHQ with a little widgetization include <a href="https://beta.observablehq.com/@justingosses/spearman-correlation-coefficient-using-i-spearmanrho-i">this quick demo of well logs and a correlation coefficient </a> and this experiment in <a href="https://beta.observablehq.com/@justingosses/1st-try-converting-well-log-data-into-audio-not-very-success">sonifying well logs</a>.</p>
<h4>Example of a widget-ed data visualization I want that doesn&#8217;t exist yet:</h4><p>There&#8217;s a widget I&#8217;ve been wanting but haven&#8217;t built yet. It would be useful for machine-learning predictions of either stratigraphic surfaces or facies. I would like to have a function that creates a new feature from original features along a well bore. All the variables in the function would be draggable widgets like in <a href="http://ncase.me/joy/demo/nonlinear/">this</a> joy.js example. There would be immediate linkage between this function and several other visualization on the page, similar to how <a href="https://dc-js.github.io/dc.js/">dc.js works</a>. One would be a <a href="https://www.spec2000.net/01-beginnersguide.htm">typical vertical well curve visualization</a>. The other a scatter plot with points colored by label class. Labels might be facies or at &#8220;pick&#8221;, &#8220;near pick&#8221;, and &#8220;away from pick&#8221;. Lastly, there would be a random forest tree visualized as a tree of links and nodes. I would be able to select all the data downstream of a specific node and use that data in the visualizations. Both the well curve plot and the scatter plot would be <a href="https://www.visualcinnamon.com/2016/07/brush-bar-chart-d3.html">brushable</a>, meaning data selected in one visualization is highlighted in the others. I think this type setup, where you can immediately see the effect of different choices in your feature creation function on how labels are clustered could greatly speed up the process of engineering effective features as a replacement for all the different types of observations we make when we look at a log.</p>
<h4>And now for something completely different: Alternative Means of User Input?</h4><p><a href="https://i2.wp.com/justingosses.com/wp-content/uploads/2018/06/KinectPottery.jpg"><img data-attachment-id="1101" data-permalink="/shortening-the-distance-between-creators-and-creation/kinectpottery/" data-orig-file="https://i2.wp.com/justingosses.com/wp-content/uploads/2018/06/KinectPottery.jpg?fit=900%2C1200" data-orig-size="900,1200" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="KinectPottery" data-image-description="&lt;p&gt;KinectPottery&lt;/p&gt;
" data-medium-file="https://i2.wp.com/justingosses.com/wp-content/uploads/2018/06/KinectPottery.jpg?fit=225%2C300" data-large-file="https://i2.wp.com/justingosses.com/wp-content/uploads/2018/06/KinectPottery.jpg?fit=640%2C853" class="wp-image-1101 size-medium alignleft" src="https://i2.wp.com/justingosses.com/wp-content/uploads/2018/06/KinectPottery.jpg?resize=225%2C300" alt="KinectPottery" width="225" height="300" srcset="https://i2.wp.com/justingosses.com/wp-content/uploads/2018/06/KinectPottery.jpg?resize=225%2C300 225w, https://i2.wp.com/justingosses.com/wp-content/uploads/2018/06/KinectPottery.jpg?resize=768%2C1024 768w, https://i2.wp.com/justingosses.com/wp-content/uploads/2018/06/KinectPottery.jpg?w=900 900w" sizes="(max-width: 225px) 100vw, 225px" data-recalc-dims="1" /></a></p><p>Another way to make user input and exploration continuous instead of discrete and get real-time feedback, is to change the means of input away from mouse and keyword entirely. This is related to widgetization but maybe another step down the line? In <a href="https://twitter.com/JustinGosses/status/999417519877312512">the</a> image above taken at the Cleveland Museum of Art, a user is molding a digital representation of clay with their hands. Could the same technique work for salt bodies in 3D seismic? Clicking takes a lot of time for seismic interpretation and has health and safety implications. Why not drawing? I can draw lines over seismic with a digital pen significantly better than I can with a mouse click hold. Kinect cameras capture 3D surfaces and create digital topography on a small human scale. A popular geoscience education use of Kinect cameras is an <a href="https://arsandbox.ucdavis.edu/">augmented reality sandboxes</a>. Can kinect&#8217;s be used for input into technical problems too? Additionally <a href="https://webgazer.cs.brown.edu/">eye tracking</a> and <a href="https://github.com/CMU-Perceptual-Computing-Lab/openpose">body tracking</a> technology that leverage machine-learning is getting good enough to start considering practical use. Are there use-cases where these types of inputs are preferred or could be used in addition to mouse clicking?</p>
<h3></h3>
<h3>Conclusion</h3><p>I&#8217;m not Bret Victor, and you&#8217;re probably not either (if you&#8217;re actually Bret Victor, hi). Although creating things at his level is inspiring, it is also difficult. Aiming for a little in that direction, however, is perhaps instructive in terms of identifying  opportunities to make something cool and even potentially useful.</p><p>&nbsp;</p>
<p>The post <a rel="nofollow" href="/shortening-the-distance-between-creators-and-creation/">Shortening the distance between creators and creation in geo-computing</a> appeared first on <a rel="nofollow" href="/">Justin Gosses Home</a>.</p>
]]></content:encoded>
			<wfw:commentRss>/shortening-the-distance-between-creators-and-creation/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
	<post-id xmlns="com-wordpress:feed-additions:1">1066</post-id>	</item>
		<item>
		<title>half-baked thoughts on predicting chronostratigraphic surfaces</title>
		<link>/thoughts-on-machine-learning-predictions-of-chronostratigraphic-surfaces/</link>
		<comments>/thoughts-on-machine-learning-predictions-of-chronostratigraphic-surfaces/#respond</comments>
		<pubDate>Fri, 18 May 2018 02:45:29 +0000</pubDate>
		<dc:creator><![CDATA[Justin]]></dc:creator>
				<category><![CDATA[Uncategorized]]></category>

		<guid isPermaLink="false">/?p=1075</guid>
		<description><![CDATA[<p>EDIT: Released a package for predicting well log tops called, Predictatops&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;- Why make half-baked thoughts public? / DisclaimerI think predicting stratigraphic surfaces in well logs programmatically is a really interesting, if difficult, problem.  I&#8217;ve been working on it from time to time over the last few months as a side project after starting it as<a href="/thoughts-on-machine-learning-predictions-of-chronostratigraphic-surfaces/">[...]</a></p>
<p>The post <a rel="nofollow" href="/thoughts-on-machine-learning-predictions-of-chronostratigraphic-surfaces/">half-baked thoughts on predicting chronostratigraphic surfaces</a> appeared first on <a rel="nofollow" href="/">Justin Gosses Home</a>.</p>
]]></description>
				<content:encoded><![CDATA[<h2>EDIT: Released a package for predicting well log tops called, <a href=" https://justingosses.github.io/predictatops/html/index.html">Predictatops</a></h2><p>&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;-</p>
<h3>Why make half-baked thoughts public? / Disclaimer</h3><p>I think predicting stratigraphic surfaces in well logs programmatically is a really interesting, if difficult, problem.  I&#8217;ve been working on it from time to time over the last few months as a side project after starting it as a hackathon project. A person I know from the twitter-verse is going to this years version of the same AAPG hackathon and wanted to work on the same problem. He contacted me for suggestions. Although I&#8217;ve gotten some encouraging results, there are lots of paths to improvement that have not been to be tested. That means I have a lot of interesting but very likely wrong ideas in my head, which I&#8217;m sharing below. I&#8217;m also coming of 13 hours of jet lag. I apologize in advance for everything being a bulleted list and maybe not entirely making sense at times. Good luck!</p><p>&nbsp;</p>
<h3>Some Basics for the non-geologists:</h3>
<h4>What are well logs?</h4><p>Well logs are basically point measurements taken at set intervals along a well bore drilled into the earth. Typically, a half a foot is a common interval. These measurements are often visualized as line graphs tilted on their side. Depth is the y axis. Measurement of some physical property is the x axis. The number of different types of measurements, well curves, in a well varies. Typically, it might be three to twelve different curves. Wikipedia has some <a href="https://en.wikipedia.org/wiki/Well_logging">good general information</a> on well logs.</p>
<h4>What type of correlation?</h4><p>Geologists like to break things into formations and units. Basically, to say this bit of well A is the same as well B. Often, the implication is the rocks in unit A in one well are the same age as rocks in unit A in another well, hence chronostratigraphic correlation.</p><p>Due to the fact that well logs don&#8217;t directly measure age, chronostratigraphic correlations are interpretations by a geologist based on what they think formation A and formation B <em>should</em> look like.</p><p>If you&#8217;re not doing chronostratigraphic correlation, you&#8217;re likely doing lithostratigraphic correlation. In this type of correlation, you just correlating rocks with similar lithology. Sands to sands. Shales to Shales.</p><p>Lithostratigraphic correlation has an advantage in being done programmatically in that it doesn&#8217;t attempt to make very long correlations and the variance that has to be dealt with is smaller. For this reason, machine-learning or programmatic lithostratigraphic correlation between only two wells is possible, and probably preferred, where as you need a larger population of wells to do chronostratigraphic correlation using machine-learning.</p><p>A good example of programmatic lithostratigraphic correlation is the <a href="http://www.kgs.ku.edu/Publications/OFR/2002/OFR02_51/ManualOFR2002-51.pdf">CORRELATOR</a> Fortran-based software out of the <a href="http://www.kgs.ku.edu/software/softwareIndex.html">Kansas Geological Survey</a>.</p>
<h3></h3>
<h3>Geologic Truths that would be nice to include some how in any sort of automated approach?</h3>
<ol>
<li>Shales are more important than sands for correlating.</li>
<li>Surfaces have appearances than change both gradually over a region and over very short distances.</li>
<li>Usually if certain primary characteristics of a surface are not locally present, other secondary characteristics will still be present.</li>
<li>Very large changes in characteristics are unlikely to only appear once. They are commonly caused by salt dissolution, faults, or channelized erosion, which means their distribution may be localized but unlikely to just one well.</li>
</ol><p>&nbsp;</p>
<h3>Big simplistic concepts I like</h3>
<ol>
<li>If we think carefully about the types of observations geologists make while looking at logs and correlating them, we can come up with good ways to mimic those observations with quantitative programmatically generated features for machine-learning.</li>
<li>Class expression (whether or not a point is the surface in question) is highly variable. Your program should be able to deal with high variance and a some noise.</li>
</ol><p>&nbsp;</p>
<h3>Big simplistic concepts I don&#8217;t like</h3>
<ol>
<li>The idea that applying a single fancy math technique to raw data will work, because there is an underlying mathematical pattern to well log curves that makes them predictable (This is typically said by physicist or physics-inclined and really could be any domain they stumble into).</li>
<li>Fractals (just because you can squint and see them everywhere doesn&#8217;t mean they are useful for prediction).</li>
</ol><p>&nbsp;</p>
<h3>Parts I&#8217;m very certain about</h3>
<ol>
<li>To predict whether or not a point in a well is a specific time surface, you need to leverage information about that point, the points above and below it, the transition of points above and below it, points in neighboring wells, and information about known surfaces both locally and regionally &#8211; all in regards to that point in question that you are trying to determine whether or not is ___ chronostratigraphic surface.</li>
</ol><p>&nbsp;</p>
<h3>Thoughts I like but might be wrong</h3>
<ol>
<li>The need for many engineered features (and more than I have right now 40-60 features in total)</li>
<li>Tree-based machine-learning algorithms, like random forests or xgboost, are a way to go both as they are more self-explanatory (not a black box as you can see all the decision points) and deal well with spatial differences in class characteristics.</li>
<li>The <a href="http://www.kgs.ku.edu/Publications/OFR/2002/OFR02_51/ManualOFR2002-51.pdf">pearson correlation & shale character based approach</a> for programmatic lithostratigraphic correlation taken by the CORRELATOR software can be used in a machine-learning based approach as additional features.</li>
</ol><p>&nbsp;</p>
<h3>Thoughts I give less weights but might be useful</h3>
<ol>
<li>Ideally, you&#8217;d leverage as many logs as possible but should start with Gamma-ray.</li>
<li>Learning more and more towards some sort of multi-step approach in which a first round of prediction is done and then leveraged in second round.</li>
<li>Leveraging aggregate and map-based information on groupings from known wells and applying those groupings manually is a good idea.</li>
<li>Doing a two step machine-learning process where first step generates a class of unit name for each point and second step predicts a probability of each of the points being the pick in question. This might deal with some of the false positives and better take advantage of the some of the higher certainty information away from the point in question or away from the actual pick position.</li>
<li>Wavelet transform and <a href="https://ieeexplore.ieee.org/abstract/document/993193/">other approaches </a>have been useful in ECG waveform classification in the medical field. Although, I think these approaches won&#8217;t be as useful in well log correlation due to the wide variance in surface character, there might be a way to use them for local comparison of 2-5 wells where appearances are more likely to be similar, though this risks becoming strongly lithostratigraphic.</li>
</ol><p>&nbsp;</p>
<h3>Things I wonder about</h3>
<ol>
<li>What is the best way to included information about the the sequence of log curve data significantly above or below the point in question?
<ol>
<li>What would be the best way to combine LSTM (long-short term memory) into the process?</li>
<li>Is LSTM even needed or can that information be included in other ways?</li>
<li>What are other ways?</li>
</ol>
</li>
<li>What other features can I create from the well curve data?</li>
<li>Normalization:
<ol>
<li>To what degree do I need to normalize both raw and calculated data?</li>
<li>How much could this be throwing off the results?</li>
<li>What would be the best way to go about doing that given the raw data isn&#8217;t collected the same way every time?</li>
</ol>
</li>
</ol>
<h3></h3>
<h3>My current work in this problem space</h3>
<ul>
<li><a href="https://github.com/JustinGOSSES/MannvilleGroup_Strat_Hackathon">MannvilleGroup_Strat_Hackathon</a></li>
</ul><p>&nbsp;</p>
<h3>Good Reads</h3>
<ol>
<li><a href="http://www.kgs.ku.edu/Publications/OFR/2002/OFR02_51/ManualOFR2002-51.pdf">CORRELATOR User&#8217;s Manual : Lithostratigraphic Correlation in Fortran</a></li>
<li>&#8220;<a href="https://csegrecorder.com/articles/view/using-the-scattering-transform-to-predict-strat-units-from-well-logs">Using the Scattering Transform to Predict Stratigraphic Units from Well Logs</a>&#8220;, by Ben Bougher, Felix J. Herrmann</li>
</ol>
<h3></h3>
<h3>Possible algorithms<strong><br />
</strong></h3><p>I like tree-based algorithms for this problem it seems like they would deal well with class characteristics changing spatially and there are ways to visualizing the resulting leaves of a decision tree, which eliminates a lot of the black-box problem some people have with machine-learning. Additionally, if you can see into the algorithm decision making process, it might inspire creation of additional features or even new ways of looking at the geology.</p>
<ol>
<li>Extreme boosted trees or <a href="http://xgboost.readthedocs.io/en/latest/model.html">XGBoost</a></li>
<li>Random Forest</li>
<li>Some combination of LSTM and random forest&#8230;. not sure the best way to combine? Do LTSM only locally?</li>
</ol>
<h3></h3>
<h3>Notes on setting up the problem</h3>
<ul>
<li>If you judge success by trying to predict the formation of every point, you&#8217;ll appear to get decent results pretty easily. What you should really be going for is the picks. Error should not be % of formation points predicted successfully but rather the average error between predicted pick depth and actual pick depth.</li>
<li>There are 3-4 wells in the Mannville dataset that might give you problems with certain types of feature creation as there is &#8220;bad&#8221; or &#8220;odd&#8221; data in them.</li>
<li>Always useful to look at the actual wells before, during, and after trying to do machine-learning projects.</li>
</ul>
<div id="attachment_1091" style="width: 650px" class="wp-caption aligncenter"><a href="https://i2.wp.com/justingosses.com/wp-content/uploads/2018/05/Mannville_Xsection_B.png"><img data-attachment-id="1091" data-permalink="/thoughts-on-machine-learning-predictions-of-chronostratigraphic-surfaces/mannville_xsection_b/" data-orig-file="https://i2.wp.com/justingosses.com/wp-content/uploads/2018/05/Mannville_Xsection_B.png?fit=2000%2C1412" data-orig-size="2000,1412" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Mannville_Xsection_B" data-image-description="&lt;p&gt;Alberta Geological Survey Open File Report 1994-14. Cross-section B to B`.&lt;/p&gt;
" data-medium-file="https://i2.wp.com/justingosses.com/wp-content/uploads/2018/05/Mannville_Xsection_B.png?fit=300%2C212" data-large-file="https://i2.wp.com/justingosses.com/wp-content/uploads/2018/05/Mannville_Xsection_B.png?fit=640%2C452" class="size-large wp-image-1091" src="https://i2.wp.com/justingosses.com/wp-content/uploads/2018/05/Mannville_Xsection_B.png?resize=640%2C452" alt="Alberta Geological Survey Open File Report 1994-14. Cross-section B to B&#96;." width="640" height="452" srcset="https://i2.wp.com/justingosses.com/wp-content/uploads/2018/05/Mannville_Xsection_B.png?resize=1024%2C723 1024w, https://i2.wp.com/justingosses.com/wp-content/uploads/2018/05/Mannville_Xsection_B.png?resize=300%2C212 300w, https://i2.wp.com/justingosses.com/wp-content/uploads/2018/05/Mannville_Xsection_B.png?resize=768%2C542 768w, https://i2.wp.com/justingosses.com/wp-content/uploads/2018/05/Mannville_Xsection_B.png?w=1280 1280w, https://i2.wp.com/justingosses.com/wp-content/uploads/2018/05/Mannville_Xsection_B.png?w=1920 1920w" sizes="(max-width: 640px) 100vw, 640px" data-recalc-dims="1" /></a></p>
<p class="wp-caption-text">Alberta Geological Survey Open File Report 1994-14. Cross-section B to B`.</p>
</div>
<div id="attachment_1092" style="width: 650px" class="wp-caption aligncenter"><a href="https://i1.wp.com/justingosses.com/wp-content/uploads/2018/05/MannvilleWellsMap.png"><img data-attachment-id="1092" data-permalink="/thoughts-on-machine-learning-predictions-of-chronostratigraphic-surfaces/mannvillewellsmap/" data-orig-file="https://i1.wp.com/justingosses.com/wp-content/uploads/2018/05/MannvilleWellsMap.png?fit=1102%2C1369" data-orig-size="1102,1369" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="MannvilleWellsMap" data-image-description="&lt;p&gt;Map of Mannville wells in the Alberta Geological Survey open file report 1994-14 that are used in the project I&#8217;m doing at the github link.&lt;/p&gt;
" data-medium-file="https://i1.wp.com/justingosses.com/wp-content/uploads/2018/05/MannvilleWellsMap.png?fit=241%2C300" data-large-file="https://i1.wp.com/justingosses.com/wp-content/uploads/2018/05/MannvilleWellsMap.png?fit=640%2C795" class="size-large wp-image-1092" src="https://i1.wp.com/justingosses.com/wp-content/uploads/2018/05/MannvilleWellsMap.png?resize=640%2C795" alt="Map of Mannville wells in the Alberta Geological Survey open file report 1994-14 that are used in the project I'm doing at the github link." width="640" height="795" srcset="https://i1.wp.com/justingosses.com/wp-content/uploads/2018/05/MannvilleWellsMap.png?resize=824%2C1024 824w, https://i1.wp.com/justingosses.com/wp-content/uploads/2018/05/MannvilleWellsMap.png?resize=241%2C300 241w, https://i1.wp.com/justingosses.com/wp-content/uploads/2018/05/MannvilleWellsMap.png?resize=768%2C954 768w, https://i1.wp.com/justingosses.com/wp-content/uploads/2018/05/MannvilleWellsMap.png?w=1102 1102w" sizes="(max-width: 640px) 100vw, 640px" data-recalc-dims="1" /></a></p>
<p class="wp-caption-text">Map of Mannville wells in the Alberta Geological Survey open file report 1994-14 that are used in the project I&#8217;m doing at the github link. The data is <a href="http://ags.aer.ca/publications/SPE_006.html">here</a> and the <a href="http://ags.aer.ca/document/OFR/OFR_1994_14.PDF">Open File 1994-14</a> report is useful reading.</p>
</div><p>&nbsp;</p>
<h3>Basic Features</h3>
<ol>
<li>Raw values at a depth in a well & normalized values</li>
<li>For different windows above, below, around a point in question:
<ol>
<li>average, sum, max, min, max/min</li>
<li>ranges</li>
<li>slopes</li>
<li>variance</li>
<li>slope variance</li>
<li>same as everything above but for higher or lower ___ number of points</li>
</ol>
</li>
<li>Thickness of unit in question in nearby wells</li>
<li>Where surface would be in well in question if thickness didn&#8217;t change from nearby well</li>
<li>All characteristics from 1 & 2 in nearby wells with known surfaces</li>
</ol>
<h3></h3>
<h3>Things that would make this problem easier but don&#8217;t exist yet?</h3>
<ol>
<li>Multiple datasets of equal size to the Manville dataset. These would be handy to test the degree of generalization of the methods (not the model).</li>
<li>A widget for playing / creating new features that would let me see how new features relate to class identification across single and multiple wells without a lot of clicks but mostly just drags and rotates, such that the hypothesis space can be explored quickly.
<ol>
<li>EXAMPLE:
<ol>
<li>Elements of :
<ol>
<li>code input box</li>
<li>Widgets that let your drag to change values of variables in the code.
<ol>
<li>Examples of variables changed via a slider:
<ol>
<li>window length</li>
<li>Minimum slope angle</li>
<li>etc.</li>
</ol>
</li>
</ol>
</li>
<li>cross-section of well log(s)</li>
<li>scatter plot in 3D with colors being classes (probably unit names or pick, near pick, and not pick.)</li>
</ol>
</li>
<li>Behavior:
<ol>
<li>In real-time dragging the sliders back and forth changes the display of the feature along the well curve in each well. At the same time, the data for the well(s) in question is automatically altered in a scatter plot generated using three features as the x, y, z axis and class name (probably something like pick, within 5 meters of pick, and not pick) as the color of the point.</li>
<li>By moving many sliders back and forth I can explore the hypothesis space quickly and find features that separate the classes better.</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
<li>Need better way to visualize pick uncertainty and multiple pick possibilities in single well, multiple ways, and all wells.</li>
</ol>
<h3></h3>
<h3>Hackathon-sized sub-problems to tackle</h3>
<ol>
<li>See number 2 in section directly above.</li>
<li>See number 3 in section directly above.</li>
<li>What&#8217;s the best way to identify sub-regional trends like thickness, background shale value, chance of confusing erosion surfaces, etc. that might correlate with surface appearance changes and be identified as within certain spatial areas from known wells.</li>
<li>CORRELATOR used a small expert knowledge system with their more programmatic work. Can something similar be done here?</li>
<li>What are the different ways to visualize error in pick prediction or multiple different potential pick positions based on probability?</li>
<li>Optimize the feature creation code here: <a href="https://github.com/JustinGOSSES/MannvilleGroup_Strat_Hackathon">MannvilleGroup_Strat_Hackathon</a></li>
<li>In the mannville dataset, there are a large number of wells with facies identified as well. Can the distribution of facies be used as another feature? What would it add?</li>
<li>Re-build at least part of CORRELATOR in python, instead of Fortran, and then use comparisons of neighbor wells for features. Alternatively, use a completely different correlation coefficient approach that does something roughly similar (but easier) that could at least provide some ballpark constraints on where the other features should be looking.</li>
<li>Can we create an expert system to quantitatively identify and describe circumstances where lithostratigraphy is likely fine or likely not fine?
<ol>
<li>Prograding parasquences?</li>
<li>Transgressive surface hard grounds?</li>
</ol>
</li>
</ol>
<p>The post <a rel="nofollow" href="/thoughts-on-machine-learning-predictions-of-chronostratigraphic-surfaces/">half-baked thoughts on predicting chronostratigraphic surfaces</a> appeared first on <a rel="nofollow" href="/">Justin Gosses Home</a>.</p>
]]></content:encoded>
			<wfw:commentRss>/thoughts-on-machine-learning-predictions-of-chronostratigraphic-surfaces/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
	<post-id xmlns="com-wordpress:feed-additions:1">1075</post-id>	</item>
		<item>
		<title>Using Machine-learning to Extend Stratigraphic Surfaces</title>
		<link>/stratigraphicpicks/</link>
		<comments>/stratigraphicpicks/#respond</comments>
		<pubDate>Wed, 27 Sep 2017 23:25:57 +0000</pubDate>
		<dc:creator><![CDATA[Justin]]></dc:creator>
				<category><![CDATA[code]]></category>
		<category><![CDATA[geology]]></category>
		<category><![CDATA[Geology]]></category>
		<category><![CDATA[machine-learning]]></category>
		<category><![CDATA[ML]]></category>
		<category><![CDATA[stratigraphic]]></category>

		<guid isPermaLink="false">/?p=965</guid>
		<description><![CDATA[<p>[BLOG POST COMING SOON]This weekend I finally got to do a hackathon project I&#8217;ve been wanting to try for more than two years. It leverages machine-learning to mimic human-created stratigraphic picks. It uses a dataset of 2000 wells with picks from the Alberta Energy Regulator, which is one of the only public datasets I&#8217;m aware<a href="/stratigraphicpicks/">[...]</a></p>
<p>The post <a rel="nofollow" href="/stratigraphicpicks/">Using Machine-learning to Extend Stratigraphic Surfaces</a> appeared first on <a rel="nofollow" href="/">Justin Gosses Home</a>.</p>
]]></description>
				<content:encoded><![CDATA[<p>[BLOG POST COMING SOON]</p><p>This weekend I finally got to do a hackathon project I&#8217;ve been wanting to try for more than two years. It leverages machine-learning to mimic human-created stratigraphic picks. It uses a <a href="http://ags.aer.ca/publications/SPE_006.html">dataset</a> of 2000 wells with picks from the Alberta Energy Regulator, which is one of the only public datasets I&#8217;m aware of with that many picks of the same surfaces done by people trying to pick in the same way. We only got the first pass done, as is the nature of hackathons, but we&#8217;re going to keep working on the idea. I think it has a lot of potential. We&#8217;re trying to take a more geologic approach and a less geophysicist or mathematical approach, which has been more typically been used in past efforts.</p><p>I&#8217;ll edit this to be a longer post later, but for now here is the link to the project on github.</p><p><a href="https://github.com/JustinGOSSES/MannvilleGroup_Strat_Hackathon">https://github.com/JustinGOSSES/MannvilleGroup_Strat_Hackathon</a></p>
<div id="attachment_967" style="width: 894px" class="wp-caption aligncenter"><a href="https://i2.wp.com/justingosses.com/wp-content/uploads/2017/09/Screen-Shot-2017-09-27-at-6.22.31-PM.png"><img data-attachment-id="967" data-permalink="/stratigraphicpicks/screen-shot-2017-09-27-at-6-22-31-pm/" data-orig-file="https://i2.wp.com/justingosses.com/wp-content/uploads/2017/09/Screen-Shot-2017-09-27-at-6.22.31-PM.png?fit=884%2C552" data-orig-size="884,552" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screen Shot 2017-09-27 at 6.22.31 PM" data-image-description="&lt;p&gt;Predicted (blue) vs. true depth (red) of the top McMurray pick. &lt;/p&gt;
" data-medium-file="https://i2.wp.com/justingosses.com/wp-content/uploads/2017/09/Screen-Shot-2017-09-27-at-6.22.31-PM.png?fit=300%2C187" data-large-file="https://i2.wp.com/justingosses.com/wp-content/uploads/2017/09/Screen-Shot-2017-09-27-at-6.22.31-PM.png?fit=640%2C400" class="size-full wp-image-967" src="https://i2.wp.com/justingosses.com/wp-content/uploads/2017/09/Screen-Shot-2017-09-27-at-6.22.31-PM.png?resize=640%2C400" alt="Predicted (blue) vs. true depth (red) of the top McMurray pick. " width="640" height="400" srcset="https://i2.wp.com/justingosses.com/wp-content/uploads/2017/09/Screen-Shot-2017-09-27-at-6.22.31-PM.png?w=884 884w, https://i2.wp.com/justingosses.com/wp-content/uploads/2017/09/Screen-Shot-2017-09-27-at-6.22.31-PM.png?resize=300%2C187 300w" sizes="(max-width: 640px) 100vw, 640px" data-recalc-dims="1" /></a></p>
<p class="wp-caption-text">Predicted (blue) vs. true depth (red) of the top McMurray pick.</p>
</div><p>&nbsp;</p>
<p>The post <a rel="nofollow" href="/stratigraphicpicks/">Using Machine-learning to Extend Stratigraphic Surfaces</a> appeared first on <a rel="nofollow" href="/">Justin Gosses Home</a>.</p>
]]></content:encoded>
			<wfw:commentRss>/stratigraphicpicks/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
	<post-id xmlns="com-wordpress:feed-additions:1">965</post-id>	</item>
		<item>
		<title>What do I get out of conferences?</title>
		<link>/what-do-i-get-out-of-conferences/</link>
		<comments>/what-do-i-get-out-of-conferences/#respond</comments>
		<pubDate>Tue, 30 May 2017 06:23:56 +0000</pubDate>
		<dc:creator><![CDATA[Justin]]></dc:creator>
				<category><![CDATA[code]]></category>
		<category><![CDATA[geology]]></category>
		<category><![CDATA[Uncategorized]]></category>
		<category><![CDATA[AAPG]]></category>
		<category><![CDATA[Agile Geoscience]]></category>
		<category><![CDATA[conference]]></category>
		<category><![CDATA[convention]]></category>
		<category><![CDATA[data science]]></category>
		<category><![CDATA[Geology]]></category>
		<category><![CDATA[hackathon]]></category>
		<category><![CDATA[HTML]]></category>
		<category><![CDATA[learning]]></category>
		<category><![CDATA[NASA]]></category>
		<category><![CDATA[Online Map]]></category>
		<category><![CDATA[python]]></category>
		<category><![CDATA[talks]]></category>
		<category><![CDATA[tutorials]]></category>
		<category><![CDATA[web development]]></category>

		<guid isPermaLink="false">/?p=894</guid>
		<description><![CDATA[<p>Four conferences, two hackathons, and a lot of meet-ups: Analyzing what I&#8217;ve gotten from technical gatherings outside of work this year&#160; Part 1 &#8211;  The PremiseOver the last year, I&#8217;ve been lucky to attend more than my usual number of conferences, meetups, and hackathons. Some of the events were paid by work, some were paid<a href="/what-do-i-get-out-of-conferences/">[...]</a></p>
<p>The post <a rel="nofollow" href="/what-do-i-get-out-of-conferences/">What do I get out of conferences?</a> appeared first on <a rel="nofollow" href="/">Justin Gosses Home</a>.</p>
]]></description>
				<content:encoded><![CDATA[<h3 style="text-align: center;">Four conferences, two hackathons, and a lot of meet-ups: Analyzing what I&#8217;ve gotten from technical gatherings outside of work this year</h3><p>&nbsp;</p>
<h2>Part 1 &#8211;  The Premise</h2><p>Over the last year, I&#8217;ve been lucky to attend more than my usual number of conferences, meetups, and hackathons. Some of the events were paid by work, some were paid by me, and some were free. As my last event for 2017 is coming up, I&#8217;m asking myself two questions.</p><p><strong>First, what did I get out of the gatherings I attended?</strong></p><p><strong>Second, what types of events should I attend next year in order to maximize the benefits I&#8217;m interested in?</strong></p><p>As I see it, attending technical gatherings can have a range of benefits:</p>
<ol>
<li>People
<ul>
<li>Meet leaders in the field</li>
<li>Make new contacts and catch up with old contacts</li>
<li>Meet many vendors at once</li>
<li>Market yourself and your company</li>
<li>Gain a better understanding of where your skills and knowledge rank</li>
</ul>
</li>
<li>Skills
<ul>
<li>Pick up new &#8220;tricks of the trade&#8221;</li>
<li>Learn what to do or not do from others&#8217; experiences</li>
<li>Attend a tutorial and take the first few steps in a new skill with someone there to lead you</li>
</ul>
</li>
<li>Knowledge of the environment beyond your immediate organization
<ul>
<li>Gain exposure to a wide range of tools, methods, and applications</li>
<li>Learn what is upcoming and new</li>
<li>Understand how the larger market or community is evolving</li>
</ul>
</li>
</ol><p>Working under the assumption that understanding what I got out of the past events will help me plan ahead, I&#8217;ve compiled a description of various technical gatherings I&#8217;ve attended over the last twelve months.</p>
<h2>Part 2 &#8211; The Data</h2><p>&nbsp;</p>
<h2 style="text-align: center;">AAPG ACE 2017</h2>
<h5><span style="color: #008000;">What is it?</span></h5><p><a href="http://www.aapg.org/">American Association of Petroleum Geologist</a>s Annual <a href="http://ace.aapg.org/2017/about">Conference & Exhibit</a>. It is the main conference for petroleum geologists and the largest of several AAPG conferences. The conference can cost between $65 and $650 depending on whether you are a student and when you purchase.</p>
<h5><span style="color: #008000;">Who goes?</span></h5><p>Geologists in the oil and gas industry and some geophysicists. Engineers have their own conferences. The focus is on technical aspects as opposed to business environment or deal making.</p>
<h5><span style="color: #008000;">Dress?</span></h5><p>Most people dress like they do at work, which is to say dress pants, dress pants, and collared shirts if you&#8217;re a guy or the equivalent if female. If you&#8217;re presenting or looking for work, you might wear a suit and tie. A few people wear jeans. There are no funny t-shirts.</p>
<h5><span style="color: #008000;">Where?</span></h5><p>This year it was in Houston. The conference moves every year between North American oil industry centers like Houston, Long Beach, Calgary, and Denver.</p>
<h5><span style="color: #008000;">How big?</span></h5><p>The average over the last 5 years has been <a href="http://www.aapg.org/events/conferences/ace">6,900</a>.</p>
<h5><span style="color: #008000;">Types of talks?</span></h5><p>Most of the talks follow the pattern of a typical science talk explaining what they did in very rough terms and what their conclusions are.</p>
<h5><span style="color: #008000;">Main Benefits for me</span></h5>
<ul>
<li><em>Make new contacts and catch up with old contacts</em>
<ul>
<li>AAPG ACE was very good for making connections with people I haven&#8217;t seen in a while now that I&#8217;m out of the oil and gas industry.</li>
</ul>
</li>
<li><em>Learn what is upcoming and new</em>
<ul>
<li>It is also a great place for seeing what is at the forefront of the intersection between industry and academia in geology as various research consortia present talks and posters.</li>
</ul>
</li>
</ul>
<h5><span style="color: #008000;">Benefit areas that were lacking</span></h5>
<ul>
<li><em>Pick up new &#8220;tricks of the trade&#8221;</em></li>
<li><em>Attend a tutorial and take the first few steps in a new skill with someone to lead you</em>
<ul>
<li>Compared with tech conferences, the range of talk types is limited. There are almost no &#8220;how to&#8221; or &#8220;when to use blank method&#8221; talks. Everything is in the science talk mold.</li>
</ul>
</li>
</ul>
<h5><span style="color: #008000;">Summary</span></h5><p>AAPG was great for catching up with people and getting a peek at what other people are working on, even if it is a small peak. Some of the talks can be frustratingly vague due to intellectual property constraints. Field trips provide some opportunity for improving technical skills, but they typically cost enough that you&#8217;ll only attend if your employer is paying. The main convention talks tend to focus on what someone has been done rather than what you could do.</p><p>If you&#8217;re interested in hearing more about what geology conferences are missing and what they might be able to learn from certain tech conference models, the Undersampled Radio podcast recent had a great conversation on this topic starting at 30 minutes into <a href="https://www.youtube.com/watch?v=vCeNA9btD9E"> episode 46</a>.</p>
<h2 style="text-align: center;">SXSW Interactive</h2>
<h5><span style="color: #008000;"> What is it?</span></h5><p>South by Southwest is a mega-conference in which the &#8220;<a href="https://www.sxsw.com/festivals/interactive/">Interactive</a>&#8221; sub-conference focuses on digital, internet, intelligent future, social impact, journalism, start-ups, AR/VR, music industry, sports industry, and the workplace. The interactive sub-conference takes place over 5 days and overlaps with the education, music, film, and comedy sub-conferences. More information <a href="https://www.sxsw.com/festivals/interactive/">here</a>. SXSW Interactive tickets cost $1,225.</p>
<h5><span style="color: #008000;">Who goes?</span></h5><p>Marketing companies, hip people, students who volunteer to get their otherwise expensive tickets paid for, and people in the digital space who want to see what is new or make connections.</p>
<h5><span style="color: #008000;">Dress?</span></h5><p>Varies from nerdy t-shirts to professor jackets with elbow patches. If business casual, a little on the fashionable side.</p>
<h5><span style="color: #008000;">Where?</span></h5><p>Austin, every year.</p>
<h5><span style="color: #008000;">How big?</span></h5><p><a href="https://en.wikipedia.org/wiki/South_by_Southwest">30,621</a></p>
<h5><span style="color: #008000;">Types of talks?</span></h5><p>The talks here range from &#8220;this is new&#8221; to &#8220;we did and you can too&#8221; to &#8220;let&#8217;s talk about the context of something&#8221; to &#8220;fluff and buzzwords&#8221;.</p>
<h5><span style="color: #008000;">Main Benefits for me</span></h5>
<ul>
<li><em>Meet leaders in the field</em>
<ul>
<li>I talked with <a href="https://homes.cs.washington.edu/~jheer/">Vint Cerf</a>, one of the &#8220;fathers of the internet, and <a href="https://homes.cs.washington.edu/~jheer/">Jeffrey Heer </a>, a professor who has had a role in many key data visualization code libraries, such as <a href="https://vega.github.io/vega/">vega.js</a>, <a href="https://vincent.readthedocs.io/en/latest/">vincent.py</a>, and <a href="https://d3js.org/">d3.js</a>.</li>
</ul>
</li>
<li><em>Understand trends in the larger market or community. Learn what is new</em></li>
<li><em>Learn what is upcoming and new</em>
<ul>
<li>Saw a lot in regards to VR/AR that was cutting edge.</li>
</ul>
</li>
<li><em>Understand how the larger market or community is evolving</em></li>
<li><em>Meet many vendors at once</em>
<ul>
<li>Largest exhibit showroom of any conference in this list.</li>
<li>Met with two vendors afterward and used the experience to benchmark against other vendors post conference</li>
</ul>
</li>
<li><em>Meet people doing similar work and learn from their experiences</em>
<ul>
<li>There were several talks that inspired ideas for future projects based on what similar teams had done in other organizations. Post-talk discussions were great for identifying failures to avoid in upcoming projects.</li>
</ul>
</li>
</ul>
<h5><span style="color: #008000;">Benefit areas that were lacking</span></h5>
<ul>
<li><em>Pick up new &#8220;tricks of the trade&#8221;</em>
<ul>
<li>Talks tend to lack technical depth.</li>
</ul>
</li>
<li><em>Attend a tutorial and take the first few steps in a new skill with someone to lead you</em>
<ul>
<li>There weren&#8217;t any tutorials.</li>
</ul>
</li>
<li><em>Learn about the larger range of tools, methods, and applications out there</em>
<ul>
<li>There are more talks about products and solutions than methods or tools.</li>
</ul>
</li>
</ul>
<h5><span style="color: #008000;">Summary</span></h5><p>There were some great talks that inspired potential future projects, but meeting people was the more valuable activity at SXSW. Perhaps for that reason, there were <a href="http://schedule.sxsw.com/2017/03/10/events/conference/Interactive/type/panel">several time slots</a> for people to just &#8220;meet-up&#8221; in a room and talk about a specific topic.</p>
<h3 style="text-align: center;">PyCon2017</h3>
<h5><span style="color: #008000;">What is it?</span></h5><p><a href="https://us.pycon.org/2017/">PyCon</a> is the largest conference for Python developers. Web development and data analytics are the two focus areas. The base convention ticket for PyCon is $600 for corporate, $350 for individuals, and $125 for students. If sign-up for the max amount of tutorials, total ticket price can be up to $1200.</p>
<h5><span style="color: #008000;">Who goes?</span></h5><p>People who write code in Python. The male/female ratio at PyCon was maybe 70/30, which made it the most unbalanced of all the conferences.</p>
<h5><span style="color: #008000;">Dress?</span></h5><p>There&#8217;s a range, but, compared to the other conferences, it was high on nerdy t-shirts and low on formal or business clothes.</p>
<h5><span style="color: #008000;">Where?</span></h5><p>PyCon was held in Portland, Oregon. PyCon holds their conferences in the same city for two years before switching, which minimizes costs and planning requirements. Next year, it will be in Cleveland, Ohio. Previous to Portland, it was in Montreal.</p>
<h5><span style="color: #008000;">How big?</span></h5><p><a href="https://en.wikipedia.org/wiki/Python_Conference">3,391</a> badges were picked up from registration.</p>
<h5><span style="color: #008000;">Types of talks?</span></h5><p>PyCon is split into two days of tutorials, three days of talks, and then four days of open-source development sprints.</p>
<ul>
<li>Tutorials are half a day in length. Topics included Bayesian machine learning, time series analysis, network analysis, using flask for microservices, <a href="https://us.pycon.org/2017/schedule/tutorials/">etc</a>.</li>
<li>During the main convention, talks ranged in style from:
<ul>
<li>We did this with Python</li>
<li>Best practice in some aspect of writing code</li>
<li>The &#8220;craft&#8221; of some part of writing python code</li>
<li>Introduction to a new python module or open-source project</li>
<li>Introduction to some activity that can be done with python</li>
</ul>
</li>
<li>During the sprints, open-source Python <a href="https://us.pycon.org/2017/community/sprints/">projects</a> are built or extended.</li>
</ul>
<h5><span style="color: #008000;">Main Benefits for me</span></h5>
<ul>
<li><em>Meet leaders in the field</em>
<ul>
<li>Ended up at a bar with <a href="https://www.destroyallsoftware.com/talks/the-birth-and-death-of-javascript">Gary Bernhardt</a> , who runs &#8220;destroyallsoftware.com&#8221;, and <a href="https://www.kennethreitz.org/projects/">Kenneth Reitz</a>, the main author of the &#8220;requests&#8221; python module.</li>
</ul>
</li>
<li><em>Attend a tutorial and take the first few steps in a new skill with someone to lead you</em>
<ul>
<li>Attended excellent half-day <a href="https://us.pycon.org/2017/schedule/tutorials/">tutorials</a> on Bayesian machine learning, time series analysis, and MQTT protocol.</li>
</ul>
</li>
<li><em>Pick up new &#8220;tricks of the trade&#8221;</em>
<ul>
<li>Several talks were on the &#8220;craft&#8221; of some aspect of writing code, examples included documentation, testing, and sever reliability.</li>
</ul>
</li>
<li><em>Meet people doing similar work and learn from their experiences</em>
<ul>
<li>Talked to a variety of people doing similar work in different organizations and learned how their teams and approaches differ from mine.</li>
</ul>
</li>
<li><em>Learn about the larger range of tools, methods, and applications out there</em>
<ul>
<li>Got exposure to a range of new modules and methods and what they could be used for.</li>
</ul>
</li>
</ul>
<h5><span style="color: #008000;">Benefit areas that were lacking</span></h5>
<ul>
<li><em>Meet many vendors at once</em>
<ul>
<li>Although there was an exhibit floor, the number and diversity of vendors were a bit lacking for a conference of that size.</li>
</ul>
</li>
</ul>
<h5><span style="color: #008000;">Summary</span></h5><p>PyCon was excellent for picking up bits of new skills and improving my understanding of what python modules I might be able to use in future projects. Many of the talks had a focus on leaving the audience with something useful, which made it a great conference for learning. My <a href="https://docs.google.com/document/d/1zm0x1uLg-SKGI4nbu-_ND_44Bycl_wo4tTxVpjDDC6g/edit?usp=sharing">notes</a> have links to the slides and Jupyter Notebooks used by some of the presenters.</p>
<h3 style="text-align: center;">Johnson Space Center Data Science Day</h3>
<h5><span style="color: #008000;">What is it?</span></h5><p><a href="https://fal.jsc.nasa.gov/DSD/">Data Science Day 2.0</a> was two days of talks around various aspects of data science, data visualization, and analytics. It was free to attend.</p>
<h5><span style="color: #008000;">Who goes?</span></h5><p>A mixture of NASA civil servants, NASA contractors, vendors, and the public who were interested in the subject matter.</p>
<h5><span style="color: #008000;">Dress?</span></h5><p>Mostly business casual with some suits and ties.</p>
<h5><span style="color: #008000;">Where?</span></h5><p>Gilruth Center just outside Johnson Space Center, Houston, Texas.</p>
<h5><span style="color: #008000;">How big?</span></h5><p>I estimate 200-350.</p>
<h5><span style="color: #008000;">Types of talks?</span></h5><p>Talks ranged from programming newbie talks to &#8220;we built this&#8221; talks to &#8220;this capability exists&#8221; talks.</p>
<h5><span style="color: #008000;">Main Benefits for me</span></h5>
<ul>
<li><em>Learn about the larger range of tools, methods, and applications out there</em>
<ul>
<li>Got exposure to skills and methods I haven&#8217;t used myself yet.</li>
</ul>
</li>
<li><em>Meet people doing similar work and learn from their experiences</em>
<ul>
<li>Made connections to others at Johnson Space Center who were interested in working with our team.</li>
</ul>
</li>
<li><em>Market yourself and your company</em>
<ul>
<li>Presented a <a href="http://slides.com/justingosses/history_data_visualization_tools#/">talk</a> on the history of digital data visualization tools.</li>
</ul>
</li>
</ul>
<h5><span style="color: #008000;">Benefit areas that were lacking</span></h5>
<ul>
<li><em>Pick up new &#8220;tricks of the trade&#8221;</em>
<ul>
<li>There weren&#8217;t many talks about the craft of data science or data visualization.</li>
</ul>
</li>
</ul>
<h5><span style="color: #008000;">Summary</span></h5><p>Given Johnson Space Center is a rather spread out campus with many buildings, events like this are really valuable for communicating about skills that cross normal organizational boundaries. Attending an event of this type wouldn&#8217;t replace something like PyCon, however, due to the lack of tutorials and in-depth skill sessions.</p>
<h3 style="text-align: center;">Various Houston Tech Meetups</h3>
<h5><span style="color: #008000;">What is it?</span></h5><p>There are a variety of <a href="https://www.meetup.com/find/?allMeetups=false&keywords=tech&radius=25&userFreeform=Houston%2C+TX&mcId=c77001&mcName=Houston%2C+TX&sort=default">meetups</a> in Houston that focus on t<a href="https://www.meetup.com/Collabonauts/">ech</a>, <a href="https://www.meetup.com/houston-js/events/240279389/">web development</a>, <a href="https://www.meetup.com/Houston-VR-Developers/events/239502556/">virtual reality</a>, <a href="https://www.meetup.com/Hackster-Hardware-Meetup-Houston/events/240263187/">IoT</a>, and <a href="https://www.meetup.com/Houston-Energy-Data-Science-Meetup/">data science</a>. These are typically 1.5 to 4-hour meetings around various topics held every month or two somewhere in Houston. I regularly go to ones on <a href="https://www.meetup.com/Houston-Data-Visualization-Meetup/">data visualization</a>, <a href="https://www.meetup.com/houston-js/">JavaScript</a>, <a href="https://www.meetup.com/python-web-houston/">Python</a>, <a href="https://www.meetup.com/sketchcity/events/239311484/">civic projects</a>, and <a href="https://www.meetup.com/Houston-React-Js-Group/events/240297939/">front-end web development</a>. They are free to attend although sometimes donations are requested for snacks.</p>
<h5><span style="color: #008000;">Who goes?</span></h5><p>Anyone interested in the subject. Attendees range from complete newbies to professional developers.</p>
<h5><span style="color: #008000;">Dress?</span></h5><p>Casual to whatever people were wearing at work.</p>
<h5><span style="color: #008000;">Where?</span></h5><p>It varies from civic community spaces to tech companies to coffee shops and bars.</p>
<h5><span style="color: #008000;">How big?</span></h5><p>5-75, but many times a year.</p>
<h5><span style="color: #008000;">Types of talks?</span></h5><p>The two most common types are &#8220;introduction to blank&#8221; talks and &#8220;this is what I have done with blank&#8221; talks. My favorite is Houston data visualization meetup&#8217;s monthly &#8220;data jams&#8221;. A cleaned dataset is provided. Participants have 4 hours to build data visualizations with any code library or software tool they care to apply. This is a great way to learn about new tools and methods for data visualization.</p>
<h5><span style="color: #008000;">Main Benefits for me</span></h5>
<ul>
<li><em>Learn about the larger range of tools, methods, and applications out there</em>
<ul>
<li>You&#8217;ll get exposure to a wide range of tools and approaches for a single topic.</li>
</ul>
</li>
<li><em>Meet people doing similar work and learn from their experiences</em>
<ul>
<li>Make connections across industries and organizations in Houston.</li>
</ul>
</li>
<li>Make new contacts and catch up with old contacts</li>
<li><em>Market yourself and your company</em>
<ul>
<li>The easiest place to present a talk or contribute to the local developer community.</li>
</ul>
</li>
</ul>
<h5><span style="color: #008000;">Benefit areas that were lacking</span></h5>
<ul>
<li><em>Meet many vendors at once</em>
<ul>
<li>Vendor pitches are generally frowned upon, so there aren&#8217;t that many. Energy industry meetups are the exception.</li>
</ul>
</li>
<li><em>Meet leaders in the field</em>
<ul>
<li>Unfortunately, Houston is not much of a tech hub, so there aren&#8217;t that many big names here.</li>
</ul>
</li>
</ul>
<h5><span style="color: #008000;">Summary</span></h5><p>The main benefit of meetups for me is the exposure to a wide range of tools applied to the same topic or problem. This saves me a great amount of time in terms of researching and comparing new tools myself.</p>
<h3 style="text-align: center;">Space-Apps Challenge Houston</h3>
<h5><span style="color: #008000;">What is it?</span></h5><p>A <a href="https://2017.spaceappschallenge.org/">global hackathon</a> that uses NASA data, but is hosted locally in many cities around the world. This was the first year the event was hosted in Houston for several years. Participants form teams and have two days to hack together a solution, usually a web application but sometimes hardware, to one of the NASA <a href="https://2017.spaceappschallenge.org/challenges/">challenges</a>. It is free to attend. There was sponsor swag, coffee, beer, and food from <a href="http://stationhouston.com/">Station Houston</a>, Amazon Web Services, Intel, and <a href="https://www.yelp.com/biz/morningstar-houston">Morningstar Coffee</a>. I was a technical mentor during the event, not a participant.</p>
<h5><span style="color: #008000;">Who goes?</span></h5><p>Participants at the Houston event included high school students with a little coding knowledge, recent coding boot camp graduates, computer science undergraduates, IBM engineers, and professional web developers.</p>
<h5><span style="color: #008000;">Dress?</span></h5><p>85% jeans & t-shirt and 15% slightly fancier.</p>
<h5><span style="color: #008000;">Where?</span></h5><p><a href="https://www.theironyard.com/locations/houston">The Iron Yard</a>, a coding boot camp with locations in various cities, including Houston.</p>
<h5><span style="color: #008000;">How big?</span></h5><p>~30</p>
<h5><span style="color: #008000;">Types of talks?</span></h5><p>Aside from a 20-minute talk on NASA civilian science, the time was spent working on each team&#8217;s project. You can read more about some of the projects created at the Houston event <a href="https://2017.spaceappschallenge.org/locations/houston/">here</a>.</p>
<h5><span style="color: #008000;">Main Benefits for me</span></h5>
<ul>
<li><em>Learn about the larger range of tools, methods, and applications out there</em>
<ul>
<li>Two of the teams used technologies I hadn&#8217;t worked with before.</li>
</ul>
</li>
<li><em>Pick up new &#8220;tricks of the trade&#8221;</em></li>
<li><em>Make new contacts and catch up with old contacts</em>
<ul>
<li>Made connections with several or the participants</li>
<li>Worked with <a href="http://stationhouston.com/">Station</a>, <a href="https://www.theironyard.com/locations/houston">The Iron Yard</a>, and several <a href="https://www.meetup.com/Houston-Data-Visualization-Meetup/">meet-up group</a> leads to organize the event.</li>
</ul>
</li>
</ul>
<h5><span style="color: #008000;">Benefit areas that were lacking</span></h5>
<ul>
<li><em>Meet leaders in the field</em></li>
<li><em>Meet people doing similar work and learn from their experiences</em></li>
<li><em>Meet many vendors at once</em></li>
</ul>
<h5><span style="color: #008000;">Summary</span></h5><p>As a participant, hackathons are great for taking a method or technology that is new to you, cramming as much about it into your brain as possible, and then applying it in a very intense, short period of time. As a technical mentor, who also did a bit of event organization, it is a great way to expand your network, learn from others, and you get some of the previously mentioned technical benefits too.</p>
<h3 style="text-align: center;">Agile Scientific Paris Subsurface Hackathon</h3>
<h5><span style="color: #008000;">What is it?</span></h5><p>A hackathon associated with a geological society conference in Paris.  This is one of <a href="https://agilescientific.com/">Agile Scientific&#8217;s</a> hackathons that take place 1-3 times a year at geology and geophysics conferences. Total is co-organizing it. It is free to attend.</p>
<h5><span style="color: #008000;">Who goes?</span></h5><p>Geologists and geophysicists who know how to code, usually in Python. Web development skills are typically sparse. Several people, including myself, will be participating as &#8220;robots&#8221;. This means I&#8217;ll be teleconferencing into the hackathon and my face will be appearing on a little laptop there.</p>
<h5><span style="color: #008000;">Dress?</span></h5><p>Most of the on-location participants will be French, so I&#8217;m assuming they will likely be better dressed than me.</p>
<h5><span style="color: #008000;">Where?</span></h5><p>Virtual & Paris.</p>
<h5><span style="color: #008000;">How big?</span></h5><p>Not sure as it hasn&#8217;t happened yet, but looks to be around 50.</p>
<h5><span style="color: #008000;">Types of talks?</span></h5><p>There will likely be an introduction talk and then lots of coding.</p>
<h5><span style="color: #008000;">Main Benefits for me</span></h5>
<ul>
<li><em>Learn about the larger range of tools, methods, and applications out there</em>
<ul>
<li>This always seems to happen at hackathons.</li>
</ul>
</li>
<li>Pick up new &#8220;tricks of the trade&#8221;
<ul>
<li>A lot of my coding ability was picked up after I left oil and gas, so it will be nice to work with geological datasets.</li>
</ul>
</li>
<li>Make new contacts and catch up with old contacts
<ul>
<li>Several of the participants are people I know from a previous hackathon.</li>
</ul>
</li>
</ul>
<h5><span style="color: #008000;">Summary</span></h5><p>I&#8217;m hoping to use this as an opportunity to apply a new skill area that I&#8217;ll be using at work eventually but haven&#8217;t had much opportunity to use yet. Possibilities include time-series analysis, deep-learning, web-scraping, and natural language processing.</p>
<h2>Part 3  &#8211;  The Analysis</h2>
<h3>Ranking of which events had which benefits the most</h3><p>Based on the notes above, I&#8217;ve ranked the events in terms of how well they fulfilled each benefit in my list. The event that most fulfilled each benefit is in <span style="color: #ff0000;">red<span style="color: #000000;">, with second in</span> <span style="color: #cc99ff;">purple</span><span style="color: #000000;">, etc</span></span>.</p>
<ol>
<li>People
<ul>
<li><em>Meet leaders in the field</em>
<ul>
<li><span style="color: #993300;"><span style="color: #ff0000;">SXSW &</span> <span style="color: #cc99ff;">PyCon</span></span></li>
</ul>
</li>
<li><em>Meet people doing similar work and learn from their experiences</em>
<ul>
<li><span style="color: #993300;"><span style="color: #ff6600;"><span style="color: #ff0000;">Meet-ups</span>,</span> <span style="color: #cc99ff;">PyCon</span><span style="color: #ff9900;"><span style="color: #cc99ff;">,</span> <span style="color: #99cc00;">JSC Data Science Day<span style="color: #99ccff;">,</span></span><span style="color: #99ccff;"> and meetups</span></span></span></li>
</ul>
</li>
<li><em>Make new contacts and catch up with old contacts</em>
<ul>
<li><span style="color: #993300;"><span style="color: #ff0000;">AAPG,</span> <span style="color: #cc99ff;">meetups,</span> <span style="color: #99cc00;">and PyCon</span></span></li>
</ul>
</li>
<li><em>Meet many vendors at once</em>
<ul>
<li><span style="color: #993300;"><span style="color: #ff0000;">SXSW <span style="color: #cc99ff;">and</span></span><span style="color: #cc99ff;"> AAPG</span></span></li>
</ul>
</li>
<li><em>Market yourself and your company</em>
<ul>
<li><span style="color: #ff0000;">SXSW,</span><span style="color: #cc99ff;"> PyCON,</span><span style="color: #993300;"> </span><span style="color: #ff9900;"><span style="color: #99cc00;">AAPG,</span> <span style="color: #99ccff;">and meetups</span></span></li>
</ul>
</li>
<li><em>Gain a better understanding of where your skills and knowledge rank</em>
<ul>
<li><span style="color: #993300;"><span style="color: #ff0000;">PyCon,</span> <span style="color: #cc99ff;">hackathons, </span><span style="color: #99cc00;">and meetups</span></span></li>
</ul>
</li>
</ul>
</li>
<li>Skills
<ul>
<li><em>Pick up new &#8220;tricks of the trade&#8221;</em>
<ul>
<li><span style="color: #993300;"><span style="color: #ff6600;"><span style="color: #993300;"><span style="color: #ff0000;">Hackathons,</span><span style="color: #cc99ff;"> PyCon,</span></span></span> <span style="color: #99cc00;">meet-ups</span></span></li>
</ul>
</li>
<li><em>Learn what to do or not do from others&#8217; experiences</em>
<ul>
<li><span style="color: #993300;"><span style="color: #ff0000;">PyCon,</span> <span style="color: #cc99ff;">meet-ups, </span><span style="color: #99cc00;">JSC Data Science Day</span></span></li>
</ul>
</li>
<li><em>Attend a tutorial and take the first few steps in a new skill with someone to lead you</em>
<ul>
<li><span style="color: #993300;"><span style="color: #ff0000;">PyCon,</span> <span style="color: #cc99ff;">meet-ups, </span><span style="color: #99cc00;">hackathon</span></span></li>
</ul>
</li>
</ul>
</li>
<li>Knowledge of the environment beyond your immediate organization
<ul>
<li><em>Learn about the larger range of tools, methods, and applications out there</em>
<ul>
<li><span style="color: #993300;"><span style="color: #ff0000;">PyCon,</span> <span style="color: #cc99ff;">meet-ups, </span><span style="color: #99cc00;">JSC Data Science Day,</span><span style="color: #99ccff;"> SXSW</span><br />
</span></li>
</ul>
</li>
<li><em>Understand trends in the larger market or community</em>
<ul>
<li><span style="color: #993300;"><span style="color: #ff0000;">SXSW,</span> <span style="color: #cc99ff;">meet-ups,</span> <span style="color: #99cc00;">PyCon</span></span></li>
</ul>
</li>
<li><em>Learn what is new</em>
<ul>
<li><span style="color: #993300;"><span style="color: #ff0000;"><span style="color: #ff6600;"><span style="color: #ff0000;">PyCon,</span> <span style="color: #cc99ff;">SXSW,</span></span></span> <span style="color: #99cc00;">JSC Data Science Day</span></span></li>
</ul>
</li>
</ul>
</li>
</ol>
<h3>Discussion</h3><p>Some types of events I might not want to go to every year. Other types of events I would go every year, but I might trade one conference for another with a similar style but different focus area.</p>
<h5>SXSW Interactive or another large conference of this type</h5><p>SXSW Interactive is great for getting a wide view of what is new and upcoming, but I&#8217;m not sure I need to go to it, or a conference like it, more than once every two to three years, even on a team that is responsible for keeping up with what is new.</p>
<h5>AAPG or another large science or professional association conference</h5><p>AAPG is great in terms of what it tries to be, a science conference for oil and gas geologists, but there are definitely <a href="https://www.youtube.com/watch?v=vCeNA9btD9E">some aspects</a> of tech and computer language specific conferences that science and industry conferences could learn from. In-depth half-day tutorials, how-to sessions, and skill-building activities are all things that could be done in that conference space but just aren&#8217;t. A similar conference to this one, but in a computer science domain, would be <a href="https://www.ieee.org/conferences_events/index.html">IEEE</a>.</p>
<h5>PyCon or similar tech conference</h5><p>PyCon had a wide range of benefits, including tutorials and &#8220;how to do this activity well&#8221; talks that are not always present at other technical gatherings. The year before I went to <a href="https://pydata.org/chicago2016/">PyData in Chicago</a>, which, although a smaller conference, had a similar range of talks. A conference that might be similar but with a different focus is <a href="https://scipy2017.scipy.org/ehome/index.php?eventid=220975&">SciPy</a>.</p>
<h5>Hackathons</h5><p>They are great at both putting you in contact with the local developer community and showing you the range of approaching to a topic. However, they are intense. I participate or help out with 1-2 a year. More than that might be too much. I&#8217;ll do Space-Apps Houston again as there is definitely some value there both to me and to the community. Also, it is Houston! It was embarrassing there were several years when over a hundred Space-Apps hackathon events occurred globally, but there wasn&#8217;t an event in Houston. An alternative option that I seem to always be out of town for is the <a href="http://houstonhackathon.com/">Houston Hackathon</a>.</p>
<h5>Johnson Space Center Data Science Day or similar 1-2 day, &lt;300 people,  local event.</h5><p>Johnson Space Center Data Science Day is useful for making local and NASA specific people connections and seeing what others are working on, however, it can&#8217;t replace something like PyCon or PyData for learning new skills. I&#8217;ll attend and present, but I don&#8217;t really count it as a learning opportunity in the same way. Similar type one to two-day speaker events are held at Rice University focusing on big data and <a href="http://ml2017.rice.edu/">machine learning</a>.</p>
<h5>Houston tech meetups</h5><p>Tech meet-ups are my bread and butter learning opportunity. The combination of free, relatively easy to fit in your schedule as you don&#8217;t have to take days off, and leading directly into side projects works out well for me, especially as someone relatively new to writing code for a living. How many meetups I attend will depend on my schedule and number of side projects, which is difficult to predict in advance.</p>
<h3>Next year plans</h3>
<h5><em>Attend 0-1</em></h5><p>AAPG and SXSW style conferences have value but a more narrow range of benefits that ranks secondary to me right now. If options for travel and training are limited, I would focus my budget elsewhere next year.</p>
<h5><em>Attend many, present at 1+, and organize at least 1</em></h5><p>Tech meetups and hackathons are great in that they&#8217;re free, local, and there&#8217;s something you could attend multiple times a week if you wanted, at least in a major US city. That frequency also represents a burn-out danger, however, so I&#8217;ll probably attend the same amount or shift to attending a little less next year.</p>
<h5><em>Attend 1+ and present at 1+</em></h5><p>JSC Data Science Day is a great way to make local connections in a large and spread out organization, but I wouldn&#8217;t consider it a replacement for training or a major conference.</p>
<h5><em>Attend 1 (consider presenting)</em></h5><p>PyCon and similar-type conferences probably offer the most value of the options examined due to the presence of many tutorials and &#8220;craft of coding&#8221; talks. My top focus for planning which conference to attend next year will be on finding a good PyCon-style conference that covers slightly different terrain but is still very applicable to work.</p>
<h3>Conclusion</h3><p>Different outside of work technical gatherings have different benefits. An exercise like this helps organize experiences into data that is easier to analyze. My conclusions on what types of conferences are the most useful for me this year and next reflects what benefits I value the most right now. My main focus is on building skills and learning new tools, which shows up in my future conference preferences.</p><p>&nbsp;</p>
<p>The post <a rel="nofollow" href="/what-do-i-get-out-of-conferences/">What do I get out of conferences?</a> appeared first on <a rel="nofollow" href="/">Justin Gosses Home</a>.</p>
]]></content:encoded>
			<wfw:commentRss>/what-do-i-get-out-of-conferences/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
	<post-id xmlns="com-wordpress:feed-additions:1">894</post-id>	</item>
		<item>
		<title>Presenting at Johnson Space Center Data Science Day</title>
		<link>/presenting-at-johnson-space-center-data-science-day/</link>
		<comments>/presenting-at-johnson-space-center-data-science-day/#respond</comments>
		<pubDate>Fri, 28 Apr 2017 22:41:52 +0000</pubDate>
		<dc:creator><![CDATA[Justin]]></dc:creator>
				<category><![CDATA[code]]></category>
		<category><![CDATA[data visualization]]></category>
		<category><![CDATA[javascript]]></category>
		<category><![CDATA[Javascript library]]></category>
		<category><![CDATA[NASA]]></category>
		<category><![CDATA[reveal.js]]></category>
		<category><![CDATA[talk]]></category>

		<guid isPermaLink="false">/?p=861</guid>
		<description><![CDATA[<p>This week I presented on the last 40 years of digital data visualization tools at Johnson Space Center Data Science Day. The event was held just off site this year, so it could be opened up to the public. The talk was a condensed, and I think improved, version of a talk I had previous gave<a href="/presenting-at-johnson-space-center-data-science-day/">[...]</a></p>
<p>The post <a rel="nofollow" href="/presenting-at-johnson-space-center-data-science-day/">Presenting at Johnson Space Center Data Science Day</a> appeared first on <a rel="nofollow" href="/">Justin Gosses Home</a>.</p>
]]></description>
				<content:encoded><![CDATA[<p>This week I presented on the last 40 years of digital data visualization tools at <a href="https://fal.jsc.nasa.gov/DSD/">Johnson Space Center Data Science Day</a>. The event was held just off site this year, so it could be opened up to the public. The talk was a condensed, and I think improved, version of a talk I had previous gave at a data visualization meet-up. This version was shorter by half and focused just on the tool evolution, as opposed to the previous talk which tried to also cover the context of these tools in large organizations.</p><p><iframe src="//slides.com/justingosses/history_data_visualization_tools/embed" width="800" height="460" scrolling="no" frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe></p>
<p style="text-align: center;"><a href="http://slides.com/justingosses/history_data_visualization_tools">click to view as a full window on a new tab</a></p>
<p>The post <a rel="nofollow" href="/presenting-at-johnson-space-center-data-science-day/">Presenting at Johnson Space Center Data Science Day</a> appeared first on <a rel="nofollow" href="/">Justin Gosses Home</a>.</p>
]]></content:encoded>
			<wfw:commentRss>/presenting-at-johnson-space-center-data-science-day/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
	<post-id xmlns="com-wordpress:feed-additions:1">861</post-id>	</item>
		<item>
		<title>Raspberry Shake &#8211; Personal Seismometer</title>
		<link>/raspberry-shake-personal-seismometer/</link>
		<comments>/raspberry-shake-personal-seismometer/#comments</comments>
		<pubDate>Sun, 01 Jan 2017 23:39:03 +0000</pubDate>
		<dc:creator><![CDATA[Justin]]></dc:creator>
				<category><![CDATA[code]]></category>
		<category><![CDATA[geology]]></category>
		<category><![CDATA[earth quakes]]></category>
		<category><![CDATA[geophysics]]></category>
		<category><![CDATA[IoT]]></category>
		<category><![CDATA[Raspberry Pi]]></category>
		<category><![CDATA[Raspberry Shake]]></category>
		<category><![CDATA[seismology]]></category>

		<guid isPermaLink="false">/?p=805</guid>
		<description><![CDATA[<p>Sometimes I get to combine geology nerdiness with technology nerdiness. This post definitely falls into that category. Earlier this year, I contributed to a kickstarter campaign by Ángel Rodríguez that raised $99,258 to bring into existence an inexpensive short period seismometer produced by OSAP. It consists of programs running on the Raspberry Pi, a small board that sits on top of<a href="/raspberry-shake-personal-seismometer/">[...]</a></p>
<p>The post <a rel="nofollow" href="/raspberry-shake-personal-seismometer/">Raspberry Shake &#8211; Personal Seismometer</a> appeared first on <a rel="nofollow" href="/">Justin Gosses Home</a>.</p>
]]></description>
				<content:encoded><![CDATA[<p>Sometimes I get to combine geology nerdiness with technology nerdiness. This post definitely falls into that category. Earlier this year, I contributed to <a href="https://www.kickstarter.com/projects/angelrodriguez/raspberry-shake-your-personal-seismograph">a kickstarter campaign</a> by Ángel Rodríguez that raised <span class="money">$99,258</span> to bring into existence an inexpensive <a href="https://qvsdata.wordpress.com/types-of-seismometer/">short period</a> seismometer produced by OSAP. It consists of programs running on the Raspberry Pi, a small board that sits on top of a raspberry pi or HAT (Hardware Attached on Top) and a geophone. This weekend I got to set mine up and start collecting data. This was my first kickstarter, and I am supper pleased with what was produced.</p><p>&nbsp;</p>
<div id="attachment_807" style="width: 650px" class="wp-caption aligncenter"><a href="https://i2.wp.com/justingosses.com/wp-content/uploads/2017/01/RaspberryShapeDiagram1.png"><img data-attachment-id="807" data-permalink="/raspberry-shake-personal-seismometer/raspberryshapediagram-2/" data-orig-file="https://i2.wp.com/justingosses.com/wp-content/uploads/2017/01/RaspberryShapeDiagram1.png?fit=4048%2C3036" data-orig-size="4048,3036" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="raspberryshapediagram" data-image-description="&lt;p&gt;Raspberry Shake board and geophone on Raspberry Pi 3&lt;/p&gt;
" data-medium-file="https://i2.wp.com/justingosses.com/wp-content/uploads/2017/01/RaspberryShapeDiagram1.png?fit=300%2C225" data-large-file="https://i2.wp.com/justingosses.com/wp-content/uploads/2017/01/RaspberryShapeDiagram1.png?fit=640%2C480" class="wp-image-807 size-large" src="https://i2.wp.com/justingosses.com/wp-content/uploads/2017/01/RaspberryShapeDiagram1.png?resize=640%2C480" alt="Geophone and Shake board are attached in this photo. The box in which everything sits still being assembled." width="640" height="480" srcset="https://i2.wp.com/justingosses.com/wp-content/uploads/2017/01/RaspberryShapeDiagram1.png?resize=1024%2C768 1024w, https://i2.wp.com/justingosses.com/wp-content/uploads/2017/01/RaspberryShapeDiagram1.png?resize=300%2C225 300w, https://i2.wp.com/justingosses.com/wp-content/uploads/2017/01/RaspberryShapeDiagram1.png?resize=285%2C214 285w, https://i2.wp.com/justingosses.com/wp-content/uploads/2017/01/RaspberryShapeDiagram1.png?w=1280 1280w, https://i2.wp.com/justingosses.com/wp-content/uploads/2017/01/RaspberryShapeDiagram1.png?w=1920 1920w" sizes="(max-width: 640px) 100vw, 640px" data-recalc-dims="1" /></a></p>
<p class="wp-caption-text">Geophone and Shake board are attached in this photo. The box is still being assembled.</p>
</div>
<div id="attachment_811" style="width: 650px" class="wp-caption aligncenter"><a href="https://i0.wp.com/justingosses.com/wp-content/uploads/2017/01/IMG_20170101_010649.jpg"><img data-attachment-id="811" data-permalink="/raspberry-shake-personal-seismometer/img_20170101_010649/" data-orig-file="https://i1.wp.com/justingosses.com/wp-content/uploads/2017/01/IMG_20170101_010649-e1483310777691.jpg?fit=3944%2C2958" data-orig-size="3944,2958" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Pixel&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1483236409&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.67&quot;,&quot;iso&quot;:&quot;2224&quot;,&quot;shutter_speed&quot;:&quot;0.066667&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="img_20170101_010649" data-image-description="&lt;p&gt;live seismometer&lt;/p&gt;
" data-medium-file="https://i1.wp.com/justingosses.com/wp-content/uploads/2017/01/IMG_20170101_010649-e1483310777691.jpg?fit=300%2C225" data-large-file="https://i1.wp.com/justingosses.com/wp-content/uploads/2017/01/IMG_20170101_010649-e1483310777691.jpg?fit=640%2C480" class="wp-image-811 size-large" src="https://i2.wp.com/justingosses.com/wp-content/uploads/2017/01/IMG_20170101_010649-e1483310777691-1024x768.jpg?resize=640%2C480" alt="live seismometer" width="640" height="480" srcset="https://i1.wp.com/justingosses.com/wp-content/uploads/2017/01/IMG_20170101_010649-e1483310777691.jpg?resize=1024%2C768 1024w, https://i1.wp.com/justingosses.com/wp-content/uploads/2017/01/IMG_20170101_010649-e1483310777691.jpg?resize=300%2C225 300w, https://i1.wp.com/justingosses.com/wp-content/uploads/2017/01/IMG_20170101_010649-e1483310777691.jpg?resize=285%2C214 285w, https://i1.wp.com/justingosses.com/wp-content/uploads/2017/01/IMG_20170101_010649-e1483310777691.jpg?w=1280 1280w, https://i1.wp.com/justingosses.com/wp-content/uploads/2017/01/IMG_20170101_010649-e1483310777691.jpg?w=1920 1920w" sizes="(max-width: 640px) 100vw, 640px" data-recalc-dims="1" /></a></p>
<p class="wp-caption-text">assembled and live seismometer</p>
</div><p>&nbsp;</p><p>Setting up the Raspberry Shake was pretty straight forward. There was a bug in some of the units first sent out that would have made future updates difficult, but the folks at OSAP sent out very clear instructions for fixing it. The process took me less than 5 minutes. They supplied a <a href="http://raspberryshake.org/#section-about">website</a> with general information, a <a href="http://manual.raspberryshake.org/">user guide</a>, and a <a href="https://groups.google.com/forum/#!searchin/raspberryshake/download$20swarm%7Csort:relevance">google groups forum</a> for questions.</p><p>If you go to <a href="http://raspberryshake.net/stationview/#?net=AM&sta=REA98">this link</a>, you can see the last few minutes of data from my station live and a map of all the Raspberry Pi stations world-wide.</p>
<div id="attachment_810" style="width: 650px" class="wp-caption aligncenter"><a href="https://i0.wp.com/justingosses.com/wp-content/uploads/2017/01/map_station_washer.png"><img data-attachment-id="810" data-permalink="/raspberry-shake-personal-seismometer/map_station_washer/" data-orig-file="https://i0.wp.com/justingosses.com/wp-content/uploads/2017/01/map_station_washer.png?fit=2868%2C1600" data-orig-size="2868,1600" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="map_station_washer" data-image-description="&lt;p&gt;map and station information for the seismometer. Spikes are due to the end of a washer cycle. Ha ha.&lt;/p&gt;
" data-medium-file="https://i0.wp.com/justingosses.com/wp-content/uploads/2017/01/map_station_washer.png?fit=300%2C167" data-large-file="https://i0.wp.com/justingosses.com/wp-content/uploads/2017/01/map_station_washer.png?fit=640%2C357" class="wp-image-810 size-large" src="https://i0.wp.com/justingosses.com/wp-content/uploads/2017/01/map_station_washer.png?resize=640%2C357" alt="map and station information for the seismometer. Spikes are due to the end of a washer cycle. Ha ha." width="640" height="357" srcset="https://i0.wp.com/justingosses.com/wp-content/uploads/2017/01/map_station_washer.png?resize=1024%2C571 1024w, https://i0.wp.com/justingosses.com/wp-content/uploads/2017/01/map_station_washer.png?resize=300%2C167 300w, https://i0.wp.com/justingosses.com/wp-content/uploads/2017/01/map_station_washer.png?w=1280 1280w, https://i0.wp.com/justingosses.com/wp-content/uploads/2017/01/map_station_washer.png?w=1920 1920w" sizes="(max-width: 640px) 100vw, 640px" data-recalc-dims="1" /></a></p>
<p class="wp-caption-text"><a href="http://raspberryshake.net/stationview/#?net=AM&sta=REA98">Map</a> of all Raspberry Shakes in USA and station information for my seismometer. Spikes are due to the end of a washer cycle.</p>
</div><p>Right now, the device is under a desk near my router and several other digital devices. Eventually, I&#8217;ll likely move to a more quiet location. For now, I&#8217;m curious how much information it can pick up of people coming and going. One of our interns is working on a room-use sensor array for Raspberry Pi&#8217;s to help gather analytics on facility use. I&#8217;m curious if this type of information might be advantages over infrared motion sensor type approaches.</p>
<div id="attachment_812" style="width: 650px" class="wp-caption aligncenter"><a href="https://i1.wp.com/justingosses.com/wp-content/uploads/2017/01/helicorder.png"><img data-attachment-id="812" data-permalink="/raspberry-shake-personal-seismometer/helicorder/" data-orig-file="https://i1.wp.com/justingosses.com/wp-content/uploads/2017/01/helicorder.png?fit=1572%2C1444" data-orig-size="1572,1444" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="helicorder" data-image-description="&lt;p&gt;Helicorder view using the  Swarm open-source software.&lt;/p&gt;
" data-medium-file="https://i1.wp.com/justingosses.com/wp-content/uploads/2017/01/helicorder.png?fit=300%2C276" data-large-file="https://i1.wp.com/justingosses.com/wp-content/uploads/2017/01/helicorder.png?fit=640%2C588" class="size-large wp-image-812" src="https://i1.wp.com/justingosses.com/wp-content/uploads/2017/01/helicorder.png?resize=640%2C588" alt="Helicorder view using the Swarm open-source software." width="640" height="588" srcset="https://i1.wp.com/justingosses.com/wp-content/uploads/2017/01/helicorder.png?resize=1024%2C941 1024w, https://i1.wp.com/justingosses.com/wp-content/uploads/2017/01/helicorder.png?resize=300%2C276 300w, https://i1.wp.com/justingosses.com/wp-content/uploads/2017/01/helicorder.png?w=1572 1572w, https://i1.wp.com/justingosses.com/wp-content/uploads/2017/01/helicorder.png?w=1280 1280w" sizes="(max-width: 640px) 100vw, 640px" data-recalc-dims="1" /></a></p>
<p class="wp-caption-text">Helicorder view using the open-source <a href="http://www.avo.alaska.edu/Software/swarm/manual/tutorial.html">Swarm</a> software.</p>
</div><p>At this point, some of you might be thinking, &#8220;wait a minute, are there even earthquakes in Houston for it to hear!?&#8221; The short answer is maybe, if I&#8217;m lucky. It is a <a href="https://qvsdata.wordpress.com/types-of-seismometer/">short period</a> seismometer. It is good for detecting relatively close and small earthquakes and not too good for listening for bigger earthquakes farther away. Before I ordered the Raspberry Shake, I did some research and figured I might be able to detect a few earthquakes a year. There were earthquakes in the last five years that might have been big enough to detect in Houston in north Texas (<a href="http://www.houstonpublicmedia.org/articles/news/2015/05/04/60069/geologists-look-at-past-earthquakes-in-houston-to-explain-present-tremors-in-north-texas-2/">possibly induced due to water disposal</a>), <a href="http://earthquaketrack.com/us-tx-austin/recent">south of San Antonio</a>, and in <a href="http://earthquaketrack.com/r/western-texas/recent">far West Texas</a>. There were also several earthquakes in the Houston area in the early part of the 20th century <a href="https://en.wikipedia.org/wiki/Goose_Creek_Oil_Field">due to extensive oil production</a> of the Goose Creek oil field.</p><p>I&#8217;ve signed up for the USGS&#8217;s <a href="https://sslearthquake.usgs.gov/ens/">earthquakes notification service</a> and will check the Raspberry Shake when there is an earthquake detected within 600 miles.</p>
<p>The post <a rel="nofollow" href="/raspberry-shake-personal-seismometer/">Raspberry Shake &#8211; Personal Seismometer</a> appeared first on <a rel="nofollow" href="/">Justin Gosses Home</a>.</p>
]]></content:encoded>
			<wfw:commentRss>/raspberry-shake-personal-seismometer/feed/</wfw:commentRss>
		<slash:comments>2</slash:comments>
	<post-id xmlns="com-wordpress:feed-additions:1">805</post-id>	</item>
		<item>
		<title>Meet Up Talk Data Viz Tools</title>
		<link>/talk-on-changing-landscape-of-data-viz-tools/</link>
		<comments>/talk-on-changing-landscape-of-data-viz-tools/#respond</comments>
		<pubDate>Tue, 22 Nov 2016 04:02:11 +0000</pubDate>
		<dc:creator><![CDATA[Justin]]></dc:creator>
				<category><![CDATA[code]]></category>
		<category><![CDATA[business intelligence]]></category>
		<category><![CDATA[Chart.js]]></category>
		<category><![CDATA[d3.js]]></category>
		<category><![CDATA[data visualization]]></category>
		<category><![CDATA[excel]]></category>
		<category><![CDATA[Flot.js]]></category>
		<category><![CDATA[history]]></category>
		<category><![CDATA[javascript]]></category>
		<category><![CDATA[lotus 1-2-3]]></category>
		<category><![CDATA[meet-up]]></category>
		<category><![CDATA[presentation]]></category>
		<category><![CDATA[reveal.js]]></category>
		<category><![CDATA[SAS]]></category>
		<category><![CDATA[slides.com]]></category>
		<category><![CDATA[spreadsheet]]></category>
		<category><![CDATA[Tableau]]></category>
		<category><![CDATA[timeline.js]]></category>
		<category><![CDATA[visicalc]]></category>

		<guid isPermaLink="false">/?p=768</guid>
		<description><![CDATA[<p>&#8220;THE CHANGING LANDSCAPE OF DATA VISUALIZATION TOOLS IN LARGE ORGANIZATIONS&#8221;I recently gave a talk at the Houston Data Visualization meet-up. In addition to being a good excuse for putting time on my calendar to research the evolution of data visualization tools over the past 40 years, the talk allowed me to try out a few presentation<a href="/talk-on-changing-landscape-of-data-viz-tools/">[...]</a></p>
<p>The post <a rel="nofollow" href="/talk-on-changing-landscape-of-data-viz-tools/">Meet Up Talk Data Viz Tools</a> appeared first on <a rel="nofollow" href="/">Justin Gosses Home</a>.</p>
]]></description>
				<content:encoded><![CDATA[<h3>&#8220;THE CHANGING LANDSCAPE OF DATA VISUALIZATION TOOLS IN LARGE ORGANIZATIONS&#8221;</h3><p>I recently gave a talk at the <a href="https://www.meetup.com/Houston-Data-Visualization-Meetup/events/233893631/">Houston Data Visualization meet-up</a>. In addition to being a good excuse for putting time on my calendar to research the evolution of data visualization tools over the past 40 years, the talk allowed me to try out a few presentation related tools. <a href="https://github.com/hakimel/reveal.js/" target="blank">Reveal.js</a> is a user friendly framework for making presentations that consist of html, css, and JavaScript, just like any normal webpage. <a href="https://slides.com/" target="blank">Slides.com</a> is a hosting and GUI site for reveal.js slides. One of the best features of slides.com was being able to control the slides on my computer via my phone. This enabled me to walk around and not be as tied to my computer or rely on someone else to advance the slides. It also provides a nice way to briefly look down as you flip slides and sneak a glance at speakers notes. I used <a href="https://timeline.knightlab.com/" target="blank">timeline.js</a> from the <a href="https://knightlab.northwestern.edu/" target="blank">Knight Lab</a> at Northwestern university to create a timeline of key tool development that I referred to several times during the talk.</p><p>All the data for the presentation is in <a href="https://github.com/JustinGOSSES/talk_HistDVTools" target="blank"> this</a> github repo. I hope to revisit this presentation to take a second stab at it or perhaps turn it into a series of blog posts for work.</p><p>&nbsp;</p><p><iframe src="//slides.com/justingosses/dataviztoolshistorylargeorg/embed" width="800" height="460" frameborder="0" scrolling="no" allowfullscreen="allowfullscreen"></iframe></p>
<p style="text-align: center;"><a href="http://slides.com/justingosses/dataviztoolshistorylargeorg#/">click to view as a full window on a new tab</a></p><p><iframe style="border: 1px solid lightgrey;" src="https://cdn.knightlab.com/libs/timeline3/latest/embed/index.html?source=1O32FBDYO16WjoFSCsWS1d0oEuRo0C00q633nhhGZlNE&font=Default&lang=en&initial_zoom=2&height=800" width="800" height="800" scrolling="yes" allowfullscreen="allowfullscreen"></iframe></p>
<p style="text-align: center;"><a href="https://cdn.knightlab.com/libs/timeline3/latest/embed/index.html?source=1O32FBDYO16WjoFSCsWS1d0oEuRo0C00q633nhhGZlNE&font=Default&lang=en&initial_zoom=2&height=650">click to view as a full window on a new tab</a></p>
<p>The post <a rel="nofollow" href="/talk-on-changing-landscape-of-data-viz-tools/">Meet Up Talk Data Viz Tools</a> appeared first on <a rel="nofollow" href="/">Justin Gosses Home</a>.</p>
]]></content:encoded>
			<wfw:commentRss>/talk-on-changing-landscape-of-data-viz-tools/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
	<post-id xmlns="com-wordpress:feed-additions:1">768</post-id>	</item>
		<item>
		<title>Game of Thrones Parallel Sets Data Visualization</title>
		<link>/game-of-thrones-parallel-sets-data-visualization/</link>
		<comments>/game-of-thrones-parallel-sets-data-visualization/#respond</comments>
		<pubDate>Mon, 10 Oct 2016 18:31:19 +0000</pubDate>
		<dc:creator><![CDATA[Justin]]></dc:creator>
				<category><![CDATA[code]]></category>
		<category><![CDATA[d3]]></category>
		<category><![CDATA[d3.js]]></category>
		<category><![CDATA[data visualization]]></category>
		<category><![CDATA[Front-End]]></category>
		<category><![CDATA[Game of Thrones]]></category>
		<category><![CDATA[javascript]]></category>
		<category><![CDATA[opendata]]></category>
		<category><![CDATA[web development]]></category>

		<guid isPermaLink="false">/?p=748</guid>
		<description><![CDATA[<p>User interface add-ons to make a better parallel sets visualizations: (skip to the data visualization here.)Parallel sets is a data visualization type that shows how attributes of different types are distributed across a large number of instances. Common examples include datasets of the characteristics of passengers on the Titanic disaster and nutrition information of many different types of<a href="/game-of-thrones-parallel-sets-data-visualization/">[...]</a></p>
<p>The post <a rel="nofollow" href="/game-of-thrones-parallel-sets-data-visualization/">Game of Thrones Parallel Sets Data Visualization</a> appeared first on <a rel="nofollow" href="/">Justin Gosses Home</a>.</p>
]]></description>
				<content:encoded><![CDATA[<h2>User interface add-ons to make a better parallel sets visualizations:</h2>
<p style="text-align: center;">(skip to the data visualization <a href="/ParaSet_Oct2/" target="_blank">here</a>.)</p><p>Parallel sets is a data visualization type that shows how attributes of different types are distributed across a large number of instances. Common examples include datasets of the characteristics of passengers on the Titanic disaster and nutrition information of many different types of cereal. Parallel sets data visualizations are good at showing how attributes do or don&#8217;t cluster over a large dataset of instances. It is a data visualization type favored when the data is categorical and not strictly numerical.</p><p>I built a <a href="/parallel-sets-data-visualization/">parallel sets data visualization</a> based on a dataset of battles from the <a href="https://en.wikipedia.org/wiki/Game_of_Thrones">Game of Thrones series</a> (TV version, not book). Examples questions that can be answered by a <a href="/ParaSet_Oct2/" target="_blank">parallel sets</a> built from this data include: Which battle type has the best success rate? Which house has the best and track record in terms of number of battles won or lost? Were there more pitched battles versus ambushes in later years versus earlier years? Are battles in certain regions more likely to result in a major characters death?</p><p>The parallel sets visualizations that I&#8217;ve seen work best when the number of types of attributes is between 3 and 10, the number of different attributes within each type is &lt;10, and the total number of instances is &gt;100.  Outside this range, parallel sets tend to get too cluttered.</p><p>When I used parallel sets for a project at work, I found it be successful for the immediate problem but very easy to be cluttered and messy if I tried to include all characteristics found in the dataset. Although a subset of the data was fine for showing what I was interested in at the time, I knew eventually I would want to show a larger dataset and let the user explore the data. This led to brainstorming potential improvements for my initial parallel sets code base, which I had adopted from Jason Davis <a href="https://github.com/jasondavies/d3-parsets" target="_blank">parasets </a>project. Both us d3.js. <span style="color: #333399;">I&#8217;ve completed the first two interactivity improvements listed below in this</span> <a href="/ParaSet_Oct2/" target="_blank">visualization</a>.</p>
<ol>
<li><span style="color: #333399;">User can select which data dimensions to visualize (types of attributes: region, year, defender, etc.)</span></li>
<li><span style="color: #333399;">User can limit the visualization to only data that contains a certain value in a certain dimension (battles with Stark as the defender)</span></li>
<li>User can chose to turn numerical information into small categorical groups (size of battle was &gt; or &lt; some number)<br />
a. user selects n number of divisions of the data between min and max<br />
b. or n number of divisions based on equal number in each category<br />
c. or by log divisions (&gt;10, &gt;100, &gt;1000, etc.)</li>
<li>Interactive combination of histogram and parallel sets data visualizations via dc.js.</li>
<li>Pre-determined combinations of data dimensions available via a series of buttons to assist in story-telling to user.</li>
</ol><p>Letting the user select the input data and try different combinations reduces cluttering. Giving the user the option to pick the input data makes this data visualization more of a data exploration tool and less of a straight forward story telling image.</p><p>It is also useful if you don&#8217;t have HBO but want to study up for water cooler conversations.</p><p>&nbsp;</p>
<h3>Examples from the Game of Thrones Parallel Sets Visualization:</h3>
<p style="text-align: center;"><em>ribbon width = number of battles</em></p>
<div id="attachment_750" style="width: 650px" class="wp-caption aligncenter"><a href="https://i0.wp.com/justingosses.com/wp-content/uploads/2016/10/Screen-Shot-2016-10-10-at-12.29.28-PM.png"><img data-attachment-id="750" data-permalink="/game-of-thrones-parallel-sets-data-visualization/screen-shot-2016-10-10-at-12-29-28-pm/" data-orig-file="https://i0.wp.com/justingosses.com/wp-content/uploads/2016/10/Screen-Shot-2016-10-10-at-12.29.28-PM.png?fit=2006%2C1396" data-orig-size="2006,1396" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screen-shot-2016-10-10-at-12-29-28-pm" data-image-description="&lt;p&gt;Battles Type Vs. Outcome&lt;/p&gt;
" data-medium-file="https://i0.wp.com/justingosses.com/wp-content/uploads/2016/10/Screen-Shot-2016-10-10-at-12.29.28-PM.png?fit=300%2C209" data-large-file="https://i0.wp.com/justingosses.com/wp-content/uploads/2016/10/Screen-Shot-2016-10-10-at-12.29.28-PM.png?fit=640%2C446" class="wp-image-750 size-large" src="https://i0.wp.com/justingosses.com/wp-content/uploads/2016/10/Screen-Shot-2016-10-10-at-12.29.28-PM.png?resize=640%2C446" alt="Battles Type Vs. Outcome" width="640" height="446" srcset="https://i0.wp.com/justingosses.com/wp-content/uploads/2016/10/Screen-Shot-2016-10-10-at-12.29.28-PM.png?resize=1024%2C713 1024w, https://i0.wp.com/justingosses.com/wp-content/uploads/2016/10/Screen-Shot-2016-10-10-at-12.29.28-PM.png?resize=300%2C209 300w, https://i0.wp.com/justingosses.com/wp-content/uploads/2016/10/Screen-Shot-2016-10-10-at-12.29.28-PM.png?w=1280 1280w, https://i0.wp.com/justingosses.com/wp-content/uploads/2016/10/Screen-Shot-2016-10-10-at-12.29.28-PM.png?w=1920 1920w" sizes="(max-width: 640px) 100vw, 640px" data-recalc-dims="1" /></a></p>
<p class="wp-caption-text">Battles Type Vs. Outcome</p>
</div>
<p style="text-align: center;"><em>Ambushes, razing, and siege perform better for the attacker than a pitched battle. </em></p>
<div id="attachment_751" style="width: 650px" class="wp-caption aligncenter"><a href="https://i2.wp.com/justingosses.com/wp-content/uploads/2016/10/Screen-Shot-2016-10-10-at-12.36.24-PM.png"><img data-attachment-id="751" data-permalink="/game-of-thrones-parallel-sets-data-visualization/screen-shot-2016-10-10-at-12-36-24-pm/" data-orig-file="https://i2.wp.com/justingosses.com/wp-content/uploads/2016/10/Screen-Shot-2016-10-10-at-12.36.24-PM.png?fit=1988%2C1226" data-orig-size="1988,1226" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screen-shot-2016-10-10-at-12-36-24-pm" data-image-description="&lt;p&gt;Who loses battles vs. wins battles.&lt;/p&gt;
" data-medium-file="https://i2.wp.com/justingosses.com/wp-content/uploads/2016/10/Screen-Shot-2016-10-10-at-12.36.24-PM.png?fit=300%2C185" data-large-file="https://i2.wp.com/justingosses.com/wp-content/uploads/2016/10/Screen-Shot-2016-10-10-at-12.36.24-PM.png?fit=640%2C395" class="wp-image-751 size-large" src="https://i2.wp.com/justingosses.com/wp-content/uploads/2016/10/Screen-Shot-2016-10-10-at-12.36.24-PM.png?resize=640%2C395" alt="Who loses battles vs. wins battles." width="640" height="395" srcset="https://i2.wp.com/justingosses.com/wp-content/uploads/2016/10/Screen-Shot-2016-10-10-at-12.36.24-PM.png?resize=1024%2C632 1024w, https://i2.wp.com/justingosses.com/wp-content/uploads/2016/10/Screen-Shot-2016-10-10-at-12.36.24-PM.png?resize=300%2C185 300w, https://i2.wp.com/justingosses.com/wp-content/uploads/2016/10/Screen-Shot-2016-10-10-at-12.36.24-PM.png?w=1280 1280w, https://i2.wp.com/justingosses.com/wp-content/uploads/2016/10/Screen-Shot-2016-10-10-at-12.36.24-PM.png?w=1920 1920w" sizes="(max-width: 640px) 100vw, 640px" data-recalc-dims="1" /></a></p>
<p class="wp-caption-text">Who loses battles vs. wins battles.</p>
</div>
<p style="text-align: center;"><em>Freefolk (black ribbon) have a horrible track record at attacking. House Stark and Baratheon are also not that great.</em></p>
<div id="attachment_752" style="width: 650px" class="wp-caption aligncenter"><a href="https://i2.wp.com/justingosses.com/wp-content/uploads/2016/10/Screen-Shot-2016-10-10-at-12.37.40-PM.png"><img data-attachment-id="752" data-permalink="/game-of-thrones-parallel-sets-data-visualization/screen-shot-2016-10-10-at-12-37-40-pm/" data-orig-file="https://i2.wp.com/justingosses.com/wp-content/uploads/2016/10/Screen-Shot-2016-10-10-at-12.37.40-PM.png?fit=1964%2C1236" data-orig-size="1964,1236" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screen-shot-2016-10-10-at-12-37-40-pm" data-image-description="&lt;p&gt;Battles vs. character deaths&lt;/p&gt;
" data-medium-file="https://i2.wp.com/justingosses.com/wp-content/uploads/2016/10/Screen-Shot-2016-10-10-at-12.37.40-PM.png?fit=300%2C189" data-large-file="https://i2.wp.com/justingosses.com/wp-content/uploads/2016/10/Screen-Shot-2016-10-10-at-12.37.40-PM.png?fit=640%2C403" class="wp-image-752 size-large" src="https://i2.wp.com/justingosses.com/wp-content/uploads/2016/10/Screen-Shot-2016-10-10-at-12.37.40-PM.png?resize=640%2C403" alt="Battles vs. character deaths" width="640" height="403" srcset="https://i2.wp.com/justingosses.com/wp-content/uploads/2016/10/Screen-Shot-2016-10-10-at-12.37.40-PM.png?resize=1024%2C644 1024w, https://i2.wp.com/justingosses.com/wp-content/uploads/2016/10/Screen-Shot-2016-10-10-at-12.37.40-PM.png?resize=300%2C189 300w, https://i2.wp.com/justingosses.com/wp-content/uploads/2016/10/Screen-Shot-2016-10-10-at-12.37.40-PM.png?w=1280 1280w, https://i2.wp.com/justingosses.com/wp-content/uploads/2016/10/Screen-Shot-2016-10-10-at-12.37.40-PM.png?w=1920 1920w" sizes="(max-width: 640px) 100vw, 640px" data-recalc-dims="1" /></a></p>
<p class="wp-caption-text">Battles vs. character deaths: 1 = major character death, 0 = no major character death</p>
</div><p><em>Lannister, Stark, and Baratheon have the highest number of battles where they are the main attacker and an important character dies. </em></p>
<div id="attachment_754" style="width: 650px" class="wp-caption aligncenter"><a href="https://i0.wp.com/justingosses.com/wp-content/uploads/2016/10/Screen-Shot-2016-10-10-at-1.24.35-PM.png"><img data-attachment-id="754" data-permalink="/game-of-thrones-parallel-sets-data-visualization/screen-shot-2016-10-10-at-1-24-35-pm/" data-orig-file="https://i0.wp.com/justingosses.com/wp-content/uploads/2016/10/Screen-Shot-2016-10-10-at-1.24.35-PM.png?fit=1964%2C1222" data-orig-size="1964,1222" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screen-shot-2016-10-10-at-1-24-35-pm" data-image-description="&lt;p&gt;Who wins when defending and major character deaths&lt;/p&gt;
" data-medium-file="https://i0.wp.com/justingosses.com/wp-content/uploads/2016/10/Screen-Shot-2016-10-10-at-1.24.35-PM.png?fit=300%2C187" data-large-file="https://i0.wp.com/justingosses.com/wp-content/uploads/2016/10/Screen-Shot-2016-10-10-at-1.24.35-PM.png?fit=640%2C398" class="wp-image-754 size-large" src="https://i0.wp.com/justingosses.com/wp-content/uploads/2016/10/Screen-Shot-2016-10-10-at-1.24.35-PM.png?resize=640%2C398" alt="Who wins when defending and major character deaths" width="640" height="398" srcset="https://i0.wp.com/justingosses.com/wp-content/uploads/2016/10/Screen-Shot-2016-10-10-at-1.24.35-PM.png?resize=1024%2C637 1024w, https://i0.wp.com/justingosses.com/wp-content/uploads/2016/10/Screen-Shot-2016-10-10-at-1.24.35-PM.png?resize=300%2C187 300w, https://i0.wp.com/justingosses.com/wp-content/uploads/2016/10/Screen-Shot-2016-10-10-at-1.24.35-PM.png?w=1280 1280w, https://i0.wp.com/justingosses.com/wp-content/uploads/2016/10/Screen-Shot-2016-10-10-at-1.24.35-PM.png?w=1920 1920w" sizes="(max-width: 640px) 100vw, 640px" data-recalc-dims="1" /></a></p>
<p class="wp-caption-text">Who wins when defending and major character deaths</p>
</div>
<p style="text-align: center;"><em>The attacker usually wins in a Game of Thrones battle, but when they lose, it tends to be when the main defender is a Lannister. In those battles where a defending Lannister wins, it is also common for a major character of some type to die. </em></p>
<h2 style="text-align: center;">Explore the live data visualization <a href="/ParaSet_Oct2/" target="_blank">here</a>.</h2>
<h2></h2>
<p>The post <a rel="nofollow" href="/game-of-thrones-parallel-sets-data-visualization/">Game of Thrones Parallel Sets Data Visualization</a> appeared first on <a rel="nofollow" href="/">Justin Gosses Home</a>.</p>
]]></content:encoded>
			<wfw:commentRss>/game-of-thrones-parallel-sets-data-visualization/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
	<post-id xmlns="com-wordpress:feed-additions:1">748</post-id>	</item>
	</channel>
</rss>
